{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3lRg7qHY7T3"
      },
      "source": [
        "### ***DATASET PREPROCESSING AND APEENDING***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7gBTBASoROa"
      },
      "source": [
        "**Data preprocessing and correlation matrix of male records**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "uip6rH9-no5W",
        "outputId": "0a1fae62-8cfa-4523-bde0-de20aecc119b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "data = pd.read_csv(\"hairfall_problem3592.xlsx - hairfall_problem3592 (2).csv\")  #read and preprocess the data\n",
        "#data = pd.read_csv('/content/survey data.csv')\n",
        "male_records = data[data['What is your gender ?'] == 'Male']\n",
        "df = male_records.drop(columns=[\"Timestamp\", \"What is your name ?\"], axis=1)  #drop irrelevant columns for analysis\n",
        "\n",
        "#check the age column for incorrect values\n",
        "invalid_ages = df[(df['What is your age ?'] < 0) | (df['What is your age ?'] > 120)]\n",
        "#print the error value and its index\n",
        "print(\"Out of range values in age column:\")\n",
        "print(invalid_ages[['What is your age ?']])\n",
        "\n",
        "#replace the incorrect age to 18\n",
        "df.loc[503, 'What is your age ?'] = 18  # Correcting 218 to 18\n",
        "\n",
        "# Columns to exclude from checking\n",
        "excluded_columns = [\n",
        "    \"What is your age ?\",\n",
        "    \"What is your gender ?\",\n",
        "    \"What is your food habit\"\n",
        "]\n",
        "\n",
        "# Check for anomalies in all other columns\n",
        "for i in range(df.shape[1]):\n",
        "    col_name = df.columns[i]\n",
        "    if col_name in excluded_columns:\n",
        "        continue\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        value = str(row[col_name]).strip().lower()\n",
        "        if value != \"yes\" and value != \"no\":\n",
        "            print(f\"Index: {index}, Column: {col_name}, Value: {row[col_name]}\")\n",
        "\n",
        "df.loc[8, 'Do you use chemicals, hair gel, or color in your hair?'] = 'Yes'  #correcting yea to Yes\n",
        "\n",
        "#apply one-hot encoding to the filtered dataset\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "df = df.astype({col: int for col in df.columns if df[col].dtype == bool})\n",
        "\n",
        "#correlation matrix\n",
        "corr_matrix = df.corr()  #compute the correlation matrix\n",
        "plt.figure(figsize=(15, 12))  #plot the heatmap\n",
        "sns.heatmap(\n",
        "    corr_matrix,\n",
        "    annot=True,\n",
        "    annot_kws={\"size\": 7},\n",
        "    cmap='coolwarm',\n",
        "    fmt='.2f',\n",
        "    linewidths=0.5,\n",
        "    linecolor='white',\n",
        "    cbar=True,\n",
        "    cbar_kws={'shrink': 0.8}\n",
        ")\n",
        "\n",
        "plt.title('Correlation Matrix Heatmap', fontsize=18, pad=20)\n",
        "plt.xticks(fontsize=10, rotation=45, ha='right')\n",
        "plt.yticks(fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#display table of corr with the target variable sorted from highest to lowest value\n",
        "print(\"**Table of correlation matrix values with the target variable** \\n\")\n",
        "target_variable = 'Do you have hair fall problem ?_Yes'\n",
        "correlation_with_target = df.corr()[target_variable]\n",
        "print(correlation_with_target.sort_values(ascending=False))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dJKvvjCiVBD"
      },
      "source": [
        "**Drop the columns with lowest corr values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7hrv38Q4sEj"
      },
      "outputs": [],
      "source": [
        "data_relevant_columns = df.drop(columns=[\"Do you have any type of sleep disturbance?_Yes\",\n",
        "                                         \"Do you have anemia?_Yes\", \"What is your food habit_Nutritious\",\n",
        "                                         \"What is your food habit_Dependent on fast food\"]\n",
        "                                         ,axis=1)\n",
        "\n",
        "data_relevant_columns.head()\n",
        "data_relevant_columns.count()\n",
        "data_relevant_columns.to_csv(\"preprocessed_mendeley_dataset.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OW3vDAAGVhaP",
        "outputId": "4211b918-06d9-446f-f246-6e2a2a9f69ab"
      },
      "outputs": [],
      "source": [
        "#data_relevant_columns.head()\n",
        "data_relevant_columns.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhAfJS8LCCzr"
      },
      "source": [
        "**Preproccessing and appending the new records from the questionnaire to the dataset with relevant columns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRx6QqQoCP1L",
        "outputId": "65ee3d73-ba65-4e9c-f748-7b37dfa94e85"
      },
      "outputs": [],
      "source": [
        "#loading the Google Forms dataset\n",
        "responses_df = pd.read_csv(\"×—×™×–×•×™ × ×©×™×¨×ª ×©×™×¢×¨ (Responses) - Form Responses 1 (1).csv\")\n",
        "#responses_df = pd.read_csv('/content/Form Responses.csv')\n",
        "\n",
        "#column name mapping\n",
        "column_mapping = {\n",
        "    \"××”×• ×’×™×œ×š?\": \"What is your age ?\",\n",
        "    \"×”×× ××ª×” ×—×•×•×” × ×©×™×¨×ª ×©×™×¢×¨ ××• × ×¡×™×’×” ×©×œ ×§×• ×”×©×™×¢×¨?\": \"Do you have hair fall problem ?_Yes\",\n",
        "    \"×”×× ××™×©×”×• ×‘××©×¤×—×ª×š ×—×•×•×” × ×©×™×¨×ª ×©×™×¢×¨ ××• ×”×ª×§×¨×—×•×ª?\": \"Is there anyone in your family having a hair fall problem or a baldness issue?_Yes\",\n",
        "    \"×”×× ×”×ª××•×“×“×ª ×¢× ×¡×•×’ ×›×œ×©×”×• ×©×œ ××—×œ×” ×›×¨×•× ×™×ª ×‘×¢×‘×¨?\": \"Did you face any type of chronic illness in the past?_Yes\",\n",
        "    \"××ª×” × ×©××¨ ×¢×¨ ×¢×“ ×××•×—×¨ ×‘×œ×™×œ×”?\": \"Do you stay up late at night?_Yes\",\n",
        "    \"×”×× ××ª×” ×—×•×©×‘ ×©×‘××–×•×¨ ×©×œ×š ××™× ×”× ×¡×™×‘×” ×××—×•×¨×™ ×‘×¢×™×•×ª × ×©×™×¨×ª ×©×™×¢×¨?\": \"Do you think that in your area water is a reason behind hair fall problems?_Yes\",\n",
        "    \"×”×× ××ª×” ××©×ª××© ×‘×›×™××™×§×œ×™×, ×’'×œ ×œ×©×™×¢×¨ ××• ×¦×‘×¢ ×‘×©×™×¢×¨ ×©×œ×š?\": \"Do you use chemicals, hair gel, or color in your hair?_Yes\",\n",
        "    \"×”×× ××ª×” ×—×•×•×” ×œ×¢×™×ª×™× ×œ×—×¥ × ×¤×©×™ ××• ×ª×§×•×¤×•×ª ××ª×•×—×•×ª?\": \"Do you have too much stress_Yes\"\n",
        "}\n",
        "\n",
        "#rename Hebrew columns\n",
        "responses_df_renamed = responses_df.rename(columns=column_mapping)\n",
        "\n",
        "#align only the relevant/common columns for merging\n",
        "common_columns = list(set(data_relevant_columns.columns) & set(responses_df_renamed.columns))\n",
        "\n",
        "#subset both dataFrames\n",
        "data_eng = data_relevant_columns[common_columns]\n",
        "data_heb = responses_df_renamed[common_columns].copy()\n",
        "\n",
        "# Convert all Yes/No columns in data_heb to 1/0\n",
        "for col in data_heb.columns:\n",
        "    if data_heb[col].nunique() == 2 and set(data_heb[col].dropna().unique()) <= {\"Yes\", \"No\"}:\n",
        "        data_heb[col] = data_heb[col].map({\"Yes\": 1, \"No\": 0})\n",
        "\n",
        "#combine both datasets\n",
        "combined_df = pd.concat([data_eng, data_heb], ignore_index=True)\n",
        "\n",
        "# combined_df.count()\n",
        "combined_df.head()\n",
        "combined_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPm76bLf7vm2",
        "outputId": "870e71be-6467-4a20-9505-45a9228c49ae"
      },
      "outputs": [],
      "source": [
        "print(\"Existing English columns:\\n\", data_relevant_columns.columns.tolist())\n",
        "print(\"\\nRenamed Hebrew columns:\\n\", responses_df_renamed.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSQzr4DxH8aQ"
      },
      "source": [
        "Apply Min-Max normalization for Age column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEaeD3uVH_32"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "\n",
        "combined_df[\"What is your age ?\"] = scaler.fit_transform(\n",
        "    combined_df[[\"What is your age ?\"]]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGF-x-yEts7b"
      },
      "source": [
        "**New correlation matrix after appending the questionnaire **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dvi2BVywuFAX",
        "outputId": "4e674803-5f3a-41b7-abc7-70700c9b6e49"
      },
      "outputs": [],
      "source": [
        "combined_df = combined_df.astype({col: int for col in combined_df.columns if combined_df[col].dtype == bool})\n",
        "corr_matrix = combined_df.corr()  #compute the correlation matrix\n",
        "\n",
        "plt.figure(figsize=(15, 12))  #plot the heatmap\n",
        "sns.heatmap(\n",
        "    corr_matrix,\n",
        "    annot=True,\n",
        "    annot_kws={\"size\": 7},\n",
        "    cmap='coolwarm',\n",
        "    fmt='.2f',\n",
        "    linewidths=0.5,\n",
        "    linecolor='white',\n",
        "    cbar=True,\n",
        "    cbar_kws={'shrink': 0.8}\n",
        ")\n",
        "\n",
        "plt.title('Correlation Matrix Heatmap', fontsize=18, pad=20)\n",
        "plt.xticks(fontsize=10, rotation=45, ha='right')\n",
        "plt.yticks(fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#display table of corr with the target variable sorted from highest to lowest value\n",
        "print(\"**Table of correlation matrix values with the target variable** \\n\")\n",
        "target_variable = 'Do you have hair fall problem ?_Yes'\n",
        "correlation_with_target = combined_df.corr()[target_variable]\n",
        "print(correlation_with_target.sort_values(ascending=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpy74IN2HpeS"
      },
      "source": [
        "### ***GRAPHS ON THE FINAL DATA FRAME*** (combined_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wezEBYJdH0HS"
      },
      "source": [
        "COLUMN BOX PLOT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c_aG338Hymm",
        "outputId": "67b4a607-4d07-4691-a091-51758e351bb8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 8))\n",
        "sns.boxplot(y=combined_df['What is your age ?'])\n",
        "plt.title('Box plot of age')\n",
        "plt.ylabel('Age')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-yYMAuRLF5W"
      },
      "source": [
        "CATEGORICAL COLUMNS DISTRIBUTION GRAPH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9tv6J9sLRgw",
        "outputId": "181adaf8-cd5d-4069-827c-f9d9bd07ae6b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#binary columns (assuming all are 0/1)\n",
        "binary_cols = [col for col in combined_df.columns if set(combined_df[col].unique()).issubset({0, 1})]\n",
        "\n",
        "#plot distributions\n",
        "fig, axes = plt.subplots(nrows=len(binary_cols), figsize=(10, 4 * len(binary_cols)))\n",
        "\n",
        "if len(binary_cols) == 1:\n",
        "    axes = [axes]  #make it iterable\n",
        "\n",
        "for i, col in enumerate(binary_cols):\n",
        "    counts = combined_df[col].value_counts().sort_index()\n",
        "    axes[i].bar(['No (0)', 'Yes (1)'], counts)\n",
        "    axes[i].set_title(f'Distribution of: {col}')\n",
        "    axes[i].set_ylabel('Count')\n",
        "    axes[i].set_ylim(0, max(counts) + 10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X-532RnRzah"
      },
      "source": [
        "Gaussian Bell Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVJYcrEXRyzv",
        "outputId": "6c90493b-d014-460a-d1d2-9a9931e61858"
      },
      "outputs": [],
      "source": [
        "#set the style for the plot\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "#plot the Gaussian bell curve for the Age column\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(combined_df['What is your age ?'], kde=True, color='skyblue', bins=20)\n",
        "\n",
        "plt.title(\"Gaussian Distribution of Age\", fontsize=16)\n",
        "plt.xlabel(\"Age\", fontsize=12)\n",
        "plt.ylabel(\"Frequency\", fontsize=12)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6JLtZDMZXBI"
      },
      "source": [
        "### ***SURVEY DATASET MODEL DEVELOPMENT AND TESTING***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QRMw7ttipb8"
      },
      "source": [
        "## Table models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_RTwSpFZwcC"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "id": "vhQ1PgMNZmFi",
        "outputId": "9bffda44-c8d8-485a-aa80-ca0116fc0bf6"
      },
      "outputs": [],
      "source": [
        "# prompt: I want tio run logistic regression on my data frame combined_df\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = combined_df.drop('Do you have hair fall problem ?_Yes', axis=1)\n",
        "y = combined_df['Do you have hair fall problem ?_Yes']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "lr_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {lr_accuracy}\")\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Predicted No', 'Predicted Yes'],\n",
        "            yticklabels=['Actual No', 'Actual Yes'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3vn4jNlRN2y"
      },
      "source": [
        "logistic regression with grid search cv library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "id": "9mnkCkejRTvE",
        "outputId": "53d03e36-a198-4e76-ebfd-865352166f4f"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = combined_df.drop('Do you have hair fall problem ?_Yes', axis=1)\n",
        "y = combined_df['Do you have hair fall problem ?_Yes']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l2'],\n",
        "    'solver': ['lbfgs', 'liblinear']\n",
        "}\n",
        "\n",
        "# Initialize model\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Run GridSearchCV\n",
        "grid = GridSearchCV(lr, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Best estimator\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "lr_accuracy_cv = accuracy_score(y_test, y_pred)\n",
        "print(f\"Best Parameters: {grid.best_params_}\")\n",
        "print(f\"Accuracy: {lr_accuracy_cv}\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Predicted No', 'Predicted Yes'],\n",
        "            yticklabels=['Actual No', 'Actual Yes'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHglpK_oeTJz"
      },
      "source": [
        "**K-Nearest Neighbors (KNN)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KjDq2y_Qen9Z",
        "outputId": "c1609747-7a9a-409c-8d91-f09dcc2f9224"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# --- Elbow method for K ---\n",
        "error_rates = []\n",
        "\n",
        "# Try K values from 1 to 20\n",
        "for k in range(1, 21):\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    pred_k = knn.predict(X_test)\n",
        "    error = 1 - accuracy_score(y_test, pred_k)  # error = 1 - accuracy\n",
        "    error_rates.append(error)\n",
        "\n",
        "# Plot the Elbow Graph\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, 21), error_rates, marker='o')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.xlabel('Number of Neighbors (k)')\n",
        "plt.ylabel('Error Rate (1 - Accuracy)')\n",
        "plt.xticks(range(1, 21))\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# --- Your original KNN Model ---\n",
        "# Initialize and train the KNN model\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)  #5 is the ideal result\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "knn_y_pred = knn_model.predict(X_test)\n",
        "\n",
        "# Evaluate the KNN model\n",
        "knn_accuracy = accuracy_score(y_test, knn_y_pred)\n",
        "print(f\"KNN Accuracy: {knn_accuracy:.4f}\")\n",
        "\n",
        "print(classification_report(y_test, knn_y_pred))\n",
        "\n",
        "# Confusion matrix for KNN\n",
        "knn_cm = confusion_matrix(y_test, knn_y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(knn_cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Predicted No', 'Predicted Yes'],\n",
        "            yticklabels=['Actual No', 'Actual Yes'])\n",
        "plt.title('KNN Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJqsjm9dU37V"
      },
      "source": [
        "KNN with grid search cv library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dk9uyrPmU6-X",
        "outputId": "706e3b1e-cd45-4e9b-d2bb-ca366c3db772"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# --- Elbow method for K ---\n",
        "error_rates = []\n",
        "\n",
        "# Try K values from 1 to 20\n",
        "for k in range(1, 21):\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    pred_k = knn.predict(X_test)\n",
        "    error = 1 - accuracy_score(y_test, pred_k)\n",
        "    error_rates.append(error)\n",
        "\n",
        "# Plot the Elbow Graph\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, 21), error_rates, marker='o')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.xlabel('Number of Neighbors (k)')\n",
        "plt.ylabel('Error Rate (1 - Accuracy)')\n",
        "plt.xticks(range(1, 21))\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# --- GridSearchCV to find best k ---\n",
        "param_grid = {'n_neighbors': list(range(1, 21))}\n",
        "\n",
        "grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_knn.fit(X_train, y_train)\n",
        "\n",
        "# Best KNN model\n",
        "best_knn = grid_knn.best_estimator_\n",
        "\n",
        "# Make predictions\n",
        "knn_y_pred = best_knn.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "knn_accuracy_cv = accuracy_score(y_test, knn_y_pred)\n",
        "print(f\"Best Parameters: {grid_knn.best_params_}\")\n",
        "print(f\"KNN Accuracy: {knn_accuracy_cv:.4f}\")\n",
        "print(classification_report(y_test, knn_y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "knn_cm = confusion_matrix(y_test, knn_y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(knn_cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Predicted No', 'Predicted Yes'],\n",
        "            yticklabels=['Actual No', 'Actual Yes'])\n",
        "plt.title('KNN Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN4K4Emli0Q8"
      },
      "source": [
        "**Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "id": "n0RfG5O9fPk5",
        "outputId": "2cc26142-8f23-442d-ebe4-69e148498643"
      },
      "outputs": [],
      "source": [
        "# prompt: run Random Forest on combined_df\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Assuming combined_df is already defined and preprocessed as in your code\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = combined_df.drop('Do you have hair fall problem ?_Yes', axis=1)\n",
        "y = combined_df['Do you have hair fall problem ?_Yes']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(random_state=42)  # You can adjust hyperparameters here\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "rf_y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the Random Forest model\n",
        "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
        "\n",
        "print(classification_report(y_test, rf_y_pred))\n",
        "\n",
        "# Confusion matrix for Random Forest\n",
        "rf_cm = confusion_matrix(y_test, rf_y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(rf_cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Predicted No', 'Predicted Yes'],\n",
        "            yticklabels=['Actual No', 'Actual Yes'])\n",
        "plt.title('Random Forest Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXXumZqpYAel"
      },
      "source": [
        "random forest with grid search cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "id": "No0ybQkgYFlh",
        "outputId": "9eadf95f-7904-48c5-f6fd-a3709003c2f1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = combined_df.drop('Do you have hair fall problem ?_Yes', axis=1)\n",
        "y = combined_df['Do you have hair fall problem ?_Yes']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Set up parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "# Grid search setup\n",
        "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_rf = grid_rf.best_estimator_\n",
        "\n",
        "# Predict on test set\n",
        "rf_y_pred = best_rf.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "rf_accuracy_cv = accuracy_score(y_test, rf_y_pred)\n",
        "print(f\"Best Parameters: {grid_rf.best_params_}\")\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy_cv:.4f}\")\n",
        "print(classification_report(y_test, rf_y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "rf_cm = confusion_matrix(y_test, rf_y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(rf_cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Predicted No', 'Predicted Yes'],\n",
        "            yticklabels=['Actual No', 'Actual Yes'])\n",
        "plt.title('Random Forest Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb1lw5kv_KLm"
      },
      "source": [
        "**XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "id": "6gNJnb--_ycI",
        "outputId": "ed3fb2ec-ee32-4b03-ab7f-e97d9055770a"
      },
      "outputs": [],
      "source": [
        "# prompt: run XGBoost for combined_df\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ... (Your existing code for data loading and preprocessing) ...\n",
        "\n",
        "# Assuming combined_df is already defined and preprocessed\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = combined_df.drop('Do you have hair fall problem ?_Yes', axis=1)\n",
        "y = combined_df['Do you have hair fall problem ?_Yes']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the XGBoost model\n",
        "xgb_model = xgb.XGBClassifier(random_state=42)  # You can adjust hyperparameters here\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "xgb_y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the XGBoost model\n",
        "xgb_accuracy = accuracy_score(y_test, xgb_y_pred)\n",
        "print(f\"XGBoost Accuracy: {xgb_accuracy:.4f}\")\n",
        "\n",
        "print(classification_report(y_test, xgb_y_pred))\n",
        "\n",
        "# Confusion matrix for XGBoost\n",
        "xgb_cm = confusion_matrix(y_test, xgb_y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(xgb_cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Predicted No', 'Predicted Yes'],\n",
        "            yticklabels=['Actual No', 'Actual Yes'])\n",
        "plt.title('XGBoost Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181,
          "referenced_widgets": [
            "8f51dfd864f047fd853aaf71c8b8b9c9",
            "889049e5296d401db5e560f655db7d84",
            "4577b88358c6428d9b885ff4d4473fbe",
            "3b83dd45ad50474db2a55781ab3ed6dc",
            "6897d611d0cc4fa7aa77a8b4edeacfb6",
            "81f43482b6da437bad87273c5f02a605",
            "c269acba95f14cc68f0f6f9f34f9fd65",
            "80bbe663222945e4b4c111a827768706",
            "ff04c5a4b313492fb8a73edcafc8bbd0",
            "38acfd388a01439e95563ce2c20c8817",
            "ee0b778744f44c5c945a9cd12093d417",
            "2182b4a8a36848c4a07c76dd4a64375c",
            "8b18ce183ba14899b577237d2f4deb3d",
            "57c5e0fbed7049e19d6dda3fb7f969bd",
            "7e899251cecf4434b982ad0cc9f3e9d8",
            "8a0ccff7a68f42d2a8b0895b6345f27a",
            "b2d9ac97db4f42eba4f3edd3b3ff86a0",
            "ed4133ab62e240e182b219d673a3cea3",
            "3aeaa9070cb944328e40a401e202fd82",
            "aeb6df19b6ca4f34b2bbf6caa7781389",
            "ef3238bd31c14610b8c8ef41a2cd19af",
            "8621c495aebd4ae0990a5bd3e923848b",
            "c7cb5cdb156041c6af54d42741fb9fc0",
            "47346fb4ba0549188b2e055e259c0028",
            "69293defbd3f4ebe9eaaad8cf5036e83",
            "214fae346aa84eccbe5882afb1ab0656",
            "db4f5dc54fb143259f864063aa395f71",
            "dde7a5d4cbb5453bad8e378b884e5ff2",
            "668e1bf5c63b48dea17668e8527b7a1b",
            "95f5c85401f04244a68de18631faf3f3",
            "4bf5e3471d6c40caab3efa70e2431df2",
            "88b49ffcd25b491b90d99a6798fb982c",
            "589abc95558142358648d600f6076fa1",
            "52d34ac9915745999cd22f7c949cac41",
            "ec2dde35edcd493da530f38666ffec6b",
            "e3790aa0fa274b23a77f1dcf9b1fe7fb",
            "4aef77b59273487d825a4fb902fa48ec",
            "419a5d37336741c681c2a0d5349fc5f5",
            "3e78b7b26f1647c082d96b113cccde69",
            "46da16e43ae74180b6df3d6829952188",
            "0062a4b023cd4fc89551df4277e408e3",
            "83ee1354ed6e4615bd08c5bebe4e51d4",
            "4f2b0b09ccc3441988a4b9cee2a4dd81",
            "bd7c556a21ae42c0b24b6134fd98ea7c",
            "9b4f231b24b84db2b13490a6d1d4f9b7",
            "b9179123006f440489e33dd2f882fe38",
            "548a58207d7e4d74bd74a055e4f057af",
            "c4726b45a1a84b36a23b392bb8cfad35",
            "669d36403fd54984bcd9bd4039f216a8",
            "41a299d1894c46fa88fa30c19a222a8d",
            "452ee95e0dc64736b762f5cfef2966c2",
            "9acda40993d04dc8ac4735e0107786ac",
            "6bda8817a0b94105a5499e64158b78d3",
            "ee83aa1c7e5c446b9027cc1d0ab2ac8c",
            "6ecd0d90495f4a26a08cc9651ef35976",
            "3a708d93f1524597a1a8758ca415451f",
            "2f2e2fc7ef54461a85fb619098a08c05",
            "14d46328fe9f498b983e0367b7242603",
            "c8ad759bf4d2490b85a55e28ccbbc38e",
            "1af501bb411e4e67a4c64c8d9e92a0a9",
            "86342a28207043d080259f190aac52c2",
            "695ca5ac9e92423183b4eca35a3b073f",
            "11cd1c591d63426a819c4a3d00e0520c",
            "dfae06417a5b4e6197cb25dbeb19e9fc"
          ]
        },
        "id": "3n9YKpZ_mx_k",
        "outputId": "a0ecd80e-1241-4ad2-ea9c-76534ddf3795"
      },
      "outputs": [],
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# Upload trained XGBoost model and metadata to Hugging Face\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "!pip install --quiet huggingface_hub joblib\n",
        "\n",
        "from huggingface_hub import login, create_repo, upload_folder\n",
        "import json\n",
        "import joblib\n",
        "\n",
        "# (A) Login with your token (only once per session)\n",
        "login()  # Paste your Hugging Face token when prompted\n",
        "\n",
        "# (B) Set repo name\n",
        "hf_username = \"alamb98\"  # ğŸ” Your HF username\n",
        "MODEL_NAME = \"xgboost_hair_fall_classifier\"\n",
        "repo_id = f\"{hf_username}/{MODEL_NAME}\"\n",
        "\n",
        "# (C) Create or use existing repo\n",
        "create_repo(repo_id, repo_type=\"model\", exist_ok=True)\n",
        "\n",
        "# (D) Save model and metadata\n",
        "model_path = f\"{MODEL_NAME}.joblib\"\n",
        "joblib.dump(xgb_model, model_path)\n",
        "\n",
        "metadata = {\n",
        "    \"model_name\": MODEL_NAME,\n",
        "    \"model_type\": \"XGBoost\",\n",
        "    \"framework\": \"scikit-learn + xgboost\",\n",
        "    \"input_features\": list(X.columns),\n",
        "    \"target_label\": \"Do you have hair fall problem ?_Yes\",\n",
        "    \"test_accuracy\": round(float(xgb_accuracy), 4),\n",
        "    \"description\": \"XGBoost classifier predicting hair fall presence based on combined tabular dataset.\"\n",
        "}\n",
        "with open(\"metadata.json\", \"w\") as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "# (E) Upload both model and metadata.json\n",
        "upload_folder(\n",
        "    folder_path=\".\",\n",
        "    repo_id=repo_id,\n",
        "    repo_type=\"model\",\n",
        "    allow_patterns=[model_path, \"metadata.json\"]\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ… Uploaded to: https://huggingface.co/{repo_id}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS80xRahSV3o"
      },
      "source": [
        "xgboost with grid search cv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "id": "mSVBFiPIR2Jo",
        "outputId": "89c58755-201b-4ae7-9a7b-6ca4734806b6"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Prepare the data\n",
        "X = combined_df.drop('Do you have hair fall problem ?_Yes', axis=1)\n",
        "y = combined_df['Do you have hair fall problem ?_Yes']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define parameter grid for tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.3]\n",
        "}\n",
        "\n",
        "# Initialize the model\n",
        "xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "\n",
        "# Perform grid search\n",
        "grid_xgb = GridSearchCV(xgb_clf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_xgb.fit(X_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_xgb = grid_xgb.best_estimator_\n",
        "\n",
        "# Predict\n",
        "y_pred = best_xgb.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Best Parameters: {grid_xgb.best_params_}\")\n",
        "print(f\"XGBoost Accuracy: {accuracy:.4f}\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Predicted No', 'Predicted Yes'],\n",
        "            yticklabels=['Actual No', 'Actual Yes'])\n",
        "plt.title('XGBoost Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oQI48KRBbPh"
      },
      "source": [
        "**Weighted KNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FBpf9-uuBgfk",
        "outputId": "871e0125-351f-444c-d1f3-da9731564362"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = combined_df.drop('Do you have hair fall problem ?_Yes', axis=1)\n",
        "y = combined_df['Do you have hair fall problem ?_Yes']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Elbow method for Weighted KNN ---\n",
        "error_rates = []\n",
        "\n",
        "# Try K values from 1 to 20\n",
        "for k in range(1, 21):\n",
        "    weighted_knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
        "    weighted_knn.fit(X_train, y_train)\n",
        "    pred_k = weighted_knn.predict(X_test)\n",
        "    error = 1 - accuracy_score(y_test, pred_k)\n",
        "    error_rates.append(error)\n",
        "\n",
        "# Plot the Elbow Graph\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, 21), error_rates, marker='o')\n",
        "plt.title('Elbow Method For Optimal k (Weighted KNN)')\n",
        "plt.xlabel('Number of Neighbors (k)')\n",
        "plt.ylabel('Error Rate (1 - Accuracy)')\n",
        "plt.xticks(range(1, 21))\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# --- Your original Weighted KNN Model ---\n",
        "# Initialize and train the Weighted KNN model\n",
        "weighted_knn = KNeighborsClassifier(n_neighbors=1, weights='distance')  # Adjust k based on elbow result\n",
        "weighted_knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "weighted_knn_pred = weighted_knn.predict(X_test)\n",
        "\n",
        "# Evaluate the Weighted KNN model\n",
        "weighted_knn_accuracy = accuracy_score(y_test, weighted_knn_pred)\n",
        "print(f\"Weighted KNN Accuracy: {weighted_knn_accuracy:.4f}\")\n",
        "\n",
        "print(classification_report(y_test, weighted_knn_pred))\n",
        "\n",
        "# Confusion matrix for Weighted KNN\n",
        "weighted_knn_cm = confusion_matrix(y_test, weighted_knn_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(weighted_knn_cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Predicted No', 'Predicted Yes'],\n",
        "            yticklabels=['Actual No', 'Actual Yes'])\n",
        "plt.title('Weighted KNN Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWa5hNJOEpcm"
      },
      "source": [
        "#### **Models accuracy comparsion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ldLV3R4GZf4",
        "outputId": "72135576-fadf-4da5-a2fa-f18170def1a3"
      },
      "outputs": [],
      "source": [
        "# prompt: just print the accuracy of each model in the recent blocks\n",
        "\n",
        "print(f\"Logistic Regression Accuracy: {lr_accuracy}\")\n",
        "print(f\"Logistic Regression CV Accuracy: {lr_accuracy_cv}\")\n",
        "print(f\"KNN Accuracy: {knn_accuracy}\")\n",
        "print(f\"KNN CV Accuracy: {knn_accuracy_cv}\")\n",
        "print(f\"Random Forest Accuracy: {rf_accuracy}\")\n",
        "print(f\"Random Forest CV Accuracy: {rf_accuracy_cv}\")\n",
        "print(f\"XGBoost Accuracy: {xgb_accuracy}\")\n",
        "print(f\"Weighted KNN Accuracy: {weighted_knn_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "yoQcF59aGjrZ",
        "outputId": "3e5a6dc5-ade9-46c0-a424-b44eaa49967f"
      },
      "outputs": [],
      "source": [
        "# prompt: print a bar chart comparing them\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Accuracy scores (replace with your actual values)\n",
        "models = ['Logistic Regression', 'Logistic Regression CV', 'KNN', 'KNN CV', 'Random Forest', 'Random Forest CV', 'XGBoost', 'Weighted KNN']\n",
        "accuracy_scores = [lr_accuracy, lr_accuracy_cv, knn_accuracy, knn_accuracy_cv, rf_accuracy, rf_accuracy_cv, xgb_accuracy, weighted_knn_accuracy]\n",
        "\n",
        "# Create the bar chart\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(models, accuracy_scores, color='skyblue')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel(\"Models\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Comparison of Model Accuracies\")\n",
        "plt.xticks(rotation=45, ha='right') # Rotate x-axis labels for better readability\n",
        "\n",
        "# Add value annotations to each bar\n",
        "for i, v in enumerate(accuracy_scores):\n",
        "    plt.text(i, v + 0.01, str(round(v, 4)), ha='center')\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVpDLrICjm6K"
      },
      "source": [
        "## Images Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jytXzhxk70c"
      },
      "source": [
        "**Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRRa2DT9k-nz",
        "outputId": "c1619ea8-5235-462b-9494-83f03ad7e984"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Input root directory (original dataset)\n",
        "#root_dir = \"C:/Users/Ryan/Desktop/hair fall images\"  # change as needed\n",
        "root_dir = \"/content/hyehye2.v3i.folder 2.zip\"\n",
        "# Resize settings\n",
        "target_size = (224, 224)\n",
        "\n",
        "# Loop through train, valid, test folders\n",
        "for split in ['train', 'valid', 'test']:\n",
        "    split_path = os.path.join(root_dir, split)\n",
        "    if not os.path.exists(split_path):\n",
        "        continue\n",
        "\n",
        "    # Go through each level folder (level 2 to level 7)\n",
        "    for level in os.listdir(split_path):\n",
        "        level_path = os.path.join(split_path, level)\n",
        "\n",
        "        if not os.path.isdir(level_path):\n",
        "            continue\n",
        "\n",
        "        # Resize each image\n",
        "        for img_file in os.listdir(level_path):\n",
        "            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                img_path = os.path.join(level_path, img_file)\n",
        "                try:\n",
        "                    img = Image.open(img_path).convert(\"RGB\")\n",
        "                    img = img.resize(target_size)\n",
        "                    img.save(img_path)  # Overwrites original\n",
        "                except Exception as e:\n",
        "                    print(f\"âš ï¸ Error processing {img_path}: {e}\")\n",
        "\n",
        "print(\"âœ… All images resized successfully to 224x224.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZCou-4f-ldCB",
        "outputId": "5971f998-60ac-459d-f0b9-b1bc3201dd8e"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pRWrxw6jrwG"
      },
      "source": [
        "**ResNet50**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "1j--nfb5jxwp",
        "outputId": "bba2fc27-0f92-4d85-8f26-cca22bbb2a14"
      },
      "outputs": [],
      "source": [
        "# TensorFlow-Mac optimized version to load scalp images and run ResNet50 fine-tuning\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import zipfile, os, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
        "\n",
        "\n",
        "# 1. Unzip the dataset if needed\n",
        "zip_file_path = \"/content/hyehye2.v3i.folder 2.zip\"\n",
        "extract_path  = \"/content/extracted_images\"\n",
        "\n",
        "if not os.path.exists(extract_path):\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "# 2. Discover the actual data root (skip __MACOSX)\n",
        "data_root = None\n",
        "for sub in os.listdir(extract_path):\n",
        "    if sub == \"__MACOSX\":\n",
        "        continue\n",
        "    candidate = os.path.join(extract_path, sub)\n",
        "    if os.path.isdir(candidate) and \"train\" in os.listdir(candidate):\n",
        "        data_root = candidate\n",
        "        break\n",
        "\n",
        "if data_root is None:\n",
        "    raise FileNotFoundError(\"Could not find a folder containing 'train' under extracted_images\")\n",
        "\n",
        "# 3. Set image dimensions and directories\n",
        "img_size   = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "train_dir = os.path.join(data_root, \"train\")\n",
        "valid_dir = os.path.join(data_root, \"valid\")\n",
        "test_dir  = os.path.join(data_root, \"test\")\n",
        "\n",
        "print(\"Using directories:\")\n",
        "print(\" TRAIN:\", train_dir)\n",
        "print(\" VALID:\", valid_dir)\n",
        "print(\" TEST: \", test_dir)\n",
        "\n",
        "# 4. Use ImageDataGenerator to load images (with proper ResNet preprocessing)\n",
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "test_datagen  = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical'\n",
        ")\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    valid_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical'\n",
        ")\n",
        "test_generator  = test_datagen.flow_from_directory(\n",
        "    test_dir,  target_size=img_size, batch_size=batch_size,\n",
        "    class_mode='categorical', shuffle=False\n",
        ")\n",
        "\n",
        "# 5. Load ResNet50 base\n",
        "base_model = ResNet50(\n",
        "    weights='imagenet', include_top=False, input_shape=(img_size[0], img_size[1], 3)\n",
        ")\n",
        "\n",
        "# 6. Add custom layers on top\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# 7. Freeze ResNet50 layers for initial training\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 8. Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 9. Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    epochs=5  # bump this up when youâ€™re happy with the pipeline\n",
        ")\n",
        "\n",
        "# 10. Evaluate on test set\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_generator.classes\n",
        "\n",
        "print(classification_report(\n",
        "    y_true, y_pred_classes,\n",
        "    target_names=list(test_generator.class_indices.keys())\n",
        "))\n",
        "\n",
        "# 11. Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(\n",
        "    cm, annot=True, fmt='d', cmap='Blues',\n",
        "    xticklabels=test_generator.class_indices.keys(),\n",
        "    yticklabels=test_generator.class_indices.keys()\n",
        ")\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I87V9LzCjwip"
      },
      "source": [
        "**MobileNet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrbgPv65nYUd"
      },
      "outputs": [],
      "source": [
        "# prompt: extract the hair fall images.zip\n",
        "\n",
        "import zipfile\n",
        "\n",
        "# Replace 'hair fall images.zip' with the actual filename if different\n",
        "with zipfile.ZipFile('/content/hair fall images (2).zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('hair_fall_images_extracted') # Specify the extraction directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ACTzOuTkjyIg",
        "outputId": "b5aae762-2a66-429b-ba7a-163670253755"
      },
      "outputs": [],
      "source": [
        "# prompt: generate code for mobile net model same as other models that we already made\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, f1_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define image dimensions and batch size\n",
        "img_width, img_height = 224, 224\n",
        "batch_size = 32\n",
        "\n",
        "# Create data generators for training, validation, and test data\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory('/content/hair_fall_images_extracted/hair fall images/train',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory('/content/hair_fall_images_extracted/hair fall images/valid',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "test_generator = val_datagen.flow_from_directory('/content/hair_fall_images_extracted/hair fall images/test',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False)\n",
        "\n",
        "# Load pre-trained MobileNet model (excluding the top classification layer)\n",
        "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "\n",
        "# Add custom classification layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size)\n",
        "\n",
        "# Evaluate on validation set\n",
        "mobilenet_val_loss, mobilenet_val_accuracy = model.evaluate(validation_generator, steps=validation_generator.samples // batch_size)\n",
        "print(f\"\\nValidation Loss: {mobilenet_val_loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {mobilenet_val_accuracy:.4f}\")\n",
        "\n",
        "# Save the model\n",
        "model.save('mobilenet_hairfall.h5')\n",
        "\n",
        "# Reload the model (optional)\n",
        "model = tf.keras.models.load_model('mobilenet_hairfall.h5')\n",
        "\n",
        "# Evaluate on test set\n",
        "mobilenet_test_loss, mobilenet_test_accuracy = model.evaluate(test_generator, steps=int(np.ceil(test_generator.samples / batch_size)))\n",
        "print(f\"\\nTest Loss: {mobilenet_test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {mobilenet_test_accuracy:.4f}\")\n",
        "\n",
        "# Predict on test set\n",
        "Y_test_pred = model.predict(test_generator, steps=int(np.ceil(test_generator.samples / batch_size)))\n",
        "y_test_pred = np.argmax(Y_test_pred, axis=1)\n",
        "y_test_true = test_generator.classes\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test_true, y_test_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_generator.class_indices.keys())\n",
        "disp.plot(cmap='Blues', xticks_rotation=45)\n",
        "plt.title(\"Test Set Confusion Matrix\")\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "report = classification_report(y_test_true, y_test_pred, target_names=class_labels)\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(report)\n",
        "\n",
        "# total f1 score\n",
        "f1_macro = f1_score(y_test_true, y_test_pred, average='macro')\n",
        "f1_weighted = f1_score(y_test_true, y_test_pred, average='weighted')\n",
        "\n",
        "print(f\"Macro F1-score: {f1_macro:.4f}\")\n",
        "print(f\"Weighted F1-score: {f1_weighted:.4f}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLIO2GLLWE_R"
      },
      "outputs": [],
      "source": [
        "              precision    recall  f1-score   support\n",
        "\n",
        "     Level 2       0.81      0.70      0.75        30\n",
        "     Level 3       0.24      0.28      0.26        18\n",
        "     Level 4       0.48      0.50      0.49        22\n",
        "     Level 5       0.55      0.43      0.48        14\n",
        "     Level 6       0.45      0.62      0.53         8\n",
        "     Level 7       0.57      0.57      0.57         7\n",
        "\n",
        "    accuracy                           0.53        99\n",
        "   macro avg       0.52      0.52      0.51        99\n",
        "weighted avg       0.55      0.53      0.53        99\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XVVqe15WJD6"
      },
      "source": [
        "              precision    recall  f1-score   support\n",
        "\n",
        "     Level 2       0.81      0.70      0.75        30\n",
        "     Level 3       0.24      0.28      0.26        18\n",
        "     Level 4       0.48      0.50      0.49        22\n",
        "     Level 5       0.55      0.43      0.48        14\n",
        "     Level 6       0.45      0.62      0.53         8\n",
        "     Level 7       0.57      0.57      0.57         7\n",
        "\n",
        "    accuracy                           0.53        99\n",
        "   macro avg       0.52      0.52      0.51        99\n",
        "weighted avg       0.55      0.53      0.53        99\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYtx9NIGC66r"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z03y6ZajCz5b"
      },
      "source": [
        "**MobileNet improved**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjP7IDnMC2j1",
        "outputId": "1a2b372a-6870-4b5e-a4a0-41290cc166ad"
      },
      "outputs": [],
      "source": [
        "# Colab | Full pipeline with background removal + zoom/flip augmentations + MobileNet\n",
        "\n",
        "# 0. Install OpenCV\n",
        "!pip install opencv-python-headless --quiet\n",
        "\n",
        "# 1. Imports\n",
        "import zipfile, os, shutil\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "\n",
        "\n",
        "# 2. Edit these to match exactly what you see above:\n",
        "ZIP_FILE_PATH = \"/content/hyehye2.v3i.folder 2.zip\"  # must match `!ls` output\n",
        "EXTRACT_DIR   = \"/content/extracted_images\"\n",
        "\n",
        "# 3. If it's already a folder, skip unzip:\n",
        "if os.path.isdir(ZIP_FILE_PATH):\n",
        "    print(f\"ğŸ“‚ {ZIP_FILE_PATH} is already a folder â†’ using it directly\")\n",
        "    EXTRACT_DIR = ZIP_FILE_PATH\n",
        "\n",
        "# 4. Else if itâ€™s a zipfile, extract it:\n",
        "elif zipfile.is_zipfile(ZIP_FILE_PATH):\n",
        "    print(f\"ğŸ“¦ Extracting {ZIP_FILE_PATH} â†’ {EXTRACT_DIR}\")\n",
        "    with zipfile.ZipFile(ZIP_FILE_PATH, \"r\") as z:\n",
        "        z.extractall(EXTRACT_DIR)\n",
        "    print(\"âœ… Extraction complete\")\n",
        "else:\n",
        "    raise FileNotFoundError(\n",
        "        f\"âŒ Could not find a valid zip at {ZIP_FILE_PATH}. \"\n",
        "        \"Please double-check the filename and path shown by `!ls /content`.\"\n",
        "    )\n",
        "\n",
        "\n",
        "# 4. Backgroundâ€removal function using GrabCut\n",
        "def remove_background(src_path, dst_path):\n",
        "    img = cv2.imread(src_path)\n",
        "    if img is None:\n",
        "        print(f\"âš ï¸  Skipping (cannot load): {src_path}\")\n",
        "        return\n",
        "    mask = np.zeros(img.shape[:2], np.uint8)\n",
        "    h, w = mask.shape\n",
        "    rect = (int(w*0.1), int(h*0.1), int(w*0.8), int(h*0.8))\n",
        "    bgd_model = np.zeros((1,65),np.float64)\n",
        "    fgd_model = np.zeros((1,65),np.float64)\n",
        "    cv2.grabCut(img, mask, rect, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_RECT)\n",
        "    mask2 = np.where((mask==2)|(mask==0), 0, 1).astype('uint8')\n",
        "    img_nobg = img * mask2[:, :, np.newaxis]\n",
        "    cv2.imwrite(dst_path, img_nobg)\n",
        "\n",
        "print(\"âœ… Background removal function is ready.\")\n",
        "\n",
        "# 5. Process every image folder structure\n",
        "if os.path.exists(PROC_DIR):\n",
        "    shutil.rmtree(PROC_DIR)\n",
        "shutil.copytree(EXTRACT_DIR, PROC_DIR)\n",
        "\n",
        "for root, _, files in os.walk(PROC_DIR):\n",
        "    for fname in files:\n",
        "        if fname.lower().endswith((\"jpg\",\"jpeg\",\"png\")):\n",
        "            src = os.path.join(root, fname)\n",
        "            remove_background(src, src)  # now safe to skip unreadable images\n",
        "\n",
        "print(\"âœ… Background removal complete.\")\n",
        "\n",
        "# 6. Data generators with zoom + flip\n",
        "img_size   = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    os.path.join(PROC_DIR, \"train\"),\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    os.path.join(PROC_DIR, \"valid\"),\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "test_gen = val_datagen.flow_from_directory(\n",
        "    os.path.join(PROC_DIR, \"test\"),\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "print(\"Data generators with zoom + flip are finished\")\n",
        "\n",
        "# 7. Build MobileNet + custom head\n",
        "base = MobileNet(weights='imagenet', include_top=False, input_shape=img_size + (3,))\n",
        "x    = GlobalAveragePooling2D()(base.output)\n",
        "x    = Dense(1024, activation='relu')(x)\n",
        "out  = Dense(train_gen.num_classes, activation='softmax')(x)\n",
        "model = Model(base.input, out)\n",
        "\n",
        "# freeze base\n",
        "for layer in base.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(1e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "print(\"Build MobileNet + custom head is finished\")\n",
        "\n",
        "# 8. Train\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=10,\n",
        "    validation_data=val_gen\n",
        ")\n",
        "print(\"Training is finished\")\n",
        "\n",
        "# 9. Evaluate on test\n",
        "test_loss, test_acc = model.evaluate(test_gen, steps=int(np.ceil(test_gen.samples / batch_size)))\n",
        "print(f\"\\nTest accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# 10. Confusion matrix & report\n",
        "y_pred          = model.predict(test_gen, steps=int(np.ceil(test_gen.samples / batch_size)))\n",
        "y_pred_classes  = np.argmax(y_pred, axis=1)\n",
        "y_true          = test_gen.classes\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes, target_names=list(test_gen.class_indices.keys())))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(test_gen.class_indices.keys()))\n",
        "disp.plot(cmap='Blues', xticks_rotation=45)\n",
        "plt.title(\"MobileNet Test Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT971PcHYAlq"
      },
      "source": [
        "**VGG16**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "y2CZAxdtYDIL",
        "outputId": "0b6a4c46-53dd-4fb5-c8c4-e15e2be25340"
      },
      "outputs": [],
      "source": [
        "# prompt: I want to run now VGG16 on the zip file containing the images in \"hyehye2.v3i.folder 2.zip\", this folder has train, valid, test folders and each has subfolders titled 2-7, each representing a different male pattern baldness stage. i WANT TO TEACH THE MODEL TO IDENTIFY EACH STAGE\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# ... (Your existing code for data loading and preprocessing) ...\n",
        "\n",
        "# 1. Set image dimensions and directories (same as ResNet50)\n",
        "img_size   = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# ... (Your existing code to define train_dir, valid_dir, test_dir) ...\n",
        "\n",
        "\n",
        "# 2. Use ImageDataGenerator (with VGG16 preprocessing)\n",
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "test_datagen  = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical'\n",
        ")\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    valid_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical'\n",
        ")\n",
        "test_generator  = test_datagen.flow_from_directory(\n",
        "    test_dir,  target_size=img_size, batch_size=batch_size,\n",
        "    class_mode='categorical', shuffle=False\n",
        ")\n",
        "\n",
        "# 3. Load VGG16 base model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_size[0], img_size[1], 3))\n",
        "\n",
        "# 4. Add custom classification layers\n",
        "x = base_model.output\n",
        "x = Flatten()(x)  # Flatten the output of VGG16\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# 5. Freeze base model layers (optional)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 6. Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 7. Train the model\n",
        "history = model.fit(train_generator, validation_data=valid_generator, epochs=10) # Adjust epochs as needed\n",
        "\n",
        "# 8. Evaluate on test set\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = test_generator.classes\n",
        "\n",
        "print(classification_report(y_true, y_pred_classes, target_names=list(test_generator.class_indices.keys())))\n",
        "\n",
        "# 9. Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDiIArqAjyai"
      },
      "source": [
        "**Custom CNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k_uvXdxcjzKQ",
        "outputId": "f1fe1d80-059e-4c8e-c0d1-7c07a38a2e10"
      },
      "outputs": [],
      "source": [
        "# prompt: generate code for custom cnn model with the hair_fall_images_extracted\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define image dimensions and batch size\n",
        "img_width, img_height = 224, 224\n",
        "batch_size = 32\n",
        "\n",
        "# Data generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory('/content/hair_fall_images_extracted/hair fall images/train',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory('/content/hair_fall_images_extracted/hair fall images/valid',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "test_generator = val_datagen.flow_from_directory('/content/hair_fall_images_extracted/hair fall images/test',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator\n",
        ")\n",
        "\n",
        "# Evaluate on validation set\n",
        "cnn_val_loss, cnn_val_accuracy = model.evaluate(validation_generator)\n",
        "print(f\"\\nValidation Loss: {cnn_val_loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {cnn_val_accuracy:.4f}\")\n",
        "\n",
        "# Save the model\n",
        "model.save('custom_cnn_hairfall.h5')\n",
        "\n",
        "# Reload the model\n",
        "model = tf.keras.models.load_model('custom_cnn_hairfall.h5')\n",
        "\n",
        "# Evaluate on test set\n",
        "cnn_test_loss, cnn_test_accuracy = model.evaluate(test_generator, steps=int(np.ceil(test_generator.samples / batch_size)))\n",
        "print(f\"\\nTest Loss: {cnn_test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {cnn_test_accuracy:.4f}\")\n",
        "\n",
        "# Predict on test data\n",
        "Y_test_pred = model.predict(test_generator, steps=int(np.ceil(test_generator.samples / batch_size)))\n",
        "y_test_pred = np.argmax(Y_test_pred, axis=1)\n",
        "y_test_true = test_generator.classes\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test_true, y_test_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_generator.class_indices.keys())\n",
        "disp.plot(cmap='Blues', xticks_rotation=45)\n",
        "plt.title(\"Test Set Confusion Matrix\")\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "report = classification_report(y_test_true, y_test_pred, target_names=class_labels)\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(report)\n",
        "\n",
        "# total f1 score\n",
        "f1_macro = f1_score(y_test_true, y_test_pred, average='macro')\n",
        "f1_weighted = f1_score(y_test_true, y_test_pred, average='weighted')\n",
        "\n",
        "print(f\"Macro F1-score: {f1_macro:.4f}\")\n",
        "print(f\"Weighted F1-score: {f1_weighted:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6470OvJKy9y"
      },
      "outputs": [],
      "source": [
        "print(f\"MobileNet Validation Accuracy: {round(mobilenet_val_accuracy,4)}\")\n",
        "print(f\"MobileNet test Accuracy: {round(mobilenet_test_accuracy,4)}\")\n",
        "print(f\"Custom CNN Validation Accuracy: {round(cnn_val_accuracy,4)}\")\n",
        "print(f\"Custom CNN Validation Accuracy: {round(cnn_test_accuracy,4)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "jVc72W0TVd-G",
        "outputId": "ef19241d-e4d9-46a8-f5a7-6d6094de6249"
      },
      "outputs": [],
      "source": [
        "# prompt: i want a bar chart graph comparing the accuracy of the image models in the code blocks above (ResNet50, MobileNet, Custom CNN, VGG16)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Accuracy scores (replace with your actual values from the model evaluations)\n",
        "models = ['ResNet50', 'MobileNet', 'Custom CNN', 'VGG16']\n",
        "accuracy_scores = [0.38, 0.53, 0.75, 0.82]  # Example accuracy values, replace with your results\n",
        "\n",
        "# Create the bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(models, accuracy_scores, color=['skyblue', 'lightcoral', 'lightgreen', 'lightblue'])\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel(\"Models\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Comparison of Image Model Accuracies\")\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
        "\n",
        "\n",
        "# Add value annotations to each bar\n",
        "for i, v in enumerate(accuracy_scores):\n",
        "    plt.text(i, v + 0.01, str(round(v, 4)), ha='center')\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W9nFOIp8ZCp"
      },
      "source": [
        "## Python Tkinter UI Screen V.1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_tEQjUn8f5N"
      },
      "source": [
        "loading screen.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLK64gaL8e6R"
      },
      "outputs": [],
      "source": [
        "# screens/loading_screen.py\n",
        "# First screen (welcome / loading) with centered logo + fade-in\n",
        "\n",
        "import os\n",
        "from tkinter import ttk\n",
        "import io\n",
        "import re\n",
        "import requests\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    from PIL import Image, ImageTk, ImageEnhance\n",
        "except Exception:\n",
        "    Image = None\n",
        "    ImageTk = None\n",
        "    ImageEnhance = None\n",
        "\n",
        "\n",
        "class LoadingScreen(ttk.Frame):\n",
        "    \"\"\"\n",
        "    Usage:\n",
        "        root = tk.Tk()\n",
        "        screen = LoadingScreen(root,\n",
        "                               controller=my_controller,                 # must have show(next_screen_name)\n",
        "                               logo_path=\"/Users/alambebar/Desktop/Screenshot 2025-08-09 at 21.23.05\",\n",
        "                               next_screen_name=\"IntakeScreen\")\n",
        "        screen.pack(fill=\"both\", expand=True)\n",
        "        root.mainloop()\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, parent, controller=None, logo_path=None, next_screen_name=\"IntakeScreen\"):\n",
        "        super().__init__(parent)\n",
        "        self.controller = controller\n",
        "        self.logo_path = logo_path\n",
        "        self.next_screen_name = next_screen_name\n",
        "\n",
        "        self._raw_logo = None     # PIL.Image\n",
        "        self._tk_logo = None      # ImageTk.PhotoImage\n",
        "        self._fade_step = 0\n",
        "        self._fade_total = 18     # how many steps in the fade\n",
        "        self._fade_job = None\n",
        "\n",
        "        self._build_style()\n",
        "        self._build_ui()\n",
        "        self._load_logo()\n",
        "        self.after(300, self._start_animation)   # slight delay so the UI is drawn\n",
        "\n",
        "    # ---------- UI ----------\n",
        "\n",
        "    def _build_style(self):\n",
        "        style = ttk.Style(self)\n",
        "        # make sure we have a theme\n",
        "        try:\n",
        "            if style.theme_use() not in style.theme_names():\n",
        "                style.theme_use(\"clam\")\n",
        "        except Exception:\n",
        "            try:\n",
        "                style.theme_use(\"clam\")\n",
        "            except Exception:\n",
        "                pass\n",
        "        style.configure(\"Title.TLabel\", font=(\"Arial\", 36, \"bold\"))\n",
        "        style.configure(\"Subtitle.TLabel\", font=(\"Arial\", 24, \"bold\"))\n",
        "        style.configure(\"Body.TLabel\", font=(\"Arial\", 18))\n",
        "        style.configure(\"Start.TButton\", font=(\"Arial\", 16, \"bold\"))\n",
        "        style.configure(\"Small.TLabel\", font=(\"Arial\", 11))\n",
        "\n",
        "    def _build_ui(self):\n",
        "        self.columnconfigure(0, weight=1)\n",
        "        self.rowconfigure(4, weight=1)\n",
        "\n",
        "        # top welcome\n",
        "        ttk.Label(self, text=\"WELCOME\", style=\"Title.TLabel\").grid(row=0, column=0, pady=(30, 0), sticky=\"n\")\n",
        "        ttk.Label(self, text=\"This tool uses image preprocessing (CLAHE, segmentation, cropping), majority-vote Norwood stage classification from four CNNs,\\nand an XGBoost tabular hair-fall predictor.Built with Tkinter, it provides insights for clinical \\nuse in hair-transplant settings, with the goal of supporting early intervention and offering \\npersonalized recommendations based on the results.\", style=\"Subtitle.TLabel\")\\\n",
        "           .grid(row=1, column=0, pady=(6, 0), sticky=\"n\")\n",
        "        ttk.Label(self,\n",
        "                  text=\"We will provide recommendations and scientifically backed preventive measures based on your predicted male pattern,\\nand estimate the number of hair follicles needed to achieve a full hairline\",\n",
        "                  style=\"Body.TLabel\", wraplength=900, justify=\"center\")\\\n",
        "           .grid(row=2, column=0, pady=(24, 12), sticky=\"n\")\n",
        "\n",
        "        # logo + progress\n",
        "        logo_wrap = ttk.Frame(self)\n",
        "        logo_wrap.grid(row=3, column=0, pady=(8, 4), sticky=\"n\")\n",
        "        self.logo_label = ttk.Label(logo_wrap)   # image set later\n",
        "        self.logo_label.pack(pady=(0, 8))\n",
        "\n",
        "        self.progress = ttk.Progressbar(self, mode=\"indeterminate\", length=280)\n",
        "        self.progress.grid(row=4, column=0, pady=(0, 20), sticky=\"n\")\n",
        "\n",
        "        # start button\n",
        "        self.start_btn = ttk.Button(self, text=\"START NOW >\", style=\"Start.TButton\",\n",
        "                                    command=self._on_start)\n",
        "        self.start_btn.grid(row=5, column=0, pady=(6, 28))\n",
        "\n",
        "        # tiny tagline box to match your mock\n",
        "        box = ttk.Frame(self, padding=16)\n",
        "        box.grid(row=6, column=0, pady=(8, 30))\n",
        "        ttk.Label(box, text=\"We are students from The Max Stern Valley College - This is our final project - Students Alam Bebar (207415407), Ryan Thawkho (305070567)\").pack()\n",
        "\n",
        "        ttk.Label(self, text=\"Tip: Your hairline is more than just hair â€” itâ€™s confidence, presence, and the best version of you. Donâ€™t settle for less.\",\n",
        "                  style=\"Small.TLabel\").grid(row=7, column=0, pady=(0, 12))\n",
        "    def _open_logo_image(self):\n",
        "        \"\"\"\n",
        "        Returns a PIL.Image in RGBA from either:\n",
        "          - local file path (self.logo_path), or\n",
        "          - URL (http/https), incl. Google Drive share links.\n",
        "        Raises on failure.\n",
        "        \"\"\"\n",
        "        if not self.logo_path:\n",
        "            raise FileNotFoundError(\"No logo_path provided\")\n",
        "\n",
        "        src = str(self.logo_path).strip()\n",
        "\n",
        "        # If it's a URL, fetch it\n",
        "        if src.startswith(\"http://\") or src.startswith(\"https://\"):\n",
        "            url = src\n",
        "            # Handle Google Drive share links\n",
        "            m = re.search(r\"/d/([a-zA-Z0-9_-]+)/\", url) or re.search(r\"[?&]id=([a-zA-Z0-9_-]+)\", url)\n",
        "            if \"drive.google.com\" in url and m:\n",
        "                file_id = m.group(1)\n",
        "                url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
        "\n",
        "            r = requests.get(url, timeout=15)\n",
        "            r.raise_for_status()\n",
        "            return Image.open(io.BytesIO(r.content)).convert(\"RGBA\")\n",
        "\n",
        "        # Otherwise, treat as local path\n",
        "        if not os.path.exists(src):\n",
        "            raise FileNotFoundError(f\"Logo file not found: {src}\")\n",
        "        return Image.open(src).convert(\"RGBA\")\n",
        "\n",
        "    # ---------- Logo handling + fade ----------\n",
        "\n",
        "    def _load_logo(self):\n",
        "        if Image is None or ImageTk is None:\n",
        "            self.logo_label.config(text=\"(logo)\")\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            img = self._open_logo_image()\n",
        "        except Exception as e:\n",
        "            # graceful fallback\n",
        "            self.logo_label.config(text=f\"(logo not available: {e})\")\n",
        "            return\n",
        "\n",
        "        # scale to ~150px wide, keep aspect\n",
        "        target_w = 150\n",
        "        w, h = img.size\n",
        "        scale = target_w / float(w) if w > target_w else 1.0\n",
        "        new_w = max(1, int(w * scale))\n",
        "        new_h = max(1, int(h * scale))\n",
        "        img = img.resize((new_w, new_h), Image.LANCZOS)\n",
        "        # start fully transparent for fade\n",
        "        img.putalpha(0)\n",
        "        self._raw_logo = img\n",
        "        self._tk_logo = ImageTk.PhotoImage(img)\n",
        "        self.logo_label.configure(image=self._tk_logo)\n",
        "\n",
        "    def _start_animation(self):\n",
        "        # run progress bar and fade the logo in\n",
        "        try:\n",
        "            self.progress.start(12)  # ms per move\n",
        "        except Exception:\n",
        "            pass\n",
        "        self._fade_step = 0\n",
        "        if self._raw_logo is not None:\n",
        "            self._schedule_fade()\n",
        "\n",
        "    def _schedule_fade(self):\n",
        "        if self._fade_step > self._fade_total:\n",
        "            return\n",
        "        alpha = int(255 * (self._fade_step / float(self._fade_total)))\n",
        "        # apply alpha\n",
        "        img = self._raw_logo.copy()\n",
        "        img.putalpha(alpha)\n",
        "        self._tk_logo = ImageTk.PhotoImage(img)\n",
        "        self.logo_label.configure(image=self._tk_logo)\n",
        "        self._fade_step += 1\n",
        "        self._fade_job = self.after(40, self._schedule_fade)  # ~0.7s total\n",
        "\n",
        "    # ---------- Navigation ----------\n",
        "\n",
        "    def _on_start(self):\n",
        "        # stop animation to keep things tidy\n",
        "        try:\n",
        "            self.progress.stop()\n",
        "        except Exception:\n",
        "            pass\n",
        "        if self._fade_job:\n",
        "            try:\n",
        "                self.after_cancel(self._fade_job)\n",
        "            except Exception:\n",
        "                pass\n",
        "            self._fade_job = None\n",
        "\n",
        "        # hand off to the next screen\n",
        "        if self.controller is not None:\n",
        "            if hasattr(self.controller, \"go_to_intake\"):\n",
        "                self.controller.go_to_intake()\n",
        "            elif hasattr(self.controller, \"show\"):\n",
        "                self.controller.show(\"intake\")\n",
        "            else:\n",
        "                print(\"[LoadingScreen] No navigation method on controller.\")\n",
        "        else:\n",
        "            print(f\"[LoadingScreen] Start clicked â†’ would show: {self.next_screen_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qul_F8V8nl0"
      },
      "source": [
        "intake screen.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e09rnW3m8rnx"
      },
      "outputs": [],
      "source": [
        "# Screen 2: Image + Tabular Inference (Hugging Face)\n",
        "#\n",
        "# Requirements (same venv as project):\n",
        "#   pip install pillow numpy opencv-python torch torchvision efficientnet_pytorch huggingface_hub pandas joblib xgboost\n",
        "#\n",
        "# This frame expects the main app (controller) to set:\n",
        "#   - controller.shared[\"image_path\"] : str (path to the image picked in screen 1)\n",
        "#   - controller.shared[\"form\"]       : dict with keys:\n",
        "#        stay_up_late, water_reason, family_history, use_chemicals,\n",
        "#        stress, chronic_illness, age\n",
        "#\n",
        "# It renders:\n",
        "#   - image preview (left)\n",
        "#   - per-model predictions + majority vote (right, upper)\n",
        "#   - XGBoost hair fall prediction + probability (right, lower)\n",
        "\n",
        "import threading\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Tuple, Optional\n",
        "\n",
        "import tkinter as tk\n",
        "from tkinter import ttk, messagebox\n",
        "\n",
        "# visuals\n",
        "from PIL import Image, ImageTk\n",
        "\n",
        "# â”€â”€ ML deps\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from huggingface_hub import hf_hub_download\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from tkinter import ttk, messagebox, filedialog\n",
        "\n",
        "\n",
        "# ========== Shared UI helpers ==========\n",
        "\n",
        "def pil_to_tk(pil_img: Image.Image, max_size=(360, 360)):\n",
        "    w, h = pil_img.size\n",
        "    scale = min(max_size[0] / w, max_size[1] / h, 1.0)\n",
        "    if scale < 1.0:\n",
        "        pil_img = pil_img.resize((int(w * scale), int(h * scale)))\n",
        "    return ImageTk.PhotoImage(pil_img)\n",
        "\n",
        "# ========== Classifier wrappers (your exact HF logic) ==========\n",
        "\n",
        "@dataclass\n",
        "class ImageClassifier:\n",
        "    name: str\n",
        "    repo: str\n",
        "    weights_file: str\n",
        "    meta_file: str = \"metadata.json\"\n",
        "    model: Optional[torch.nn.Module] = None\n",
        "    tfm: Optional[object] = None\n",
        "    level_names: Optional[list] = None\n",
        "    label_base: int = 0\n",
        "    img_size: int = 224\n",
        "    mean: Tuple[float, float, float] = (0.485, 0.456, 0.406)\n",
        "    std: Tuple[float, float, float] = (0.229, 0.224, 0.225)\n",
        "\n",
        "    def _load_meta(self):\n",
        "        meta_path = hf_hub_download(self.repo, filename=self.meta_file)\n",
        "        with open(meta_path, \"r\") as f:\n",
        "            meta = json.load(f)\n",
        "        # labels field might be \"labels\" or \"class_names\"\n",
        "        self.level_names = meta.get(\"labels\") or meta.get(\"class_names\") or [f\"Level {i}\" for i in range(2, 8)]\n",
        "        self.img_size = int(meta.get(\"img_size\", 224))\n",
        "        self.mean = tuple(meta.get(\"mean\", [0.485, 0.456, 0.406]))\n",
        "        self.std = tuple(meta.get(\"std\", [0.229, 0.224, 0.225]))\n",
        "        self.label_base = int(meta.get(\"label_base\", 0))\n",
        "\n",
        "    def _build_resnet18(self):\n",
        "        model = models.resnet18(weights=None)\n",
        "        in_features = model.fc.in_features\n",
        "        model.fc = nn.Linear(in_features, len(self.level_names))\n",
        "        return model\n",
        "\n",
        "    def _build_mobilenet_v3_large(self):\n",
        "        model = models.mobilenet_v3_large(weights=None)\n",
        "        in_features = model.classifier[3].in_features\n",
        "        model.classifier[3] = nn.Linear(in_features, len(self.level_names))\n",
        "        return model\n",
        "\n",
        "    def _build_efficientnet_b0(self):\n",
        "        model = EfficientNet.from_name(\"efficientnet-b0\")\n",
        "        in_features = model._fc.in_features\n",
        "        model._fc = nn.Linear(in_features, len(self.level_names))\n",
        "        return model\n",
        "\n",
        "    def _build_convnext_tiny(self):\n",
        "        model = models.convnext_tiny(weights=None)\n",
        "        in_features = model.classifier[2].in_features\n",
        "        model.classifier[2] = nn.Linear(in_features, len(self.level_names))\n",
        "        return model\n",
        "\n",
        "    def _build_by_name(self):\n",
        "        if self.name == \"resnet18\":\n",
        "            return self._build_resnet18()\n",
        "        if self.name == \"mobilenet_v3_large\":\n",
        "            return self._build_mobilenet_v3_large()\n",
        "        if self.name == \"efficientnet_b0\":\n",
        "            return self._build_efficientnet_b0()\n",
        "        if self.name == \"convnext_tiny\":\n",
        "            return self._build_convnext_tiny()\n",
        "        raise ValueError(f\"Unknown model name: {self.name}\")\n",
        "\n",
        "    def _build_tfm(self):\n",
        "        self.tfm = transforms.Compose([\n",
        "            transforms.Resize((self.img_size, self.img_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=self.mean, std=self.std),\n",
        "        ])\n",
        "\n",
        "    def load(self):\n",
        "        if self.model is not None and self.tfm is not None:\n",
        "            return\n",
        "        # metadata\n",
        "        self._load_meta()\n",
        "        # weights\n",
        "        wpath = hf_hub_download(self.repo, filename=self.weights_file)\n",
        "        # arch\n",
        "        self.model = self._build_by_name()\n",
        "        # state\n",
        "        state = torch.load(wpath, map_location=\"cpu\")\n",
        "        if isinstance(state, dict) and \"state_dict\" in state and isinstance(state[\"state_dict\"], dict):\n",
        "            state = state[\"state_dict\"]\n",
        "        fixed = {}\n",
        "        if isinstance(state, dict):\n",
        "            for k, v in state.items():\n",
        "                if isinstance(k, str) and k.startswith(\"module.\"):\n",
        "                    k = k[len(\"module.\"):]\n",
        "                if isinstance(k, str) and k.startswith(\"model.\"):\n",
        "                    k = k[len(\"model.\"):]\n",
        "                fixed[k] = v\n",
        "        else:\n",
        "            fixed = state\n",
        "        self.model.load_state_dict(fixed, strict=True)\n",
        "        self.model.eval()\n",
        "        # tfm\n",
        "        self._build_tfm()\n",
        "\n",
        "    def predict_level(self, pil_rgb: Image.Image) -> Tuple[int, str]:\n",
        "        x = self.tfm(pil_rgb).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            logits = self.model(x)\n",
        "            pred_idx = int(logits.argmax(-1).item())\n",
        "            level = pred_idx + 1 if self.label_base == 0 else pred_idx\n",
        "        label_str = (self.level_names[level - 1]\n",
        "                     if 1 <= level <= len(self.level_names)\n",
        "                     else f\"Level {level}\")\n",
        "        return level, label_str\n",
        "\n",
        "\n",
        "# Instantiate the four models (lazy-loaded)\n",
        "CLS_RESNET18 = ImageClassifier(\n",
        "    name=\"resnet18\",\n",
        "    repo=\"alamb98/resnet18\",\n",
        "    weights_file=\"resnet18.pth\",\n",
        ")\n",
        "\n",
        "CLS_MNV3 = ImageClassifier(\n",
        "    name=\"mobilenet_v3_large\",\n",
        "    repo=\"alamb98/mobilenet_v3_large_cropped_clahe_norwood_classifier\",\n",
        "    weights_file=\"mobilenet_v3_large_cropped_clahe_best.pth\",\n",
        ")\n",
        "\n",
        "CLS_EFFB0 = ImageClassifier(\n",
        "    name=\"efficientnet_b0\",\n",
        "    repo=\"alamb98/efficientnet-b0_norwood_classifier\",\n",
        "    weights_file=\"efficientnet-b0_best.pth\",\n",
        ")\n",
        "\n",
        "CLS_CONVNEXT = ImageClassifier(\n",
        "    name=\"convnext_tiny\",\n",
        "    repo=\"alamb98/convnext_tiny_clahe_norwood_classifier\",\n",
        "    weights_file=\"convnext_tiny_clahe_best.pth\",\n",
        ")\n",
        "\n",
        "# ========== XGBoost HF joblib (exact feature order you provided) ==========\n",
        "\n",
        "XGB_REPO = \"alamb98/xgboost_hair_fall_classifier\"\n",
        "XGB_FILENAME = \"xgboost_hair_fall_classifier.joblib\"\n",
        "\n",
        "FEATURE_COLUMNS = [\n",
        "    \"Do you stay up late at night?_Yes\",\n",
        "    \"Do you think that in your area water is a reason behind hair fall problems?_Yes\",\n",
        "    \"Is there anyone in your family having a hair fall problem or a baldness issue?_Yes\",\n",
        "    \"Do you use chemicals, hair gel, or color in your hair?_Yes\",\n",
        "    \"Do you have too much stress_Yes\",\n",
        "    \"Did you face any type of chronic illness in the past?_Yes\",\n",
        "    \"What is your age ?\"\n",
        "]\n",
        "\n",
        "_xgb_model_cache = None\n",
        "\n",
        "def _to01(v):\n",
        "    v = str(v).strip().lower()\n",
        "    return 1 if v in (\"yes\", \"y\", \"1\", \"true\", \"t\") else 0\n",
        "\n",
        "def form_to_features(form: dict) -> pd.DataFrame:\n",
        "    row = {\n",
        "        \"Do you stay up late at night?_Yes\": _to01(form.get(\"stay_up_late\", \"No\")),\n",
        "        \"Do you think that in your area water is a reason behind hair fall problems?_Yes\": _to01(form.get(\"water_reason\", \"No\")),\n",
        "        \"Is there anyone in your family having a hair fall problem or a baldness issue?_Yes\": _to01(form.get(\"family_history\", \"No\")),\n",
        "        \"Do you use chemicals, hair gel, or color in your hair?_Yes\": _to01(form.get(\"use_chemicals\", \"No\")),\n",
        "        \"Do you have too much stress_Yes\": _to01(form.get(\"stress\", \"No\")),\n",
        "        \"Did you face any type of chronic illness in the past?_Yes\": _to01(form.get(\"chronic_illness\", \"No\")),\n",
        "        \"What is your age ?\": float(form.get(\"age\", 0)),\n",
        "    }\n",
        "    return pd.DataFrame([row], columns=FEATURE_COLUMNS)\n",
        "\n",
        "def load_xgb():\n",
        "    global _xgb_model_cache\n",
        "    if _xgb_model_cache is None:\n",
        "        model_path = hf_hub_download(repo_id=XGB_REPO, filename=XGB_FILENAME)\n",
        "        _xgb_model_cache = joblib.load(model_path)\n",
        "    return _xgb_model_cache\n",
        "\n",
        "def predict_xgb(form: dict):\n",
        "    mdl = load_xgb()\n",
        "    X = form_to_features(form).astype(float)\n",
        "    y_pred = int(mdl.predict(X)[0])\n",
        "    if hasattr(mdl, \"predict_proba\"):\n",
        "        proba_yes = float(mdl.predict_proba(X)[0][1])\n",
        "    else:\n",
        "        proba_yes = float(\"nan\")\n",
        "    label = {0: \"No hair fall\", 1: \"Yes hair fall\"}.get(y_pred, str(y_pred))\n",
        "    return y_pred, label, proba_yes\n",
        "\n",
        "# ========== Majority vote helper ==========\n",
        "\n",
        "def majority_vote(levels: Dict[str, int]) -> int:\n",
        "    from collections import Counter\n",
        "    arr = list(levels.values())\n",
        "    c = Counter(arr)\n",
        "    maxc = max(c.values()) if c else 0\n",
        "    winners = [lvl for lvl, cnt in c.items() if cnt == maxc] if c else [3]\n",
        "    return min(winners)\n",
        "\n",
        "# ========== Tkinter Screen ==========\n",
        "\n",
        "class IntakeScreen(ttk.Frame):\n",
        "    \"\"\"\n",
        "    Usage:\n",
        "      screen = ModelsScreen(parent, controller)\n",
        "      controller.shared must include:\n",
        "        - \"image_path\": str\n",
        "        - \"form\": dict (keys listed above)\n",
        "    \"\"\"\n",
        "    def __init__(self, parent, controller):\n",
        "        super().__init__(parent)\n",
        "        self.controller = controller\n",
        "\n",
        "        # --- Header ---\n",
        "        hdr = ttk.Frame(self)\n",
        "        hdr.pack(fill=\"x\", pady=10, padx=16)\n",
        "        ttk.Label(hdr, text=\"Run Models\", font=(\"Arial\", 18, \"bold\")).pack(side=\"left\")\n",
        "\n",
        "        # --- Body (left: preview, right: results) ---\n",
        "        body = ttk.Frame(self)\n",
        "        body.pack(fill=\"both\", expand=True, padx=16, pady=8)\n",
        "\n",
        "        # --- Toolbar: choose image ---\n",
        "        tools = ttk.Frame(self)\n",
        "        tools.pack(fill=\"x\", padx=16, pady=(0, 8))\n",
        "\n",
        "        ttk.Button(tools, text=\"Choose Imageâ€¦\", command=self.on_choose_image).pack(side=\"left\")\n",
        "\n",
        "        self.path_var = tk.StringVar(value=\"No image selected\")\n",
        "        ttk.Label(tools, textvariable=self.path_var).pack(side=\"left\", padx=10)\n",
        "\n",
        "\n",
        "        # Left: image preview\n",
        "        left = ttk.LabelFrame(body, text=\"Input Image\")\n",
        "        left.pack(side=\"left\", fill=\"both\", expand=True, padx=(0, 10))\n",
        "        self.preview = ttk.Label(left, text=\"No image\")\n",
        "        self.preview.pack(fill=\"both\", expand=True, padx=10, pady=10)\n",
        "\n",
        "        # Right: predictions\n",
        "        right = ttk.LabelFrame(body, text=\"Predictions\")\n",
        "        right.pack(side=\"left\", fill=\"both\", expand=True, padx=(10, 0))\n",
        "\n",
        "        # Progress\n",
        "        self.pbar = ttk.Progressbar(right, mode=\"determinate\", maximum=100)\n",
        "        self.pbar.pack(fill=\"x\", padx=12, pady=(10, 4))\n",
        "        self.status = ttk.Label(right, text=\"Idle.\")\n",
        "        self.status.pack(fill=\"x\", padx=12)\n",
        "\n",
        "        # Per-model results\n",
        "        self.txt = tk.Text(right, height=18, wrap=\"word\")\n",
        "        self.txt.pack(fill=\"both\", expand=True, padx=12, pady=10)\n",
        "\n",
        "        # Footer buttons\n",
        "        ftr = ttk.Frame(self)\n",
        "        ftr.pack(fill=\"x\", pady=10, padx=16)\n",
        "        ttk.Button(ftr, text=\"Back\", command=self.on_back).pack(side=\"left\")\n",
        "        ttk.Button(ftr, text=\"Run Predictions\", command=self.on_run).pack(side=\"right\")\n",
        "\n",
        "        # NEW: view recommendations button (starts disabled; enabled after _worker finishes)\n",
        "        self.view_btn = ttk.Button(ftr, text=\"View Recommendations â†’\",\n",
        "                                   command=self.on_view_results, state=\"disabled\")\n",
        "        self.view_btn.pack(side=\"right\", padx=(0, 8))\n",
        "\n",
        "        # keep a place to store last results\n",
        "        self._last_results = None\n",
        "        # Auto show preview if available\n",
        "        self.after(50, self._refresh_preview)\n",
        "\n",
        "        # --- Form: features for XGBoost ---\n",
        "        form_wrap = ttk.LabelFrame(body, text=\"Tabular Features\")\n",
        "        form_wrap.pack(side=\"left\", fill=\"y\", padx=(0, 10), pady=0)\n",
        "\n",
        "        # Variables\n",
        "        self.var_stay_up_late   = tk.StringVar(value=\"No\")\n",
        "        self.var_water_reason   = tk.StringVar(value=\"No\")\n",
        "        self.var_family_history = tk.StringVar(value=\"No\")\n",
        "        self.var_use_chemicals  = tk.StringVar(value=\"No\")\n",
        "        self.var_stress         = tk.StringVar(value=\"No\")\n",
        "        self.var_chronic        = tk.StringVar(value=\"No\")\n",
        "        self.var_age            = tk.StringVar(value=\"25\")  # keep as string, we cast later\n",
        "\n",
        "        def yn_row(parent, label, var):\n",
        "            r = ttk.Frame(parent); r.pack(fill=\"x\", padx=8, pady=4)\n",
        "            ttk.Label(r, text=label, width=34, anchor=\"w\").pack(side=\"left\")\n",
        "            cb = ttk.Combobox(r, textvariable=var, state=\"readonly\", values=[\"No\", \"Yes\"], width=6)\n",
        "            cb.pack(side=\"left\")\n",
        "            return cb\n",
        "\n",
        "        yn_row(form_wrap, \"Do you stay up late at night?\", self.var_stay_up_late)\n",
        "        yn_row(form_wrap, \"Water in your area a reason?\", self.var_water_reason)\n",
        "        yn_row(form_wrap, \"Family hair fall/baldness history?\", self.var_family_history)\n",
        "        yn_row(form_wrap, \"Use chemicals/gel/color?\", self.var_use_chemicals)\n",
        "        yn_row(form_wrap, \"Too much stress?\", self.var_stress)\n",
        "        yn_row(form_wrap, \"Chronic illness in the past?\", self.var_chronic)\n",
        "\n",
        "        age_row = ttk.Frame(form_wrap); age_row.pack(fill=\"x\", padx=8, pady=(8,4))\n",
        "        ttk.Label(age_row, text=\"Age\", width=34, anchor=\"w\").pack(side=\"left\")\n",
        "        ttk.Entry(age_row, textvariable=self.var_age, width=8).pack(side=\"left\")\n",
        "\n",
        "\n",
        "    def _refresh_preview(self):\n",
        "        img_path = self.controller.shared.get(\"image_path\")\n",
        "        self.path_var.set(img_path or \"No image selected\")\n",
        "        if not img_path:\n",
        "            self.preview.config(text=\"No image selected\")\n",
        "            return\n",
        "        try:\n",
        "            pil = Image.open(img_path).convert(\"RGB\")\n",
        "            tk_img = pil_to_tk(pil)\n",
        "            self.preview.configure(image=tk_img, text=\"\")\n",
        "            self.preview.image = tk_img\n",
        "        except Exception as e:\n",
        "            self.preview.config(text=f\"Failed to load image:\\n{e}\")\n",
        "\n",
        "    def on_back(self):\n",
        "        if hasattr(self.controller, \"show\"):\n",
        "            self.controller.show(\"loading\")\n",
        "        else:\n",
        "            messagebox.showinfo(\"Back\", \"Implement controller.show(...) to navigate.\")\n",
        "\n",
        "    def on_show(self):\n",
        "        self._refresh_preview()\n",
        "        form = self.controller.shared.get(\"form\", {})\n",
        "        if form:\n",
        "            self.var_stay_up_late.set(\"Yes\" if form.get(\"stay_up_late\", \"No\") in (\"Yes\", \"yes\", 1, True) else \"No\")\n",
        "            self.var_water_reason.set(\"Yes\" if form.get(\"water_reason\", \"No\") in (\"Yes\", \"yes\", 1, True) else \"No\")\n",
        "            self.var_family_history.set(\"Yes\" if form.get(\"family_history\", \"No\") in (\"Yes\", \"yes\", 1, True) else \"No\")\n",
        "            self.var_use_chemicals.set(\"Yes\" if form.get(\"use_chemicals\", \"No\") in (\"Yes\", \"yes\", 1, True) else \"No\")\n",
        "            self.var_stress.set(\"Yes\" if form.get(\"stress\", \"No\") in (\"Yes\", \"yes\", 1, True) else \"No\")\n",
        "            self.var_chronic.set(\"Yes\" if form.get(\"chronic_illness\", \"No\") in (\"Yes\", \"yes\", 1, True) else \"No\")\n",
        "            try:\n",
        "                self.var_age.set(str(form.get(\"age\", \"\")))\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    def on_run(self):\n",
        "        img_path = self.controller.shared.get(\"image_path\")\n",
        "        if not img_path:\n",
        "            messagebox.showwarning(\"Missing image\", \"Please select an image on the first screen.\")\n",
        "            return\n",
        "\n",
        "        # collect and save the form so other screens can access it too\n",
        "        form = self._collect_form()\n",
        "        if hasattr(self.controller, \"shared\"):\n",
        "            self.controller.shared[\"form\"] = form\n",
        "\n",
        "        # clear UI + start\n",
        "        self.txt.delete(\"1.0\", \"end\")\n",
        "        self.status.config(text=\"Downloading / loading modelsâ€¦\")\n",
        "        self.pbar[\"value\"] = 0\n",
        "\n",
        "        t = threading.Thread(target=self._worker, args=(img_path, form), daemon=True)\n",
        "        t.start()\n",
        "\n",
        "    def _worker(self, img_path: str, form: dict):\n",
        "        try:\n",
        "            steps = [\n",
        "                (\"Load resnet18\", lambda: CLS_RESNET18.load()),\n",
        "                (\"Load mobilenet_v3_large\", lambda: CLS_MNV3.load()),\n",
        "                (\"Load efficientnet_b0\", lambda: CLS_EFFB0.load()),\n",
        "                (\"Load convnext_tiny\", lambda: CLS_CONVNEXT.load()),\n",
        "            ]\n",
        "            per_step = 60 / max(1, len(steps))  # first 60% for loading\n",
        "            for name, fn in steps:\n",
        "                self._ui_progress(name)\n",
        "                fn()\n",
        "                self._ui_bump(per_step)\n",
        "\n",
        "            # Image\n",
        "            self._ui_progress(\"Reading imageâ€¦\")\n",
        "            pil = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "            # Inference (next 30%)\n",
        "            preds = {}\n",
        "            for nick, clf in [\n",
        "                (\"resnet18\", CLS_RESNET18),\n",
        "                (\"mobilenet_v3_large\", CLS_MNV3),\n",
        "                (\"efficientnet_b0\", CLS_EFFB0),\n",
        "                (\"convnext_tiny\", CLS_CONVNEXT),\n",
        "            ]:\n",
        "                self._ui_progress(f\"Running {nick}â€¦\")\n",
        "                lvl, _ = clf.predict_level(pil)\n",
        "                preds[nick] = lvl\n",
        "                self._ui_bump(7.5)  # 4 * 7.5 = 30\n",
        "\n",
        "            final_level = majority_vote(preds)\n",
        "\n",
        "            # XGB (last 10%)\n",
        "            self._ui_progress(\"Running XGBoostâ€¦\")\n",
        "            y_pred, y_label, p_yes = predict_xgb(form)\n",
        "            self._ui_bump(10)\n",
        "\n",
        "            # Build results + text\n",
        "            lines = []\n",
        "            lines.append(\"â€” Image Models (Norwood per model) â€”\")\n",
        "            for k, v in preds.items():\n",
        "                lines.append(f\"  â€¢ {k}: Level {v}\")\n",
        "            lines.append(f\"\\nFinal Norwood (majority): Level {final_level}\")\n",
        "            if p_yes == p_yes:  # not NaN\n",
        "                lines.append(f\"\\nHair-Fall (XGBoost): {y_label}  (p_yes={p_yes:.2f})\")\n",
        "            else:\n",
        "                lines.append(f\"\\nHair-Fall (XGBoost): {y_label}\")\n",
        "\n",
        "            # Store results first, then update UI once\n",
        "            self._last_results = {\n",
        "                \"norwood_by_model\": preds,\n",
        "                \"norwood_final\": final_level,\n",
        "                \"hairfall_yes\": bool(y_pred == 1),\n",
        "                \"hairfall_label\": y_label,\n",
        "                \"hairfall_prob\": p_yes,\n",
        "            }\n",
        "            self._ui_done(\"\\n\".join(lines))\n",
        "\n",
        "        except Exception as e:\n",
        "            self._ui_done(f\"[ERROR]\\n{e}\")\n",
        "\n",
        "    # UI-thread helpers\n",
        "    def _ui_progress(self, msg):\n",
        "        self.after(0, lambda: self.status.config(text=msg))\n",
        "\n",
        "    def _ui_bump(self, delta):\n",
        "        def _b():\n",
        "            v = min(100, self.pbar[\"value\"] + delta)\n",
        "            self.pbar[\"value\"] = v\n",
        "        self.after(0, _b)\n",
        "\n",
        "    def _ui_done(self, text):\n",
        "        def _d():\n",
        "            self.pbar[\"value\"] = 100\n",
        "            self.status.config(text=\"Done.\")\n",
        "            self.txt.delete(\"1.0\", \"end\")\n",
        "            self.txt.insert(\"end\", text)\n",
        "            # enable the navigation button if results exist\n",
        "            try:\n",
        "                if self._last_results:\n",
        "                    self.view_btn.config(state=\"normal\")\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        self.after(0, _d)\n",
        "\n",
        "    def on_choose_image(self):\n",
        "        \"\"\"Open a file dialog, store the path, and refresh the preview.\"\"\"\n",
        "        fp = filedialog.askopenfilename(\n",
        "            parent=self,  # tie dialog to this window\n",
        "            title=\"Select image\",\n",
        "            filetypes=[\n",
        "                (\"Image files\", (\"*.png\", \"*.jpg\", \"*.jpeg\", \"*.bmp\", \"*.webp\",\n",
        "                                 \"*.PNG\", \"*.JPG\", \"*.JPEG\", \"*.BMP\", \"*.WEBP\")),\n",
        "                (\"All files\", \"*\"),\n",
        "            ],\n",
        "        )\n",
        "        if not fp:\n",
        "            return\n",
        "        # Save to shared state so other screens can use it\n",
        "        if hasattr(self.controller, \"shared\"):\n",
        "            self.controller.shared[\"image_path\"] = fp\n",
        "        # Update path label + preview\n",
        "        self.path_var.set(fp)\n",
        "        self._refresh_preview()\n",
        "\n",
        "    def on_view_results(self):\n",
        "        \"\"\"Navigate to the Results screen with the latest predictions.\"\"\"\n",
        "        if not self._last_results:\n",
        "            return\n",
        "        # put into shared state\n",
        "        if hasattr(self.controller, \"shared\"):\n",
        "            self.controller.shared[\"results\"] = self._last_results\n",
        "        # feed ResultsScreen and show it\n",
        "        try:\n",
        "            res = self.controller.screens[\"results\"]\n",
        "            res.set_results(self._last_results)\n",
        "            self.controller.show(\"results\")\n",
        "        except Exception:\n",
        "            # safe fallback if controller/screen not wired yet\n",
        "            from tkinter import messagebox\n",
        "            messagebox.showinfo(\"Results\", \"Results screen not available in controller.\")\n",
        "\n",
        "    def _collect_form(self) -> dict:\n",
        "        # Normalize age (blank/invalid -> 0)\n",
        "        try:\n",
        "            age_val = float(self.var_age.get().strip())\n",
        "        except Exception:\n",
        "            age_val = 0.0\n",
        "\n",
        "        return {\n",
        "            \"stay_up_late\":   self.var_stay_up_late.get(),\n",
        "            \"water_reason\":   self.var_water_reason.get(),\n",
        "            \"family_history\": self.var_family_history.get(),\n",
        "            \"use_chemicals\":  self.var_use_chemicals.get(),\n",
        "            \"stress\":         self.var_stress.get(),\n",
        "            \"chronic_illness\": self.var_chronic.get(),\n",
        "            \"age\":            age_val,\n",
        "        }\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-YIN0zu98mW"
      },
      "source": [
        "results_screen.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZ6mamAp-BSb"
      },
      "outputs": [],
      "source": [
        "# screens/results_screen.py\n",
        "import os\n",
        "from collections import Counter\n",
        "import tkinter as tk\n",
        "from tkinter import ttk\n",
        "\n",
        "try:\n",
        "    from PIL import Image, ImageTk\n",
        "except Exception:\n",
        "    Image = None\n",
        "    ImageTk = None\n",
        "\n",
        "\n",
        "# ---- simple, editable recommendations ----\n",
        "NORWOOD_RECS = {\n",
        "    1: [\"Maintain gentle care routine\", \"Baseline photos every 3â€“6 months\"],\n",
        "    2: [\"Consider topical minoxidil\", \"Focus on sleep & nutrition\"],\n",
        "    3: [\"Discuss finasteride/minoxidil with a clinician\", \"Dermarolling only if supervised\"],\n",
        "    4: [\"Combo therapy (finasteride + minoxidil) may help\", \"Discuss LLLT devices evidence\"],\n",
        "    5: [\"Consider procedural options (e.g., PRP)\", \"Manage expectations; camouflage options\"],\n",
        "    6: [\"Surgical candidacy evaluation\", \"Plan donor management & maintenance therapy\"],\n",
        "    7: [\"SMP or hair systems; sun protection\", \"Medical therapy only for stabilization\"],\n",
        "}\n",
        "\n",
        "HAIRFALL_RECS = {\n",
        "    False: [\"Looks stable right now\", \"Keep healthy routine & periodic photos\"],\n",
        "    True:  [\"Progression likely â€” seek medical advice\", \"Early intervention improves outcomes\"],\n",
        "}\n",
        "\n",
        "# ---- optional images for each Norwood; replace with your assets if available ----\n",
        "# Put files (e.g. 1.png â€¦ 7.png) under project_root/assets/norwood/\n",
        "NORWOOD_IMAGES = {i: f\"assets/norwood/{i}.png\" for i in range(1, 8)}\n",
        "\n",
        "\n",
        "class ResultsScreen(ttk.Frame):\n",
        "    \"\"\"\n",
        "    Call set_results(results_dict) to populate the screen, then raise this frame.\n",
        "    results_dict may contain:\n",
        "      - norwood_by_model: dict{name: level_int}\n",
        "      - norwood_final: int (optional; if missing we majority-vote here)\n",
        "      - hairfall_yes: bool (preferred)\n",
        "      - hairfall_label: str (optional)\n",
        "      - hairfall_prob: float (optional)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, parent, controller=None):\n",
        "        super().__init__(parent)\n",
        "        self.controller = controller\n",
        "        self._stage_img_tk = None\n",
        "\n",
        "        self._build_ui()\n",
        "\n",
        "    # ---------- public API ----------\n",
        "    def set_results(self, results: dict):\n",
        "        \"\"\"Update all widgets using a results dict produced by the processing step.\"\"\"\n",
        "        nbm = results.get(\"norwood_by_model\", {}) or {}\n",
        "        final_level = results.get(\"norwood_final\")\n",
        "        if final_level is None and nbm:\n",
        "            final_level = self._majority_vote(list(nbm.values()))\n",
        "        if final_level is None:\n",
        "            final_level = 3  # safe default\n",
        "\n",
        "        hairfall_yes = results.get(\"hairfall_yes\")\n",
        "        # Fallbacks: infer from label if needed\n",
        "        if hairfall_yes is None:\n",
        "            label = (results.get(\"hairfall_label\") or \"\").lower()\n",
        "            hairfall_yes = \"yes\" in label if label else None\n",
        "\n",
        "        prob = results.get(\"hairfall_prob\")\n",
        "        prob_txt = f\" (p={prob:.2f})\" if isinstance(prob, (int, float)) else \"\"\n",
        "\n",
        "        # Big title\n",
        "        hl_text = \"Progressing hair loss\" if hairfall_yes else \"No hair loss detected\" if hairfall_yes is not None else \"â€”\"\n",
        "        self.title_lbl.config(text=f\"THE RESULTS ARE READY!\")\n",
        "        self.subtitle_lbl.config(text=f\"Final Norwood: Level {final_level} â€” {hl_text}{prob_txt}\")\n",
        "\n",
        "        # Left circle text\n",
        "        self.circle_lbl.config(text=f\"Level\\n{final_level}\")\n",
        "\n",
        "        # Stage image (center)\n",
        "        self._set_stage_image(final_level)\n",
        "\n",
        "        # Recommendations\n",
        "        stage_recs = NORWOOD_RECS.get(final_level, [])\n",
        "        hf_recs = HAIRFALL_RECS.get(bool(hairfall_yes), [])\n",
        "        self._fill_listbox(self.stage_recs_box, stage_recs)\n",
        "        self._fill_listbox(self.hf_recs_box, hf_recs)\n",
        "\n",
        "        # Footer â€œpredicted with â€¦â€\n",
        "        model_names = \", \".join(nbm.keys()) if nbm else \"ensemble\"\n",
        "        self.footer_lbl.config(\n",
        "            text=f\"Predicted with {model_names or 'ensemble'} image models and an XGBoost tabular model.\"\n",
        "        )\n",
        "\n",
        "    # ---------- internals ----------\n",
        "    def _build_ui(self):\n",
        "        self.columnconfigure(0, weight=1)\n",
        "        self.rowconfigure(3, weight=1)\n",
        "\n",
        "        # Header\n",
        "        self.title_lbl = ttk.Label(self, text=\"THE RESULTS ARE READY!\", font=(\"Arial\", 36, \"bold\"))\n",
        "        self.title_lbl.grid(row=0, column=0, sticky=\"w\", padx=40, pady=(30, 0))\n",
        "\n",
        "        self.subtitle_lbl = ttk.Label(self, text=\"\", font=(\"Arial\", 18))\n",
        "        self.subtitle_lbl.grid(row=1, column=0, sticky=\"w\", padx=40, pady=(6, 10))\n",
        "\n",
        "        # Main 3-column area\n",
        "        main = ttk.Frame(self)\n",
        "        main.grid(row=2, column=0, sticky=\"nsew\", padx=40, pady=10)\n",
        "        main.columnconfigure(0, weight=1)\n",
        "        main.columnconfigure(1, weight=1)\n",
        "        main.columnconfigure(2, weight=1)\n",
        "        self.rowconfigure(2, weight=1)\n",
        "\n",
        "        # Left: big circle with level\n",
        "        circle = tk.Canvas(main, width=260, height=260, highlightthickness=0)\n",
        "        circle.grid(row=0, column=0, sticky=\"n\", padx=(0, 20))\n",
        "        # Draw circle\n",
        "        circle.create_oval(5, 5, 255, 255, fill=\"#e9e9e9\", outline=\"#b5b5b5\", width=3)\n",
        "        # Label on top (centered)\n",
        "        self.circle_lbl = ttk.Label(main, text=\"\", font=(\"Arial\", 32, \"bold\"), anchor=\"center\")\n",
        "        self.circle_lbl.place(in_=circle, relx=0.5, rely=0.5, anchor=\"center\")\n",
        "\n",
        "        # Middle: stage figure\n",
        "        mid = ttk.Frame(main)\n",
        "        mid.grid(row=0, column=1, sticky=\"n\")\n",
        "        self.stage_img_lbl = ttk.Label(mid)\n",
        "        self.stage_img_lbl.pack()\n",
        "\n",
        "        # Right: recommendations (two boxes)\n",
        "        right = ttk.Frame(main)\n",
        "        right.grid(row=0, column=2, sticky=\"nsew\")\n",
        "        right.columnconfigure(0, weight=1)\n",
        "\n",
        "        stage_box = ttk.LabelFrame(right, text=\"Recommendations (Norwood stage)\")\n",
        "        stage_box.grid(row=0, column=0, sticky=\"nsew\", pady=(0, 10))\n",
        "        self.stage_recs_box = tk.Listbox(stage_box, height=6, activestyle=\"none\")\n",
        "        self.stage_recs_box.pack(fill=\"both\", expand=True, padx=8, pady=8)\n",
        "\n",
        "        hf_box = ttk.LabelFrame(right, text=\"Recommendations (Hair loss progression)\")\n",
        "        hf_box.grid(row=1, column=0, sticky=\"nsew\")\n",
        "        self.hf_recs_box = tk.Listbox(hf_box, height=6, activestyle=\"none\")\n",
        "        self.hf_recs_box.pack(fill=\"both\", expand=True, padx=8, pady=8)\n",
        "\n",
        "        # Footer\n",
        "        self.footer_lbl = ttk.Label(self, text=\"\", font=(\"Arial\", 11))\n",
        "        self.footer_lbl.grid(row=3, column=0, sticky=\"w\", padx=40, pady=(10, 6))\n",
        "\n",
        "        # Bottom buttons (link later)\n",
        "        btns = ttk.Frame(self)\n",
        "        btns.grid(row=4, column=0, sticky=\"we\", padx=40, pady=(8, 30))\n",
        "        for i in range(3):\n",
        "            btns.columnconfigure(i, weight=1)\n",
        "\n",
        "        self.btn_about = ttk.Button(btns, text=\"LEARN MORE ABOUT US\")\n",
        "        self.btn_models = ttk.Button(btns, text=\"BROWSE OUR MODELS ON HUGGINGFACE\")\n",
        "        self.btn_prices = ttk.Button(btns, text=\"COMPARE CLINIC PRICES >\")\n",
        "\n",
        "        self.btn_about.grid(row=0, column=0, sticky=\"we\", padx=(0, 8))\n",
        "        self.btn_models.grid(row=0, column=1, sticky=\"we\", padx=8)\n",
        "        self.btn_prices.grid(row=0, column=2, sticky=\"we\", padx=(8, 0))\n",
        "\n",
        "    def _fill_listbox(self, lb: tk.Listbox, items):\n",
        "        lb.delete(0, \"end\")\n",
        "        for it in items:\n",
        "            lb.insert(\"end\", f\"â€¢ {it}\")\n",
        "\n",
        "    def _set_stage_image(self, level: int):\n",
        "        \"\"\"Load and display the per-level figure if available.\"\"\"\n",
        "        if not Image or not ImageTk:\n",
        "            self.stage_img_lbl.config(text=f\"(Stage figure {level})\")\n",
        "            return\n",
        "        path = NORWOOD_IMAGES.get(level)\n",
        "        if not path or not os.path.exists(path):\n",
        "            # fallback: show simple text if asset missing\n",
        "            self.stage_img_lbl.config(text=f\"(Add assets/norwood/{level}.png)\")\n",
        "            self.stage_img_lbl.image = None\n",
        "            return\n",
        "        try:\n",
        "            img = Image.open(path).convert(\"RGBA\")\n",
        "            # Scale nicely to a max height\n",
        "            max_h = 240\n",
        "            w, h = img.size\n",
        "            scale = min(max_h / h, 1.0)\n",
        "            if scale < 1.0:\n",
        "                img = img.resize((int(w * scale), int(h * scale)))\n",
        "            self._stage_img_tk = ImageTk.PhotoImage(img)\n",
        "            self.stage_img_lbl.config(image=self._stage_img_tk, text=\"\")\n",
        "            self.stage_img_lbl.image = self._stage_img_tk\n",
        "        except Exception:\n",
        "            self.stage_img_lbl.config(text=f\"(Couldnâ€™t load stage img {level})\")\n",
        "\n",
        "    @staticmethod\n",
        "    def _majority_vote(levels):\n",
        "        c = Counter(levels)\n",
        "        if not c:\n",
        "            return 3\n",
        "        max_count = max(c.values())\n",
        "        candidates = [lvl for lvl, cnt in c.items() if cnt == max_count]\n",
        "        return min(candidates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdhKXolP7_D3"
      },
      "source": [
        "processing_screen.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Szf6SmT8C75"
      },
      "outputs": [],
      "source": [
        "# screens/processing_screen.py\n",
        "import os\n",
        "import threading\n",
        "import traceback\n",
        "import tkinter as tk\n",
        "from tkinter import ttk\n",
        "\n",
        "try:\n",
        "    from PIL import Image, ImageTk\n",
        "except Exception:  # keep UI alive even if PIL missing\n",
        "    Image = None\n",
        "    ImageTk = None\n",
        "\n",
        "\n",
        "class ProcessingScreen(ttk.Frame):\n",
        "    \"\"\"\n",
        "    A waiting/processing view.\n",
        "    - Call `configure_job(predict_fn, args, kwargs, on_done)` before showing.\n",
        "      * predict_fn: a callable that will run on a background thread.\n",
        "      * args/kwargs: passed to predict_fn\n",
        "      * on_done(results_dict): called on the Tk thread when predict_fn returns.\n",
        "    - Call `show_uploaded_image(path)` to preview the userâ€™s photo.\n",
        "    - When this frame is raised, call `start()` to begin the job (starts spinner).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, parent, controller=None):\n",
        "        super().__init__(parent)\n",
        "        self.controller = controller\n",
        "\n",
        "        # --- Layout ---\n",
        "        self.columnconfigure(0, weight=1)\n",
        "\n",
        "        self.title_lbl = ttk.Label(\n",
        "            self, text=\"TESTING...\", anchor=\"w\",\n",
        "            font=(\"Arial\", 38, \"bold\")\n",
        "        )\n",
        "        self.title_lbl.grid(row=0, column=0, sticky=\"w\", padx=40, pady=(30, 0))\n",
        "\n",
        "        self.subtitle_lbl = ttk.Label(\n",
        "            self,\n",
        "            text=(\"PLEASE WAIT A MOMENT WHILE OUR DEEP LEARNING\\n\"\n",
        "                  \"AND MACHINE LEARNING MODELS PREDICT YOUR\\n\"\n",
        "                  \"NORWOOD SCALE STAGE, AND WHETHER THERE IS A\\n\"\n",
        "                  \"PROGRESSING HAIR LOSS\"),\n",
        "            anchor=\"w\",\n",
        "            font=(\"Arial\", 20, \"bold\")\n",
        "        )\n",
        "        self.subtitle_lbl.grid(row=1, column=0, sticky=\"w\", padx=40, pady=(6, 16))\n",
        "\n",
        "        # Preview area\n",
        "        self.preview_wrap = ttk.Frame(self)\n",
        "        self.preview_wrap.grid(row=2, column=0, sticky=\"w\", padx=40, pady=(8, 0))\n",
        "\n",
        "        self.preview_caption = ttk.Label(\n",
        "            self.preview_wrap, text=\"Your uploaded image:\",\n",
        "            font=(\"Arial\", 18)\n",
        "        )\n",
        "        self.preview_caption.grid(row=0, column=0, sticky=\"w\", pady=(0, 10))\n",
        "\n",
        "        self.preview_lbl = ttk.Label(self.preview_wrap)\n",
        "        self.preview_lbl.grid(row=1, column=0, sticky=\"w\")\n",
        "\n",
        "        # Progress area\n",
        "        self.progress_wrap = ttk.Frame(self)\n",
        "        self.progress_wrap.grid(row=3, column=0, sticky=\"we\", padx=40, pady=(30, 20))\n",
        "        self.progress_wrap.columnconfigure(0, weight=1)\n",
        "\n",
        "        self.progress = ttk.Progressbar(self.progress_wrap, mode=\"indeterminate\")\n",
        "        self.progress.grid(row=0, column=0, sticky=\"we\")\n",
        "\n",
        "        self.status_lbl = ttk.Label(self.progress_wrap, text=\"Loading modelsâ€¦\", font=(\"Arial\", 12))\n",
        "        self.status_lbl.grid(row=1, column=0, sticky=\"w\", pady=(8, 0))\n",
        "\n",
        "        # Error box (hidden unless needed)\n",
        "        self.err_box = tk.Text(self, height=8, wrap=\"word\", foreground=\"red\")\n",
        "        self.err_box.grid(row=4, column=0, sticky=\"nsew\", padx=40, pady=(10, 20))\n",
        "        self.rowconfigure(4, weight=1)\n",
        "        self.err_box.grid_remove()\n",
        "\n",
        "        # Internals\n",
        "        self._tk_img = None\n",
        "        self._predict_fn = None\n",
        "        self._job_args = ()\n",
        "        self._job_kwargs = {}\n",
        "        self._on_done = None\n",
        "        self._thread = None\n",
        "        self._anim_job = None\n",
        "        self._anim_dots = 0\n",
        "\n",
        "    # ---------------- Public API ----------------\n",
        "\n",
        "    def configure_job(self, predict_fn, args=(), kwargs=None, on_done=None):\n",
        "        \"\"\"Register the heavy job to run in a background thread.\"\"\"\n",
        "        self._predict_fn = predict_fn\n",
        "        self._job_args = args or ()\n",
        "        self._job_kwargs = kwargs or {}\n",
        "        self._on_done = on_done\n",
        "\n",
        "    def show_uploaded_image(self, image_path: str, max_size=(420, 420)):\n",
        "        \"\"\"Preview the user image (PIL) on the left.\"\"\"\n",
        "        if not Image or not ImageTk:\n",
        "            self.preview_lbl.configure(text=os.path.basename(image_path))\n",
        "            return\n",
        "        try:\n",
        "            img = Image.open(image_path).convert(\"RGB\")\n",
        "            w, h = img.size\n",
        "            scale = min(max_size[0] / w, max_size[1] / h, 1.0)\n",
        "            if scale < 1.0:\n",
        "                img = img.resize((int(w * scale), int(h * scale)))\n",
        "            self._tk_img = ImageTk.PhotoImage(img)\n",
        "            self.preview_lbl.configure(image=self._tk_img)\n",
        "        except Exception:\n",
        "            self.preview_lbl.configure(text=\"(couldnâ€™t preview image)\")\n",
        "\n",
        "    def start(self):\n",
        "        \"\"\"Begin spinner + launch background work.\"\"\"\n",
        "        self._start_spinner()\n",
        "        self._start_job_thread()\n",
        "\n",
        "    # ---------------- Internals ----------------\n",
        "\n",
        "    def _start_spinner(self):\n",
        "        self.progress.start(12)  # speed\n",
        "        self._anim_tick()\n",
        "\n",
        "    def _stop_spinner(self):\n",
        "        try:\n",
        "            self.progress.stop()\n",
        "        except Exception:\n",
        "            pass\n",
        "        if self._anim_job is not None:\n",
        "            self.after_cancel(self._anim_job)\n",
        "            self._anim_job = None\n",
        "\n",
        "    def _anim_tick(self):\n",
        "        # simple 'Loadingâ€¦', 'Loadingâ€¦..' loop\n",
        "        base = \"Processing inputâ€¦\"\n",
        "        self._anim_dots = (self._anim_dots + 1) % 6\n",
        "        self.status_lbl.configure(text=base + \".\" * self._anim_dots)\n",
        "        self._anim_job = self.after(400, self._anim_tick)\n",
        "\n",
        "    def _start_job_thread(self):\n",
        "        if self._predict_fn is None:\n",
        "            self._show_error(\"No job configured for ProcessingScreen.\")\n",
        "            return\n",
        "\n",
        "        def runner():\n",
        "            try:\n",
        "                results = self._predict_fn(*self._job_args, **self._job_kwargs)\n",
        "            except Exception as e:\n",
        "                tb = traceback.format_exc()\n",
        "                self.after(0, lambda: self._show_error(f\"{e}\\n\\n{tb}\"))\n",
        "                return\n",
        "            self.after(0, lambda: self._finish(results))\n",
        "\n",
        "        self._thread = threading.Thread(target=runner, daemon=True)\n",
        "        self._thread.start()\n",
        "\n",
        "    def _finish(self, results):\n",
        "        self._stop_spinner()\n",
        "        if callable(self._on_done):\n",
        "            try:\n",
        "                self._on_done(results)\n",
        "            except Exception as e:\n",
        "                self._show_error(f\"on_done callback failed: {e}\")\n",
        "\n",
        "    def _show_error(self, text):\n",
        "        self._stop_spinner()\n",
        "        self.err_box.grid()  # show\n",
        "        self.err_box.delete(\"1.0\", \"end\")\n",
        "        self.err_box.insert(\"end\", str(text))\n",
        "        self.status_lbl.configure(text=\"An error occurred.\")\n",
        "\n",
        "    def set_inputs(self, image_path: str, form: dict):\n",
        "        \"\"\"Compatibility wrapper used by main.py.\"\"\"\n",
        "        if image_path:\n",
        "            self.show_uploaded_image(image_path)\n",
        "        # stash for convenience if someone wants to fetch later\n",
        "        self._job_kwargs.setdefault(\"inputs\", {\"image_path\": image_path, \"form\": form})\n",
        "\n",
        "    def start_processing(self, on_done=None):\n",
        "        \"\"\"Compatibility wrapper used by main.py.\n",
        "\n",
        "        Expects the controller to expose run_full_inference(image_path, form) -> dict.\n",
        "        Falls back to any predict_fn already configured via configure_job().\n",
        "        \"\"\"\n",
        "        if callable(on_done):\n",
        "            self._on_done = on_done\n",
        "\n",
        "        # If no predict_fn configured yet, but controller has a runner, wire it up.\n",
        "        if self._predict_fn is None and hasattr(self.controller, \"run_full_inference\"):\n",
        "            inputs = self._job_kwargs.get(\"inputs\", {})\n",
        "            img = inputs.get(\"image_path\")\n",
        "            form = inputs.get(\"form\", {})\n",
        "            self.configure_job(self.controller.run_full_inference, args=(img, form))\n",
        "\n",
        "        self.start()\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Clear transient UI.\"\"\"\n",
        "        try:\n",
        "            self.progress.stop()\n",
        "        except Exception:\n",
        "            pass\n",
        "        self.status_lbl.config(text=\"Loading modelsâ€¦\")\n",
        "        self.err_box.grid_remove()\n",
        "        self.preview_lbl.configure(image=\"\", text=\"\")\n",
        "        self._tk_img = None\n",
        "        self._predict_fn = None\n",
        "        self._job_args = ()\n",
        "        self._job_kwargs = {}\n",
        "        self._on_done = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pktdfQO6-DZD"
      },
      "source": [
        "main.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNNGO_1Y-Eqq"
      },
      "outputs": [],
      "source": [
        "# main.py\n",
        "import tkinter as tk\n",
        "from tkinter import ttk, messagebox\n",
        "\n",
        "# Screens (each must expose a Frame subclass)\n",
        "from screens.loading_screen import LoadingScreen\n",
        "from screens.intake_screen import IntakeScreen\n",
        "from screens.processing_screen import ProcessingScreen\n",
        "from screens.results_screen import ResultsScreen\n",
        "from PIL import Image\n",
        "from screens.intake_screen import (\n",
        "    CLS_RESNET18, CLS_MNV3, CLS_EFFB0, CLS_CONVNEXT,\n",
        "    majority_vote, predict_xgb\n",
        ")\n",
        "\n",
        "\n",
        "class App(tk.Tk):\n",
        "    \"\"\"\n",
        "    Central controller:\n",
        "      - creates all screens\n",
        "      - exposes navigation methods for screens to call\n",
        "      - stores shared state (image path, form answers, model results)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.title(\"Hair Loss Predictor\")\n",
        "        self.geometry(\"1100x700\")\n",
        "        self.minsize(960, 640)\n",
        "\n",
        "        # Shared state between screens\n",
        "        self.shared = {\n",
        "            \"image_path\": None,\n",
        "            \"form\": {},          # your yes/no + age answers\n",
        "            \"results\": None,     # final inference payload from processing step\n",
        "        }\n",
        "\n",
        "        # Container for screens\n",
        "        container = ttk.Frame(self)\n",
        "        container.pack(fill=\"both\", expand=True)\n",
        "        container.grid_rowconfigure(0, weight=1)\n",
        "        container.grid_columnconfigure(0, weight=1)\n",
        "\n",
        "        # Instantiate screens\n",
        "        self.screens = {}\n",
        "        self.screens[\"loading\"] = LoadingScreen(\n",
        "            container,\n",
        "            controller=self,\n",
        "            logo_path=\"https://drive.google.com/file/d/1N3E_f-qyut2RHtYm29D4YJ9UY2vGRCNr/view?usp=sharing\"\n",
        "        )\n",
        "        self.screens[\"intake\"] = IntakeScreen(container, controller=self)\n",
        "        self.screens[\"processing\"] = ProcessingScreen(container, controller=self)\n",
        "        self.screens[\"results\"] = ResultsScreen(container, controller=self)\n",
        "\n",
        "        # Grid all screens (stacked)\n",
        "        for f in self.screens.values():\n",
        "            f.grid(row=0, column=0, sticky=\"nsew\")\n",
        "\n",
        "        # Start on loading screen\n",
        "        self.show(\"loading\")\n",
        "\n",
        "    # ---------- Navigation helpers ----------\n",
        "    def show(self, name: str):\n",
        "        \"\"\"Raise the given screen by key ('loading'|'intake'|'processing'|'results').\"\"\"\n",
        "        frame = self.screens[name]\n",
        "        frame.tkraise()\n",
        "        try:\n",
        "            # optional: many of our screens expose .on_show()\n",
        "            frame.on_show()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Called by IntakeScreen after user selects image + answers form\n",
        "    def go_to_processing(self, image_path: str, form: dict):\n",
        "        if not image_path:\n",
        "            messagebox.showwarning(\"Missing image\", \"Please upload an image first.\")\n",
        "            return\n",
        "\n",
        "        self.shared[\"image_path\"] = image_path\n",
        "        self.shared[\"form\"] = form or {}\n",
        "\n",
        "        proc: ProcessingScreen = self.screens[\"processing\"]  # type: ignore\n",
        "        # show a preview on the processing screen\n",
        "        proc.set_inputs(image_path=image_path, form=form)\n",
        "        # tell the processing screen how to run the job and where to send results\n",
        "        proc.configure_job(self.run_full_inference, args=(image_path, form), on_done=self._processing_finished)\n",
        "\n",
        "        self.show(\"processing\")\n",
        "        proc.start()\n",
        "\n",
        "    # Callback that processing screen invokes when all models finish\n",
        "    def _processing_finished(self, results: dict):\n",
        "        self.shared[\"results\"] = results or {}\n",
        "        # Hand results to results screen and show it\n",
        "        res: ResultsScreen = self.screens[\"results\"]  # type: ignore\n",
        "        res.set_results(self.shared[\"results\"])\n",
        "        self.show(\"results\")\n",
        "\n",
        "    # Optional â€œStart overâ€ from results\n",
        "    def start_over(self):\n",
        "        self.shared.update({\"image_path\": None, \"form\": {}, \"results\": None})\n",
        "        # Some screens may expose reset() for their UI\n",
        "        try:\n",
        "            self.screens[\"intake\"].reset()\n",
        "        except Exception:\n",
        "            pass\n",
        "        try:\n",
        "            self.screens[\"processing\"].reset()\n",
        "        except Exception:\n",
        "            pass\n",
        "        self.show(\"loading\")\n",
        "\n",
        "    def run_full_inference(self, image_path: str, form: dict) -> dict:\n",
        "        \"\"\"Loads models (lazily), runs all 4 image models + XGBoost, returns a results dict for ResultsScreen.\"\"\"\n",
        "        # Ensure models are loaded (load() is idempotent in your wrappers)\n",
        "        CLS_RESNET18.load()\n",
        "        CLS_MNV3.load()\n",
        "        CLS_EFFB0.load()\n",
        "        CLS_CONVNEXT.load()\n",
        "\n",
        "        pil = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        preds = {}\n",
        "        for name, clf in [\n",
        "            (\"resnet18\", CLS_RESNET18),\n",
        "            (\"mobilenet_v3_large\", CLS_MNV3),\n",
        "            (\"efficientnet_b0\", CLS_EFFB0),\n",
        "            (\"convnext_tiny\", CLS_CONVNEXT),\n",
        "        ]:\n",
        "            lvl, _ = clf.predict_level(pil)\n",
        "            preds[name] = lvl\n",
        "\n",
        "        final_level = majority_vote(preds)\n",
        "        y_pred, y_label, p_yes = predict_xgb(form)\n",
        "\n",
        "        return {\n",
        "            \"norwood_by_model\": preds,\n",
        "            \"norwood_final\": final_level,\n",
        "            \"hairfall_yes\": bool(y_pred == 1),\n",
        "            \"hairfall_label\": y_label,\n",
        "            \"hairfall_prob\": p_yes,\n",
        "        }\n",
        "\n",
        "    def go_to_intake(self):\n",
        "        self.show(\"intake\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    App().mainloop()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JzFbCxN-DU1"
      },
      "source": [
        "## Python Tkinter UI Screen V.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Vixe7OYMfL3"
      },
      "source": [
        "loading_screen.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2T3M1nXMhZL"
      },
      "outputs": [],
      "source": [
        "# screens/loading_screen.py\n",
        "# First screen (welcome / loading) with centered logo + fade-in\n",
        "\n",
        "import os\n",
        "from tkinter import ttk\n",
        "import io\n",
        "import re\n",
        "import requests\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    from PIL import Image, ImageTk, ImageEnhance\n",
        "except Exception:\n",
        "    Image = None\n",
        "    ImageTk = None\n",
        "    ImageEnhance = None\n",
        "\n",
        "\n",
        "class LoadingScreen(ttk.Frame):\n",
        "    \"\"\"\n",
        "    Usage:\n",
        "        root = tk.Tk()\n",
        "        screen = LoadingScreen(root,\n",
        "                               controller=my_controller,                 # must have show(next_screen_name)\n",
        "                               logo_path=\"/Users/alambebar/Desktop/Screenshot 2025-08-09 at 21.23.05\",\n",
        "                               next_screen_name=\"IntakeScreen\")\n",
        "        screen.pack(fill=\"both\", expand=True)\n",
        "        root.mainloop()\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, parent, controller=None, logo_path=None, next_screen_name=\"IntakeScreen\"):\n",
        "        super().__init__(parent)\n",
        "        self.controller = controller\n",
        "        self.logo_path = logo_path\n",
        "        self.next_screen_name = next_screen_name\n",
        "\n",
        "        self._raw_logo = None     # PIL.Image\n",
        "        self._tk_logo = None      # ImageTk.PhotoImage\n",
        "        self._fade_step = 0\n",
        "        self._fade_total = 18     # how many steps in the fade\n",
        "        self._fade_job = None\n",
        "\n",
        "        self._build_style()\n",
        "        self._build_ui()\n",
        "        self._load_logo()\n",
        "        self.after(300, self._start_animation)   # slight delay so the UI is drawn\n",
        "\n",
        "    # ---------- UI ----------\n",
        "\n",
        "    def _build_style(self):\n",
        "        style = ttk.Style(self)\n",
        "        # make sure we have a theme\n",
        "        try:\n",
        "            if style.theme_use() not in style.theme_names():\n",
        "                style.theme_use(\"clam\")\n",
        "        except Exception:\n",
        "            try:\n",
        "                style.theme_use(\"clam\")\n",
        "            except Exception:\n",
        "                pass\n",
        "        style.configure(\"Title.TLabel\", font=(\"Arial\", 36, \"bold\"))\n",
        "        style.configure(\"Subtitle.TLabel\", font=(\"Arial\", 24, \"bold\"))\n",
        "        style.configure(\"Body.TLabel\", font=(\"Arial\", 18))\n",
        "        style.configure(\"Start.TButton\", font=(\"Arial\", 16, \"bold\"))\n",
        "        style.configure(\"Small.TLabel\", font=(\"Arial\", 11))\n",
        "\n",
        "    def _build_ui(self):\n",
        "        self.columnconfigure(0, weight=1)\n",
        "        self.rowconfigure(4, weight=1)\n",
        "\n",
        "        # top welcome\n",
        "        ttk.Label(self, text=\"WELCOME\", style=\"Title.TLabel\").grid(row=0, column=0, pady=(30, 0), sticky=\"n\")\n",
        "        ttk.Label(\n",
        "            self,\n",
        "            text=(\n",
        "                \"This tool uses image preprocessing (CLAHE, segmentation, cropping), \"\n",
        "                \"majority-vote Norwood stage classification from four CNNs, and an XGBoost tabular hair-fall predictor. \"\n",
        "                \"Built with Tkinter, it provides insights for clinical use in hair-transplant settings, \"\n",
        "                \"with the goal of supporting early intervention and offering personalized recommendations based on the results.\"\n",
        "            ),\n",
        "            style=\"Subtitle.TLabel\",\n",
        "            wraplength=700,  # Adjust this value based on your window width\n",
        "            justify=\"center\"\n",
        "        ).grid(row=1, column=0, pady=(6, 0), sticky=\"n\")\n",
        "\n",
        "        ttk.Label(self,\n",
        "                  text=\"We will provide recommendations and scientifically backed preventive measures based on your predicted male pattern,\\nand estimate the number of hair follicles needed to achieve a full hairline\",\n",
        "                  style=\"Body.TLabel\", wraplength=900, justify=\"center\")\\\n",
        "           .grid(row=2, column=0, pady=(24, 12), sticky=\"n\")\n",
        "\n",
        "        # logo + progress\n",
        "        logo_wrap = ttk.Frame(self)\n",
        "        logo_wrap.grid(row=3, column=0, pady=(8, 4), sticky=\"n\")\n",
        "        self.logo_label = ttk.Label(logo_wrap)   # image set later\n",
        "        self.logo_label.pack(pady=(0, 8))\n",
        "\n",
        "        self.progress = ttk.Progressbar(self, mode=\"indeterminate\", length=280)\n",
        "        self.progress.grid(row=4, column=0, pady=(0, 20), sticky=\"n\")\n",
        "\n",
        "        # start button\n",
        "        self.start_btn = ttk.Button(self, text=\"START NOW >\", style=\"Start.TButton\",\n",
        "                                    command=self._on_start)\n",
        "        self.start_btn.grid(row=5, column=0, pady=(6, 28))\n",
        "\n",
        "        # tiny tagline box to match your mock\n",
        "        box = ttk.Frame(self, padding=16)\n",
        "        box.grid(row=6, column=0, pady=(8, 30))\n",
        "        ttk.Label(box, text=\"We are students from The Max Stern Valley College - This is our final project - Students Alam Bebar (207415407), Ryan Thawkho (305070567)\").pack()\n",
        "\n",
        "        ttk.Label(self, text=\"Tip: Your hairline is more than just hair â€” itâ€™s confidence, presence, and the best version of you. Donâ€™t settle for less.\",\n",
        "                  style=\"Small.TLabel\").grid(row=7, column=0, pady=(0, 12))\n",
        "    def _open_logo_image(self):\n",
        "        \"\"\"\n",
        "        Returns a PIL.Image in RGBA from either:\n",
        "          - local file path (self.logo_path), or\n",
        "          - URL (http/https), incl. Google Drive share links.\n",
        "        Raises on failure.\n",
        "        \"\"\"\n",
        "        if not self.logo_path:\n",
        "            raise FileNotFoundError(\"No logo_path provided\")\n",
        "\n",
        "        src = str(self.logo_path).strip()\n",
        "\n",
        "        # If it's a URL, fetch it\n",
        "        if src.startswith(\"http://\") or src.startswith(\"https://\"):\n",
        "            url = src\n",
        "            # Handle Google Drive share links\n",
        "            m = re.search(r\"/d/([a-zA-Z0-9_-]+)/\", url) or re.search(r\"[?&]id=([a-zA-Z0-9_-]+)\", url)\n",
        "            if \"drive.google.com\" in url and m:\n",
        "                file_id = m.group(1)\n",
        "                url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
        "\n",
        "            r = requests.get(url, timeout=15)\n",
        "            r.raise_for_status()\n",
        "            return Image.open(io.BytesIO(r.content)).convert(\"RGBA\")\n",
        "\n",
        "        # Otherwise, treat as local path\n",
        "        if not os.path.exists(src):\n",
        "            raise FileNotFoundError(f\"Logo file not found: {src}\")\n",
        "        return Image.open(src).convert(\"RGBA\")\n",
        "\n",
        "    # ---------- Logo handling + fade ----------\n",
        "\n",
        "    def _load_logo(self):\n",
        "        if Image is None or ImageTk is None:\n",
        "            self.logo_label.config(text=\"(logo)\")\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            img = self._open_logo_image()\n",
        "        except Exception as e:\n",
        "            # graceful fallback\n",
        "            self.logo_label.config(text=f\"(logo not available: {e})\")\n",
        "            return\n",
        "\n",
        "        # scale to ~150px wide, keep aspect\n",
        "        target_w = 150\n",
        "        w, h = img.size\n",
        "        scale = target_w / float(w) if w > target_w else 1.0\n",
        "        new_w = max(1, int(w * scale))\n",
        "        new_h = max(1, int(h * scale))\n",
        "        img = img.resize((new_w, new_h), Image.LANCZOS)\n",
        "        # start fully transparent for fade\n",
        "        img.putalpha(0)\n",
        "        self._raw_logo = img\n",
        "        self._tk_logo = ImageTk.PhotoImage(img)\n",
        "        self.logo_label.configure(image=self._tk_logo)\n",
        "\n",
        "    def _start_animation(self):\n",
        "        # run progress bar and fade the logo in\n",
        "        try:\n",
        "            self.progress.start(12)  # ms per move\n",
        "        except Exception:\n",
        "            pass\n",
        "        self._fade_step = 0\n",
        "        if self._raw_logo is not None:\n",
        "            self._schedule_fade()\n",
        "\n",
        "    def _schedule_fade(self):\n",
        "        if self._fade_step > self._fade_total:\n",
        "            return\n",
        "        alpha = int(255 * (self._fade_step / float(self._fade_total)))\n",
        "        # apply alpha\n",
        "        img = self._raw_logo.copy()\n",
        "        img.putalpha(alpha)\n",
        "        self._tk_logo = ImageTk.PhotoImage(img)\n",
        "        self.logo_label.configure(image=self._tk_logo)\n",
        "        self._fade_step += 1\n",
        "        self._fade_job = self.after(40, self._schedule_fade)  # ~0.7s total\n",
        "\n",
        "    # ---------- Navigation ----------\n",
        "\n",
        "    def _on_start(self):\n",
        "        # stop animation to keep things tidy\n",
        "        try:\n",
        "            self.progress.stop()\n",
        "        except Exception:\n",
        "            pass\n",
        "        if self._fade_job:\n",
        "            try:\n",
        "                self.after_cancel(self._fade_job)\n",
        "            except Exception:\n",
        "                pass\n",
        "            self._fade_job = None\n",
        "\n",
        "        # hand off to the next screen\n",
        "        if self.controller is not None:\n",
        "            if hasattr(self.controller, \"go_to_intake\"):\n",
        "                self.controller.go_to_intake()\n",
        "            elif hasattr(self.controller, \"show\"):\n",
        "                self.controller.show(\"intake\")\n",
        "            else:\n",
        "                print(\"[LoadingScreen] No navigation method on controller.\")\n",
        "        else:\n",
        "            print(f\"[LoadingScreen] Start clicked â†’ would show: {self.next_screen_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9evfzBIbfs1"
      },
      "source": [
        "intake_screen.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUly9IYiMQ7k"
      },
      "outputs": [],
      "source": [
        "# Screen 2: Image + Tabular Inference (Hugging Face)\n",
        "#\n",
        "# Requirements (same venv as project):\n",
        "#   pip install pillow numpy opencv-python torch torchvision efficientnet_pytorch huggingface_hub pandas joblib xgboost\n",
        "#\n",
        "# This frame expects the main app (controller) to set:\n",
        "#   - controller.shared[\"image_path\"] : str (path to the image picked in screen 1)\n",
        "#   - controller.shared[\"form\"]       : dict with keys:\n",
        "#        stay_up_late, water_reason, family_history, use_chemicals,\n",
        "#        stress, chronic_illness, age\n",
        "#\n",
        "# It renders:\n",
        "#   - image preview (left)\n",
        "#   - per-model predictions + majority vote (right, upper)\n",
        "#   - XGBoost hair fall prediction + probability (right, lower)\n",
        "\n",
        "import threading\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Tuple, Optional\n",
        "\n",
        "import tkinter as tk\n",
        "from tkinter import ttk, messagebox, filedialog\n",
        "\n",
        "# visuals\n",
        "from PIL import Image, ImageTk\n",
        "import cv2, numpy as np\n",
        "\n",
        "# â”€â”€ ML deps\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from huggingface_hub import hf_hub_download\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "import os, certifi\n",
        "os.environ[\"SSL_CERT_FILE\"] = certifi.where()\n",
        "os.environ[\"REQUESTS_CA_BUNDLE\"] = certifi.where()\n",
        "\n",
        "# ===== Hair Segmentation (exact HF setup you provided) =====\n",
        "REPO_ID   = \"alamb98/deeplabv3-hair-segmentation\"\n",
        "CKPT_NAME = \"deeplabv3_final.pth\"\n",
        "BACKBONE    = \"resnet50\"      # \"resnet50\" or \"resnet101\"\n",
        "NUM_CLASSES = 2               # background, hair\n",
        "HAIR_CLASS  = 1\n",
        "IMG_SIZE    = 256\n",
        "MEAN = [0.485, 0.456, 0.406]\n",
        "STD  = [0.229, 0.224, 0.225]\n",
        "EXPAND_RATIO = 0.01  # 1% of max(w, h) expansion around the hair bbox\n",
        "\n",
        "_SEG_MODEL = None\n",
        "_SEG_DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "_SEG_TFM = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=MEAN, std=STD),\n",
        "])\n",
        "\n",
        "def _get_seg_model():\n",
        "    global _SEG_MODEL\n",
        "    if _SEG_MODEL is not None:\n",
        "        return _SEG_MODEL\n",
        "    from torchvision.models.segmentation import deeplabv3_resnet50, deeplabv3_resnet101\n",
        "    if BACKBONE == \"resnet50\":\n",
        "        model = deeplabv3_resnet50(weights=None, num_classes=NUM_CLASSES, aux_loss=None)\n",
        "    elif BACKBONE == \"resnet101\":\n",
        "        model = deeplabv3_resnet101(weights=None, num_classes=NUM_CLASSES, aux_loss=None)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported BACKBONE.\")\n",
        "    ckpt_path = hf_hub_download(repo_id=REPO_ID, filename=CKPT_NAME)\n",
        "    state = torch.load(ckpt_path, map_location=\"cpu\")\n",
        "    if isinstance(state, dict) and \"state_dict\" in state and isinstance(state[\"state_dict\"], dict):\n",
        "        state = state[\"state_dict\"]\n",
        "    fixed = {}\n",
        "    if isinstance(state, dict):\n",
        "        for k, v in state.items():\n",
        "            if k.startswith(\"module.\"): k = k[7:]\n",
        "            if k.startswith(\"model.\"):  k = k[6:]\n",
        "            fixed[k] = v\n",
        "    else:\n",
        "        fixed = state\n",
        "    model.load_state_dict(fixed, strict=False)\n",
        "    model.to(_SEG_DEVICE).eval()\n",
        "    _SEG_MODEL = model\n",
        "    return _SEG_MODEL\n",
        "\n",
        "def _apply_clahe_bgr(img_bgr):\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    cl = clahe.apply(l)\n",
        "    merged = cv2.merge((cl, a, b))\n",
        "    return cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "def preprocess_with_segmentation(image_path: str) -> Image.Image:\n",
        "    \"\"\"\n",
        "    Loads image, applies CLAHE (exact params), runs DeeplabV3 segmentation (exact HF config),\n",
        "    crops around the hair bounding box with EXPAND_RATIO margin, draws red boundary on the\n",
        "    CROPPED image, and returns a PIL RGB image to feed the classifiers.\n",
        "    \"\"\"\n",
        "    # Load original (PIL) for size reference & later overlay\n",
        "    orig_pil = Image.open(image_path).convert(\"RGB\")\n",
        "    W, H = orig_pil.size\n",
        "\n",
        "    # OpenCV BGR for CLAHE\n",
        "    bgr = cv2.cvtColor(np.array(orig_pil), cv2.COLOR_RGB2BGR)\n",
        "    bgr = _apply_clahe_bgr(bgr)  # exact CLAHE\n",
        "\n",
        "    # Prepare model input from the (CLAHE-enhanced) RGB\n",
        "    pil_after_clahe = Image.fromarray(cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB))\n",
        "    x = _SEG_TFM(pil_after_clahe).unsqueeze(0).to(_SEG_DEVICE)\n",
        "\n",
        "    # Inference (exact DeeplabV3 config)\n",
        "    model = _get_seg_model()\n",
        "    with torch.no_grad():\n",
        "        out = model(x)\n",
        "        logits = out[\"out\"][0] if isinstance(out, dict) else out[0]\n",
        "        probs  = torch.softmax(logits, dim=0)\n",
        "        hair_p = probs[HAIR_CLASS].cpu().numpy()\n",
        "\n",
        "    # Resize prob map back to original, Otsu threshold, small morph cleanup (exact)\n",
        "    hair_p = cv2.resize(hair_p, (W, H), interpolation=cv2.INTER_LINEAR)\n",
        "    hair_u8 = np.clip(hair_p * 255.0, 0, 255).astype(np.uint8)\n",
        "    _, mask_u8 = cv2.threshold(hair_u8, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    mask_u8 = cv2.morphologyEx(mask_u8, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "    mask_u8 = cv2.morphologyEx(mask_u8, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
        "\n",
        "    # Find hair bounding box from mask (merge all contours)\n",
        "    contours, _ = cv2.findContours(mask_u8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if len(contours) == 0:\n",
        "        # No hair found â†’ fall back to full image\n",
        "        x, y, w, h = 0, 0, W, H\n",
        "    else:\n",
        "        all_pts = np.vstack(contours).squeeze()\n",
        "        xs, ys = all_pts[:, 0], all_pts[:, 1]\n",
        "        x_min, x_max = xs.min(), xs.max()\n",
        "        y_min, y_max = ys.min(), ys.max()\n",
        "        x, y, w, h = int(x_min), int(x_max - x_min), int(y_min), int(y_max - y_min)\n",
        "        # Note: carefulâ€”above was mixed; fix ordering properly:\n",
        "        x, y, w, h = int(x_min), int(y_min), int(x_max - x_min), int(y_max - y_min)\n",
        "\n",
        "    # Expand bbox by EXPAND_RATIO * max(w, h) and clamp to image bounds\n",
        "    margin = int(EXPAND_RATIO * max(w, h))\n",
        "    x1 = max(0, x - margin)\n",
        "    y1 = max(0, y - margin)\n",
        "    x2 = min(W, x + w + margin)\n",
        "    y2 = min(H, y + h + margin)\n",
        "\n",
        "    # Crop CLAHE-enhanced image and corresponding mask\n",
        "    cropped_bgr  = bgr[y1:y2, x1:x2]\n",
        "    cropped_mask = mask_u8[y1:y2, x1:x2]\n",
        "    if cropped_bgr.size == 0:  # safety fallback\n",
        "        cropped_bgr  = bgr.copy()\n",
        "        cropped_mask = mask_u8.copy()\n",
        "\n",
        "    # DO NOT draw contours on the image we feed to the models\n",
        "    cropped_rgb = cv2.cvtColor(cropped_bgr, cv2.COLOR_BGR2RGB)\n",
        "    return Image.fromarray(cropped_rgb)\n",
        "\n",
        "def preprocess_clahe_only(image_path: str) -> Image.Image:\n",
        "    \"\"\"\n",
        "    Apply the exact CLAHE you use elsewhere, but NO segmentation/cropping.\n",
        "    Returns a PIL RGB image (full frame) for model input.\n",
        "    \"\"\"\n",
        "    orig_pil = Image.open(image_path).convert(\"RGB\")\n",
        "    bgr = cv2.cvtColor(np.array(orig_pil), cv2.COLOR_RGB2BGR)\n",
        "    bgr = _apply_clahe_bgr(bgr)  # same CLAHE params (clipLimit=2.0, tileGridSize=(8,8))\n",
        "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
        "    return Image.fromarray(rgb)\n",
        "\n",
        "# ========== Shared UI helpers ==========\n",
        "def pil_to_tk(pil_img: Image.Image, max_size=(360, 360)):\n",
        "    w, h = pil_img.size\n",
        "    scale = min(max_size[0] / w, max_size[1] / h, 1.0)\n",
        "    if scale < 1.0:\n",
        "        pil_img = pil_img.resize((int(w * scale), int(h * scale)))\n",
        "    return ImageTk.PhotoImage(pil_img)\n",
        "\n",
        "# ========== Classifier wrappers (your exact HF logic) ==========\n",
        "\n",
        "@dataclass\n",
        "class ImageClassifier:\n",
        "    name: str\n",
        "    repo: str\n",
        "    weights_file: str\n",
        "    meta_file: str = \"metadata.json\"\n",
        "    model: Optional[torch.nn.Module] = None\n",
        "    tfm: Optional[object] = None\n",
        "    level_names: Optional[list] = None\n",
        "    label_base: int = 0\n",
        "    img_size: int = 224\n",
        "    mean: Tuple[float, float, float] = (0.485, 0.456, 0.406)\n",
        "    std: Tuple[float, float, float] = (0.229, 0.224, 0.225)\n",
        "\n",
        "    def _load_meta(self):\n",
        "        meta_path = hf_hub_download(self.repo, filename=self.meta_file)\n",
        "        with open(meta_path, \"r\") as f:\n",
        "            meta = json.load(f)\n",
        "        # labels field might be \"labels\" or \"class_names\"\n",
        "        self.level_names = meta.get(\"labels\") or meta.get(\"class_names\") or [f\"Level {i}\" for i in range(2, 8)]\n",
        "        self.img_size = int(meta.get(\"img_size\", 224))\n",
        "        self.mean = tuple(meta.get(\"mean\", [0.485, 0.456, 0.406]))\n",
        "        self.std = tuple(meta.get(\"std\", [0.229, 0.224, 0.225]))\n",
        "        self.label_base = int(meta.get(\"label_base\", 0))\n",
        "\n",
        "    def _build_resnet18(self):\n",
        "        model = models.resnet18(weights=None)\n",
        "        in_features = model.fc.in_features\n",
        "        model.fc = nn.Linear(in_features, len(self.level_names))\n",
        "        return model\n",
        "\n",
        "    def _build_mobilenet_v3_large(self):\n",
        "        model = models.mobilenet_v3_large(weights=None)\n",
        "        in_features = model.classifier[3].in_features\n",
        "        model.classifier[3] = nn.Linear(in_features, len(self.level_names))\n",
        "        return model\n",
        "\n",
        "    def _build_efficientnet_b0(self):\n",
        "        model = EfficientNet.from_name(\"efficientnet-b0\")\n",
        "        in_features = model._fc.in_features\n",
        "        model._fc = nn.Linear(in_features, len(self.level_names))\n",
        "        return model\n",
        "\n",
        "    def _build_convnext_tiny(self):\n",
        "        model = models.convnext_tiny(weights=None)\n",
        "        in_features = model.classifier[2].in_features\n",
        "        model.classifier[2] = nn.Linear(in_features, len(self.level_names))\n",
        "        return model\n",
        "\n",
        "    def _build_by_name(self):\n",
        "        if self.name == \"resnet18\":\n",
        "            return self._build_resnet18()\n",
        "        if self.name == \"mobilenet_v3_large\":\n",
        "            return self._build_mobilenet_v3_large()\n",
        "        if self.name == \"efficientnet_b0\":\n",
        "            return self._build_efficientnet_b0()\n",
        "        if self.name == \"convnext_tiny\":\n",
        "            return self._build_convnext_tiny()\n",
        "        raise ValueError(f\"Unknown model name: {self.name}\")\n",
        "\n",
        "    def _build_tfm(self):\n",
        "        self.tfm = transforms.Compose([\n",
        "            transforms.Resize((self.img_size, self.img_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=self.mean, std=self.std),\n",
        "        ])\n",
        "\n",
        "    def load(self):\n",
        "        if self.model is not None and self.tfm is not None:\n",
        "            return\n",
        "        # metadata\n",
        "        self._load_meta()\n",
        "        # weights\n",
        "        wpath = hf_hub_download(self.repo, filename=self.weights_file)\n",
        "        # arch\n",
        "        self.model = self._build_by_name()\n",
        "        # state\n",
        "        state = torch.load(wpath, map_location=\"cpu\")\n",
        "        if isinstance(state, dict) and \"state_dict\" in state and isinstance(state[\"state_dict\"], dict):\n",
        "            state = state[\"state_dict\"]\n",
        "        fixed = {}\n",
        "        if isinstance(state, dict):\n",
        "            for k, v in state.items():\n",
        "                if isinstance(k, str) and k.startswith(\"module.\"):\n",
        "                    k = k[len(\"module.\"):]\n",
        "                if isinstance(k, str) and k.startswith(\"model.\"):\n",
        "                    k = k[len(\"model.\"):]\n",
        "                fixed[k] = v\n",
        "        else:\n",
        "            fixed = state\n",
        "        self.model.load_state_dict(fixed, strict=True)\n",
        "        self.model.eval()\n",
        "        # tfm\n",
        "        self._build_tfm()\n",
        "\n",
        "    def predict_level(self, pil_rgb: Image.Image) -> Tuple[int, str]:\n",
        "        x = self.tfm(pil_rgb).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            logits = self.model(x)\n",
        "            pred_idx = int(logits.argmax(-1).item())  # 0-based class index\n",
        "\n",
        "        # Numeric level anchored to label_base (0 means \"use +1\")\n",
        "        base = int(self.label_base) if self.label_base is not None else 0\n",
        "        level = pred_idx + (1 if base == 0 else base)\n",
        "\n",
        "        # Human-readable label: pick directly by class index\n",
        "        if self.level_names and 0 <= pred_idx < len(self.level_names):\n",
        "            label_str = self.level_names[pred_idx]\n",
        "        else:\n",
        "            label_str = f\"Level {level}\"\n",
        "\n",
        "        # If labels look like \"Level 2\", trust that number to keep both in sync\n",
        "        try:\n",
        "            import re\n",
        "            m = re.search(r'(\\d+)', label_str)\n",
        "            if m:\n",
        "                level = int(m.group(1))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        return level, label_str\n",
        "\n",
        "\n",
        "# Instantiate the four models (lazy-loaded)\n",
        "CLS_RESNET18 = ImageClassifier(\n",
        "    name=\"resnet18\",\n",
        "    repo=\"alamb98/resnet18\",\n",
        "    weights_file=\"resnet18.pth\",\n",
        ")\n",
        "\n",
        "CLS_MNV3 = ImageClassifier(\n",
        "    name=\"mobilenet_v3_large\",\n",
        "    repo=\"alamb98/mobilenet_v3_large_cropped_clahe_norwood_classifier\",\n",
        "    weights_file=\"mobilenet_v3_large_cropped_clahe_best.pth\",\n",
        ")\n",
        "\n",
        "CLS_EFFB0 = ImageClassifier(\n",
        "    name=\"efficientnet_b0\",\n",
        "    repo=\"alamb98/efficientnet-b0_norwood_classifier\",\n",
        "    weights_file=\"efficientnet-b0_best.pth\",\n",
        ")\n",
        "\n",
        "CLS_CONVNEXT = ImageClassifier(\n",
        "    name=\"convnext_tiny\",\n",
        "    repo=\"alamb98/convnext_tiny_clahe_norwood_classifier\",\n",
        "    weights_file=\"convnext_tiny_clahe_best.pth\",\n",
        ")\n",
        "\n",
        "# ========== XGBoost HF joblib (exact feature order you provided) ==========\n",
        "\n",
        "XGB_REPO = \"alamb98/xgboost_hair_fall_classifier\"\n",
        "XGB_FILENAME = \"xgboost_hair_fall_classifier.joblib\"\n",
        "\n",
        "FEATURE_COLUMNS = [\n",
        "    \"Do you stay up late at night?_Yes\",\n",
        "    \"Do you think that in your area water is a reason behind hair fall problems?_Yes\",\n",
        "    \"Is there anyone in your family having a hair fall problem or a baldness issue?_Yes\",\n",
        "    \"Do you use chemicals, hair gel, or color in your hair?_Yes\",\n",
        "    \"Do you have too much stress_Yes\",\n",
        "    \"Did you face any type of chronic illness in the past?_Yes\",\n",
        "    \"What is your age ?\"\n",
        "]\n",
        "\n",
        "_xgb_model_cache = None\n",
        "\n",
        "def _to01(v):\n",
        "    v = str(v).strip().lower()\n",
        "    return 1 if v in (\"yes\", \"y\", \"1\", \"true\", \"t\") else 0\n",
        "\n",
        "def form_to_features(form: dict) -> pd.DataFrame:\n",
        "    row = {\n",
        "        \"Do you stay up late at night?_Yes\": _to01(form.get(\"stay_up_late\", \"No\")),\n",
        "        \"Do you think that in your area water is a reason behind hair fall problems?_Yes\": _to01(form.get(\"water_reason\", \"No\")),\n",
        "        \"Is there anyone in your family having a hair fall problem or a baldness issue?_Yes\": _to01(form.get(\"family_history\", \"No\")),\n",
        "        \"Do you use chemicals, hair gel, or color in your hair?_Yes\": _to01(form.get(\"use_chemicals\", \"No\")),\n",
        "        \"Do you have too much stress_Yes\": _to01(form.get(\"stress\", \"No\")),\n",
        "        \"Did you face any type of chronic illness in the past?_Yes\": _to01(form.get(\"chronic_illness\", \"No\")),\n",
        "        \"What is your age ?\": float(form.get(\"age\", 0)),\n",
        "    }\n",
        "    return pd.DataFrame([row], columns=FEATURE_COLUMNS)\n",
        "\n",
        "def load_xgb():\n",
        "    global _xgb_model_cache\n",
        "    if _xgb_model_cache is None:\n",
        "        model_path = hf_hub_download(repo_id=XGB_REPO, filename=XGB_FILENAME)\n",
        "        _xgb_model_cache = joblib.load(model_path)\n",
        "    return _xgb_model_cache\n",
        "\n",
        "def predict_xgb(form: dict):\n",
        "    mdl = load_xgb()\n",
        "    X = form_to_features(form).astype(float)\n",
        "    y_pred = int(mdl.predict(X)[0])\n",
        "    if hasattr(mdl, \"predict_proba\"):\n",
        "        proba_yes = float(mdl.predict_proba(X)[0][1])\n",
        "    else:\n",
        "        proba_yes = float(\"nan\")\n",
        "    label = {0: \"No hair fall\", 1: \"Yes hair fall\"}.get(y_pred, str(y_pred))\n",
        "    return y_pred, label, proba_yes\n",
        "\n",
        "# ========== Majority vote helper ==========\n",
        "\n",
        "def majority_vote(levels: Dict[str, int]) -> int:\n",
        "    from collections import Counter\n",
        "    arr = list(levels.values())\n",
        "    c = Counter(arr)\n",
        "    maxc = max(c.values()) if c else 0\n",
        "    winners = [lvl for lvl, cnt in c.items() if cnt == maxc] if c else [3]\n",
        "    return min(winners)\n",
        "\n",
        "# ========== Tkinter Screen ==========\n",
        "\n",
        "class IntakeScreen(ttk.Frame):\n",
        "    \"\"\"\n",
        "    Usage:\n",
        "      screen = ModelsScreen(parent, controller)\n",
        "      controller.shared must include:\n",
        "        - \"image_path\": str\n",
        "        - \"form\": dict (keys listed above)\n",
        "    \"\"\"\n",
        "    def __init__(self, parent, controller):\n",
        "        super().__init__(parent)\n",
        "        self.controller = controller\n",
        "\n",
        "        # --- Header ---\n",
        "        hdr = ttk.Frame(self)\n",
        "        hdr.pack(fill=\"x\", pady=10, padx=16)\n",
        "        ttk.Label(hdr, text=\"Run Models\", font=(\"Arial\", 18, \"bold\")).pack(side=\"left\")\n",
        "\n",
        "        # --- Body (left: preview, right: results) ---\n",
        "        body = ttk.Frame(self)\n",
        "        body.pack(fill=\"both\", expand=True, padx=16, pady=8)\n",
        "\n",
        "        # --- Toolbar: choose image ---\n",
        "        tools = ttk.Frame(self)\n",
        "        tools.pack(fill=\"x\", padx=16, pady=(0, 8))\n",
        "\n",
        "        ttk.Button(tools, text=\"Choose Imageâ€¦\", command=self.on_choose_image).pack(side=\"left\")\n",
        "\n",
        "        self.path_var = tk.StringVar(value=\"No image selected\")\n",
        "        ttk.Label(tools, textvariable=self.path_var).pack(side=\"left\", padx=10)\n",
        "\n",
        "        # Left: image preview (original + processed)\n",
        "        left = ttk.LabelFrame(body, text=\"Input Image\")\n",
        "        left.pack(side=\"left\", fill=\"both\", expand=True, padx=(0, 10))\n",
        "\n",
        "        # Original\n",
        "        self.preview_orig = ttk.Label(left, text=\"No image\")\n",
        "        self.preview_orig.pack(fill=\"both\", expand=True, padx=10, pady=(10, 5))\n",
        "\n",
        "        # Processed\n",
        "        self.preview_proc = ttk.Label(left, text=\"(Processed will appear here)\")\n",
        "        self.preview_proc.pack(fill=\"both\", expand=True, padx=10, pady=(5, 10))\n",
        "\n",
        "        # Right: predictions\n",
        "        right = ttk.LabelFrame(body, text=\"Predictions\")\n",
        "        right.pack(side=\"left\", fill=\"both\", expand=True, padx=(10, 0))\n",
        "\n",
        "        # Progress\n",
        "        self.pbar = ttk.Progressbar(right, mode=\"determinate\", maximum=100)\n",
        "        self.pbar.pack(fill=\"x\", padx=12, pady=(10, 4))\n",
        "        self.status = ttk.Label(right, text=\"Idle.\")\n",
        "        self.status.pack(fill=\"x\", padx=12)\n",
        "\n",
        "        # Per-model results\n",
        "        self.txt = tk.Text(right, height=18, wrap=\"word\")\n",
        "        self.txt.pack(fill=\"both\", expand=True, padx=12, pady=10)\n",
        "\n",
        "        # Footer buttons\n",
        "        ftr = ttk.Frame(self)\n",
        "        ftr.pack(fill=\"x\", pady=10, padx=16)\n",
        "        ttk.Button(ftr, text=\"Back\", command=self.on_back).pack(side=\"left\")\n",
        "        ttk.Button(ftr, text=\"Run Predictions\", command=self.on_run).pack(side=\"right\")\n",
        "\n",
        "        # NEW: view recommendations button (starts disabled; enabled after _worker finishes)\n",
        "        self.view_btn = ttk.Button(ftr, text=\"View Recommendations â†’\",\n",
        "                                   command=self.on_view_results, state=\"disabled\")\n",
        "        self.view_btn.pack(side=\"right\", padx=(0, 8))\n",
        "\n",
        "        # keep a place to store last results\n",
        "        self._last_results = None\n",
        "        # Auto show preview if available\n",
        "        self.after(50, self._refresh_preview)\n",
        "\n",
        "        # --- Form: features for XGBoost ---\n",
        "        form_wrap = ttk.LabelFrame(body, text=\"Tabular Features\")\n",
        "        form_wrap.pack(side=\"left\", fill=\"y\", padx=(0, 10), pady=0)\n",
        "\n",
        "        # Variables\n",
        "        self.var_stay_up_late   = tk.StringVar(value=\"No\")\n",
        "        self.var_water_reason   = tk.StringVar(value=\"No\")\n",
        "        self.var_family_history = tk.StringVar(value=\"No\")\n",
        "        self.var_use_chemicals  = tk.StringVar(value=\"No\")\n",
        "        self.var_stress         = tk.StringVar(value=\"No\")\n",
        "        self.var_chronic        = tk.StringVar(value=\"No\")\n",
        "        self.var_age            = tk.StringVar(value=\"25\")  # keep as string, we cast later\n",
        "\n",
        "        def yn_row(parent, label, var):\n",
        "            r = ttk.Frame(parent); r.pack(fill=\"x\", padx=8, pady=4)\n",
        "            ttk.Label(r, text=label, width=34, anchor=\"w\").pack(side=\"left\")\n",
        "            cb = ttk.Combobox(r, textvariable=var, state=\"readonly\", values=[\"No\", \"Yes\"], width=6)\n",
        "            cb.pack(side=\"left\")\n",
        "            return cb\n",
        "\n",
        "        yn_row(form_wrap, \"Do you stay up late at night?\", self.var_stay_up_late)\n",
        "        yn_row(form_wrap, \"Water in your area a reason?\", self.var_water_reason)\n",
        "        yn_row(form_wrap, \"Family hair fall/baldness history?\", self.var_family_history)\n",
        "        yn_row(form_wrap, \"Use chemicals/gel/color?\", self.var_use_chemicals)\n",
        "        yn_row(form_wrap, \"Too much stress?\", self.var_stress)\n",
        "        yn_row(form_wrap, \"Chronic illness in the past?\", self.var_chronic)\n",
        "\n",
        "        age_row = ttk.Frame(form_wrap); age_row.pack(fill=\"x\", padx=8, pady=(8,4))\n",
        "        ttk.Label(age_row, text=\"Age\", width=34, anchor=\"w\").pack(side=\"left\")\n",
        "        ttk.Entry(age_row, textvariable=self.var_age, width=8).pack(side=\"left\")\n",
        "\n",
        "    def _compute_cropped_mask(self, image_path: str):\n",
        "        \"\"\"\n",
        "        Recompute the hair mask exactly like preprocess_with_segmentation,\n",
        "        then crop it with the same expanded bbox. Returns a binary uint8 mask.\n",
        "        \"\"\"\n",
        "        orig_pil = Image.open(image_path).convert(\"RGB\")\n",
        "        W, H = orig_pil.size\n",
        "\n",
        "        # CLAHE on BGR (same as your segmentation input)\n",
        "        bgr = cv2.cvtColor(np.array(orig_pil), cv2.COLOR_RGB2BGR)\n",
        "        bgr = _apply_clahe_bgr(bgr)\n",
        "\n",
        "        # Segment (same exact config)\n",
        "        pil_after_clahe = Image.fromarray(cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB))\n",
        "        x = _SEG_TFM(pil_after_clahe).unsqueeze(0).to(_SEG_DEVICE)\n",
        "        model = _get_seg_model()\n",
        "        with torch.no_grad():\n",
        "            out = model(x)\n",
        "            logits = out[\"out\"][0] if isinstance(out, dict) else out[0]\n",
        "            probs = torch.softmax(logits, dim=0)\n",
        "            hair_p = probs[HAIR_CLASS].cpu().numpy()\n",
        "\n",
        "        # Mask (resize back + Otsu + morph) â€“ identical to preprocess\n",
        "        hair_p = cv2.resize(hair_p, (W, H), interpolation=cv2.INTER_LINEAR)\n",
        "        hair_u8 = np.clip(hair_p * 255.0, 0, 255).astype(np.uint8)\n",
        "        _, mask_u8 = cv2.threshold(hair_u8, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        kernel = np.ones((3, 3), np.uint8)\n",
        "        mask_u8 = cv2.morphologyEx(mask_u8, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "        mask_u8 = cv2.morphologyEx(mask_u8, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
        "\n",
        "        # Same bbox + expand logic\n",
        "        contours, _ = cv2.findContours(mask_u8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        if len(contours) == 0:\n",
        "            x, y, w, h = 0, 0, W, H\n",
        "        else:\n",
        "            all_pts = np.vstack(contours).squeeze()\n",
        "            xs, ys = all_pts[:, 0], all_pts[:, 1]\n",
        "            x_min, x_max = xs.min(), xs.max()\n",
        "            y_min, y_max = ys.min(), ys.max()\n",
        "            x, y, w, h = int(x_min), int(y_min), int(x_max - x_min), int(y_max - y_min)\n",
        "\n",
        "        margin = int(EXPAND_RATIO * max(w, h))\n",
        "        x1 = max(0, x - margin);\n",
        "        y1 = max(0, y - margin)\n",
        "        x2 = min(W, x + w + margin);\n",
        "        y2 = min(H, y + h + margin)\n",
        "\n",
        "        cropped_mask = mask_u8[y1:y2, x1:x2]\n",
        "        if cropped_mask.size == 0:\n",
        "            cropped_mask = mask_u8.copy()\n",
        "        return cropped_mask\n",
        "\n",
        "    def _refresh_preview(self):\n",
        "        img_path = self.controller.shared.get(\"image_path\")\n",
        "        self.path_var.set(img_path or \"No image selected\")\n",
        "        if not img_path:\n",
        "            try:\n",
        "                self.preview_orig.configure(text=\"No image selected\", image=\"\")\n",
        "            except Exception:\n",
        "                pass\n",
        "            try:\n",
        "                self.preview_proc.configure(text=\"(Processed will appear here)\", image=\"\")\n",
        "                self.preview_proc.image = None\n",
        "            except Exception:\n",
        "                pass\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            # Original (top)\n",
        "            pil_orig = Image.open(img_path).convert(\"RGB\")\n",
        "            tk_img_orig = pil_to_tk(pil_orig)\n",
        "            self.preview_orig.configure(image=tk_img_orig, text=\"\")\n",
        "            self.preview_orig.image = tk_img_orig\n",
        "\n",
        "            # Clean processed for models (no red outline)\n",
        "            pil_proc_clean = preprocess_with_segmentation(img_path)\n",
        "\n",
        "            # Preview-only red outline from REAL cropped mask\n",
        "            cropped_mask = self._compute_cropped_mask(img_path)\n",
        "            arr = np.array(pil_proc_clean)\n",
        "            bgr = cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)\n",
        "            contours, _ = cv2.findContours(cropped_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            bgr_preview = bgr.copy()\n",
        "            cv2.drawContours(bgr_preview, contours, -1, (0, 0, 255), 2)\n",
        "            pil_proc_preview = Image.fromarray(cv2.cvtColor(bgr_preview, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "            tk_img_proc = pil_to_tk(pil_proc_preview)\n",
        "            self.preview_proc.configure(image=tk_img_proc, text=\"\")\n",
        "            self.preview_proc.image = tk_img_proc\n",
        "\n",
        "        except Exception as e:\n",
        "            try:\n",
        "                self.preview_orig.configure(text=f\"Failed to load image:\\n{e}\", image=\"\")\n",
        "                self.preview_orig.image = None\n",
        "            except Exception:\n",
        "                pass\n",
        "            try:\n",
        "                self.preview_proc.configure(text=\"(Processing failed)\", image=\"\")\n",
        "                self.preview_proc.image = None\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    def on_back(self):\n",
        "        if hasattr(self.controller, \"show\"):\n",
        "            self.controller.show(\"loading\")\n",
        "        else:\n",
        "            messagebox.showinfo(\"Back\", \"Implement controller.show(...) to navigate.\")\n",
        "\n",
        "    def on_show(self):\n",
        "        self._refresh_preview()\n",
        "        form = self.controller.shared.get(\"form\", {})\n",
        "        if form:\n",
        "            self.var_stay_up_late.set(\"Yes\" if form.get(\"stay_up_late\", \"No\") in (\"Yes\", \"yes\", 1, True) else \"No\")\n",
        "            self.var_water_reason.set(\"Yes\" if form.get(\"water_reason\", \"No\") in (\"Yes\", \"yes\", 1, True) else \"No\")\n",
        "            self.var_family_history.set(\"Yes\" if form.get(\"family_history\", \"No\") in (\"Yes\", \"yes\", 1, True) else \"No\")\n",
        "            self.var_use_chemicals.set(\"Yes\" if form.get(\"use_chemicals\", \"No\") in (\"Yes\", \"yes\", 1, True) else \"No\")\n",
        "            self.var_stress.set(\"Yes\" if form.get(\"stress\", \"No\") in (\"Yes\", \"yes\", 1, True) else \"No\")\n",
        "            self.var_chronic.set(\"Yes\" if form.get(\"chronic_illness\", \"No\") in (\"Yes\", \"yes\", 1, True) else \"No\")\n",
        "            try:\n",
        "                self.var_age.set(str(form.get(\"age\", \"\")))\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    def on_run(self):\n",
        "        img_path = self.controller.shared.get(\"image_path\")\n",
        "        if not img_path:\n",
        "            messagebox.showwarning(\"Missing image\", \"Please select an image on the first screen.\")\n",
        "            return\n",
        "\n",
        "        # collect and save the form so other screens can access it too\n",
        "        form = self._collect_form()\n",
        "        if hasattr(self.controller, \"shared\"):\n",
        "            self.controller.shared[\"form\"] = form\n",
        "\n",
        "        # clear UI + start\n",
        "        self.txt.delete(\"1.0\", \"end\")\n",
        "        self.status.config(text=\"Downloading / loading modelsâ€¦\")\n",
        "        self.pbar[\"value\"] = 0\n",
        "\n",
        "        t = threading.Thread(target=self._worker, args=(img_path, form), daemon=True)\n",
        "        t.start()\n",
        "\n",
        "    # Full replacement in _worker:\n",
        "    def _worker(self, img_path: str, form: dict):\n",
        "        try:\n",
        "            steps = [\n",
        "                (\"Load resnet18\", lambda: CLS_RESNET18.load()),\n",
        "                (\"Load mobilenet_v3_large\", lambda: CLS_MNV3.load()),\n",
        "                (\"Load efficientnet_b0\", lambda: CLS_EFFB0.load()),\n",
        "                (\"Load convnext_tiny\", lambda: CLS_CONVNEXT.load()),\n",
        "                (\"Load hair segmentation model\", lambda: _get_seg_model()),\n",
        "            ]\n",
        "            per_step = 50 / max(1, len(steps))  # first ~50% for loading (now includes seg)\n",
        "            for name, fn in steps:\n",
        "                self._ui_progress(name)\n",
        "                fn()\n",
        "                self._ui_bump(per_step)\n",
        "\n",
        "            # --- Build both inputs ---\n",
        "            self._ui_progress(\"Preprocessing imagesâ€¦\")\n",
        "            pil_proc = preprocess_with_segmentation(img_path)  # CLAHE + seg + crop (clean)\n",
        "            pil_clahe = preprocess_clahe_only(img_path)  # CLAHE only (full frame)\n",
        "            self._ui_bump(5)\n",
        "\n",
        "            # --- Inference on processed image ---\n",
        "            preds_proc = {}\n",
        "            for nick, clf in [\n",
        "                (\"resnet18\", CLS_RESNET18),\n",
        "                (\"mobilenet_v3_large\", CLS_MNV3),\n",
        "                (\"efficientnet_b0\", CLS_EFFB0),\n",
        "                (\"convnext_tiny\", CLS_CONVNEXT),\n",
        "            ]:\n",
        "                self._ui_progress(f\"Processed image â†’ {nick}â€¦\")\n",
        "                lvl, _ = clf.predict_level(pil_proc)\n",
        "                preds_proc[nick] = lvl\n",
        "                self._ui_bump(5)\n",
        "\n",
        "            final_proc = majority_vote(preds_proc)\n",
        "\n",
        "            # --- Inference on CLAHE-only image ---\n",
        "            preds_clahe = {}\n",
        "            for nick, clf in [\n",
        "                (\"resnet18\", CLS_RESNET18),\n",
        "                (\"mobilenet_v3_large\", CLS_MNV3),\n",
        "                (\"efficientnet_b0\", CLS_EFFB0),\n",
        "                (\"convnext_tiny\", CLS_CONVNEXT),\n",
        "            ]:\n",
        "                self._ui_progress(f\"CLAHE-only image â†’ {nick}â€¦\")\n",
        "                lvl, _ = clf.predict_level(pil_clahe)\n",
        "                preds_clahe[nick] = lvl\n",
        "                self._ui_bump(5)\n",
        "\n",
        "            final_clahe = majority_vote(preds_clahe)\n",
        "\n",
        "            # --- XGBoost once (tabular doesnâ€™t depend on image) ---\n",
        "            self._ui_progress(\"Running XGBoostâ€¦\")\n",
        "            y_pred, y_label, p_yes = predict_xgb(form)\n",
        "            self._ui_bump(10)\n",
        "\n",
        "            # --- Compose output text (both runs) ---\n",
        "            lines = []\n",
        "            lines.append(\"â€” Image Models on PROCESSED (CLAHE + segmentation + 1% crop) â€”\")\n",
        "            for k, v in preds_proc.items():\n",
        "                lines.append(f\"  â€¢ {k}: Level {v}\")\n",
        "            lines.append(f\"  â†’ Final Norwood (majority): Level {final_proc}\")\n",
        "\n",
        "            lines.append(\"\\nâ€” Image Models on CLAHE-ONLY (full frame) â€”\")\n",
        "            for k, v in preds_clahe.items():\n",
        "                lines.append(f\"  â€¢ {k}: Level {v}\")\n",
        "            lines.append(f\"  â†’ Final Norwood (majority): Level {final_clahe}\")\n",
        "\n",
        "            if p_yes == p_yes:\n",
        "                lines.append(f\"\\nHair-Fall (XGBoost): {y_label}  (p_yes={p_yes:.2f})\")\n",
        "            else:\n",
        "                lines.append(f\"\\nHair-Fall (XGBoost): {y_label}\")\n",
        "\n",
        "            # Keep existing shape for downstream (choose PROCESSED as the canonical result)\n",
        "            self._last_results = {\n",
        "                \"norwood_by_model\": preds_proc,\n",
        "                \"norwood_final\": final_proc,\n",
        "                \"hairfall_yes\": bool(y_pred == 1),\n",
        "                \"hairfall_label\": y_label,\n",
        "                \"hairfall_prob\": p_yes,\n",
        "\n",
        "                # extra fields (optional; for your own inspection)\n",
        "                \"norwood_by_model_clahe\": preds_clahe,\n",
        "                \"norwood_final_clahe\": final_clahe,\n",
        "            }\n",
        "\n",
        "            self._ui_done(\"\\n\".join(lines))\n",
        "\n",
        "        except Exception as e:\n",
        "            self._ui_done(f\"[ERROR]\\n{e}\")\n",
        "\n",
        "    # UI-thread helpers\n",
        "    def _ui_progress(self, msg):\n",
        "        self.after(0, lambda: self.status.config(text=msg))\n",
        "\n",
        "    def _ui_bump(self, delta):\n",
        "        def _b():\n",
        "            v = min(100, self.pbar[\"value\"] + delta)\n",
        "            self.pbar[\"value\"] = v\n",
        "        self.after(0, _b)\n",
        "\n",
        "    def _ui_done(self, text):\n",
        "        def _d():\n",
        "            self.pbar[\"value\"] = 100\n",
        "            self.status.config(text=\"Done.\")\n",
        "            self.txt.delete(\"1.0\", \"end\")\n",
        "            self.txt.insert(\"end\", text)\n",
        "            # enable the navigation button if results exist\n",
        "            try:\n",
        "                if self._last_results:\n",
        "                    self.view_btn.config(state=\"normal\")\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        self.after(0, _d)\n",
        "\n",
        "    def on_choose_image(self):\n",
        "        \"\"\"Open a file dialog, store the path, and refresh the preview.\"\"\"\n",
        "        fp = filedialog.askopenfilename(\n",
        "            parent=self,  # tie dialog to this window\n",
        "            title=\"Select image\",\n",
        "            filetypes=[\n",
        "                (\"Image files\", (\"*.png\", \"*.jpg\", \"*.jpeg\", \"*.bmp\", \"*.webp\",\n",
        "                                 \"*.PNG\", \"*.JPG\", \"*.JPEG\", \"*.BMP\", \"*.WEBP\")),\n",
        "                (\"All files\", \"*\"),\n",
        "            ],\n",
        "        )\n",
        "        if not fp:\n",
        "            return\n",
        "        # Save to shared state so other screens can use it\n",
        "        if hasattr(self.controller, \"shared\"):\n",
        "            self.controller.shared[\"image_path\"] = fp\n",
        "        # Update path label + preview\n",
        "        self.path_var.set(fp)\n",
        "        self._refresh_preview()\n",
        "\n",
        "    def on_view_results(self):\n",
        "        \"\"\"Navigate to the Results screen with the latest predictions.\"\"\"\n",
        "        if not self._last_results:\n",
        "            return\n",
        "        # put into shared state\n",
        "        if hasattr(self.controller, \"shared\"):\n",
        "            self.controller.shared[\"results\"] = self._last_results\n",
        "        # feed ResultsScreen and show it\n",
        "        try:\n",
        "            res = self.controller.screens[\"results\"]\n",
        "            res.set_results(self._last_results)\n",
        "            self.controller.show(\"results\")\n",
        "        except Exception:\n",
        "            # safe fallback if controller/screen not wired yet\n",
        "            from tkinter import messagebox\n",
        "            messagebox.showinfo(\"Results\", \"Results screen not available in controller.\")\n",
        "\n",
        "    def _collect_form(self) -> dict:\n",
        "        # Normalize age (blank/invalid -> 0)\n",
        "        try:\n",
        "            age_val = float(self.var_age.get().strip())\n",
        "        except Exception:\n",
        "            age_val = 0.0\n",
        "\n",
        "        return {\n",
        "            \"stay_up_late\":   self.var_stay_up_late.get(),\n",
        "            \"water_reason\":   self.var_water_reason.get(),\n",
        "            \"family_history\": self.var_family_history.get(),\n",
        "            \"use_chemicals\":  self.var_use_chemicals.get(),\n",
        "            \"stress\":         self.var_stress.get(),\n",
        "            \"chronic_illness\": self.var_chronic.get(),\n",
        "            \"age\":            age_val,\n",
        "        }\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRXrU5OnL9ZD"
      },
      "source": [
        "processing_screen.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Uz_a_dsMAmw"
      },
      "outputs": [],
      "source": [
        "# screens/processing_screen.py\n",
        "import os\n",
        "import threading\n",
        "import traceback\n",
        "import tkinter as tk\n",
        "from tkinter import ttk\n",
        "\n",
        "try:\n",
        "    from PIL import Image, ImageTk\n",
        "except Exception:  # keep UI alive even if PIL missing\n",
        "    Image = None\n",
        "    ImageTk = None\n",
        "\n",
        "\n",
        "class ProcessingScreen(ttk.Frame):\n",
        "    \"\"\"\n",
        "    A waiting/processing view.\n",
        "    - Call `configure_job(predict_fn, args, kwargs, on_done)` before showing.\n",
        "      * predict_fn: a callable that will run on a background thread.\n",
        "      * args/kwargs: passed to predict_fn\n",
        "      * on_done(results_dict): called on the Tk thread when predict_fn returns.\n",
        "    - Call `show_uploaded_image(path)` to preview the userâ€™s photo.\n",
        "    - When this frame is raised, call `start()` to begin the job (starts spinner).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, parent, controller=None):\n",
        "        super().__init__(parent)\n",
        "        self.controller = controller\n",
        "\n",
        "        # --- Layout ---\n",
        "        self.columnconfigure(0, weight=1)\n",
        "\n",
        "        self.title_lbl = ttk.Label(\n",
        "            self, text=\"TESTING...\", anchor=\"w\",\n",
        "            font=(\"Arial\", 38, \"bold\")\n",
        "        )\n",
        "        self.title_lbl.grid(row=0, column=0, sticky=\"w\", padx=40, pady=(30, 0))\n",
        "\n",
        "        self.subtitle_lbl = ttk.Label(\n",
        "            self,\n",
        "            text=(\"PLEASE WAIT A MOMENT WHILE OUR DEEP LEARNING\\n\"\n",
        "                  \"AND MACHINE LEARNING MODELS PREDICT YOUR\\n\"\n",
        "                  \"NORWOOD SCALE STAGE, AND WHETHER THERE IS A\\n\"\n",
        "                  \"PROGRESSING HAIR LOSS\"),\n",
        "            anchor=\"w\",\n",
        "            font=(\"Arial\", 20, \"bold\")\n",
        "        )\n",
        "        self.subtitle_lbl.grid(row=1, column=0, sticky=\"w\", padx=40, pady=(6, 16))\n",
        "\n",
        "        # Preview area\n",
        "        self.preview_wrap = ttk.Frame(self)\n",
        "        self.preview_wrap.grid(row=2, column=0, sticky=\"w\", padx=40, pady=(8, 0))\n",
        "\n",
        "        self.preview_caption = ttk.Label(\n",
        "            self.preview_wrap, text=\"Your uploaded image:\",\n",
        "            font=(\"Arial\", 18)\n",
        "        )\n",
        "        self.preview_caption.grid(row=0, column=0, sticky=\"w\", pady=(0, 10))\n",
        "\n",
        "        self.preview_lbl = ttk.Label(self.preview_wrap)\n",
        "        self.preview_lbl.grid(row=1, column=0, sticky=\"w\")\n",
        "\n",
        "        # Progress area\n",
        "        self.progress_wrap = ttk.Frame(self)\n",
        "        self.progress_wrap.grid(row=3, column=0, sticky=\"we\", padx=40, pady=(30, 20))\n",
        "        self.progress_wrap.columnconfigure(0, weight=1)\n",
        "\n",
        "        self.progress = ttk.Progressbar(self.progress_wrap, mode=\"indeterminate\")\n",
        "        self.progress.grid(row=0, column=0, sticky=\"we\")\n",
        "\n",
        "        self.status_lbl = ttk.Label(self.progress_wrap, text=\"Loading modelsâ€¦\", font=(\"Arial\", 12))\n",
        "        self.status_lbl.grid(row=1, column=0, sticky=\"w\", pady=(8, 0))\n",
        "\n",
        "        # Error box (hidden unless needed)\n",
        "        self.err_box = tk.Text(self, height=8, wrap=\"word\", foreground=\"red\")\n",
        "        self.err_box.grid(row=4, column=0, sticky=\"nsew\", padx=40, pady=(10, 20))\n",
        "        self.rowconfigure(4, weight=1)\n",
        "        self.err_box.grid_remove()\n",
        "\n",
        "        # Internals\n",
        "        self._tk_img = None\n",
        "        self._predict_fn = None\n",
        "        self._job_args = ()\n",
        "        self._job_kwargs = {}\n",
        "        self._on_done = None\n",
        "        self._thread = None\n",
        "        self._anim_job = None\n",
        "        self._anim_dots = 0\n",
        "\n",
        "    # ---------------- Public API ----------------\n",
        "\n",
        "    def configure_job(self, predict_fn, args=(), kwargs=None, on_done=None):\n",
        "        \"\"\"Register the heavy job to run in a background thread.\"\"\"\n",
        "        self._predict_fn = predict_fn\n",
        "        self._job_args = args or ()\n",
        "        self._job_kwargs = kwargs or {}\n",
        "        self._on_done = on_done\n",
        "\n",
        "    def show_uploaded_image(self, image_path: str, max_size=(420, 420)):\n",
        "        \"\"\"Preview the user image (PIL) on the left.\"\"\"\n",
        "        if not Image or not ImageTk:\n",
        "            self.preview_lbl.configure(text=os.path.basename(image_path))\n",
        "            return\n",
        "        try:\n",
        "            img = Image.open(image_path).convert(\"RGB\")\n",
        "            w, h = img.size\n",
        "            scale = min(max_size[0] / w, max_size[1] / h, 1.0)\n",
        "            if scale < 1.0:\n",
        "                img = img.resize((int(w * scale), int(h * scale)))\n",
        "            self._tk_img = ImageTk.PhotoImage(img)\n",
        "            self.preview_lbl.configure(image=self._tk_img)\n",
        "        except Exception:\n",
        "            self.preview_lbl.configure(text=\"(couldnâ€™t preview image)\")\n",
        "\n",
        "    def start(self):\n",
        "        \"\"\"Begin spinner + launch background work.\"\"\"\n",
        "        self._start_spinner()\n",
        "        self._start_job_thread()\n",
        "\n",
        "    # ---------------- Internals ----------------\n",
        "\n",
        "    def _start_spinner(self):\n",
        "        self.progress.start(12)  # speed\n",
        "        self._anim_tick()\n",
        "\n",
        "    def _stop_spinner(self):\n",
        "        try:\n",
        "            self.progress.stop()\n",
        "        except Exception:\n",
        "            pass\n",
        "        if self._anim_job is not None:\n",
        "            self.after_cancel(self._anim_job)\n",
        "            self._anim_job = None\n",
        "\n",
        "    def _anim_tick(self):\n",
        "        # simple 'Loadingâ€¦', 'Loadingâ€¦..' loop\n",
        "        base = \"Processing inputâ€¦\"\n",
        "        self._anim_dots = (self._anim_dots + 1) % 6\n",
        "        self.status_lbl.configure(text=base + \".\" * self._anim_dots)\n",
        "        self._anim_job = self.after(400, self._anim_tick)\n",
        "\n",
        "    def _start_job_thread(self):\n",
        "        if self._predict_fn is None:\n",
        "            self._show_error(\"No job configured for ProcessingScreen.\")\n",
        "            return\n",
        "\n",
        "        def runner():\n",
        "            try:\n",
        "                results = self._predict_fn(*self._job_args, **self._job_kwargs)\n",
        "            except Exception as e:\n",
        "                tb = traceback.format_exc()\n",
        "                self.after(0, lambda: self._show_error(f\"{e}\\n\\n{tb}\"))\n",
        "                return\n",
        "            self.after(0, lambda: self._finish(results))\n",
        "\n",
        "        self._thread = threading.Thread(target=runner, daemon=True)\n",
        "        self._thread.start()\n",
        "\n",
        "    def _finish(self, results):\n",
        "        self._stop_spinner()\n",
        "        if callable(self._on_done):\n",
        "            try:\n",
        "                self._on_done(results)\n",
        "            except Exception as e:\n",
        "                self._show_error(f\"on_done callback failed: {e}\")\n",
        "\n",
        "    def _show_error(self, text):\n",
        "        self._stop_spinner()\n",
        "        self.err_box.grid()  # show\n",
        "        self.err_box.delete(\"1.0\", \"end\")\n",
        "        self.err_box.insert(\"end\", str(text))\n",
        "        self.status_lbl.configure(text=\"An error occurred.\")\n",
        "\n",
        "    def set_inputs(self, image_path: str, form: dict):\n",
        "        \"\"\"Compatibility wrapper used by main.py.\"\"\"\n",
        "        if image_path:\n",
        "            self.show_uploaded_image(image_path)\n",
        "        # stash for convenience if someone wants to fetch later\n",
        "        self._job_kwargs.setdefault(\"inputs\", {\"image_path\": image_path, \"form\": form})\n",
        "\n",
        "    def start_processing(self, on_done=None):\n",
        "        \"\"\"Compatibility wrapper used by main.py.\n",
        "\n",
        "        Expects the controller to expose run_full_inference(image_path, form) -> dict.\n",
        "        Falls back to any predict_fn already configured via configure_job().\n",
        "        \"\"\"\n",
        "        if callable(on_done):\n",
        "            self._on_done = on_done\n",
        "\n",
        "        # If no predict_fn configured yet, but controller has a runner, wire it up.\n",
        "        if self._predict_fn is None and hasattr(self.controller, \"run_full_inference\"):\n",
        "            inputs = self._job_kwargs.get(\"inputs\", {})\n",
        "            img = inputs.get(\"image_path\")\n",
        "            form = inputs.get(\"form\", {})\n",
        "            self.configure_job(self.controller.run_full_inference, args=(img, form))\n",
        "\n",
        "        self.start()\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Clear transient UI.\"\"\"\n",
        "        try:\n",
        "            self.progress.stop()\n",
        "        except Exception:\n",
        "            pass\n",
        "        self.status_lbl.config(text=\"Loading modelsâ€¦\")\n",
        "        self.err_box.grid_remove()\n",
        "        self.preview_lbl.configure(image=\"\", text=\"\")\n",
        "        self._tk_img = None\n",
        "        self._predict_fn = None\n",
        "        self._job_args = ()\n",
        "        self._job_kwargs = {}\n",
        "        self._on_done = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHldMrLaMJn2"
      },
      "source": [
        "results_screen.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ll7n3iVML8R"
      },
      "outputs": [],
      "source": [
        "# screens/results_screen.py\n",
        "import os\n",
        "from collections import Counter\n",
        "import tkinter as tk\n",
        "from tkinter import ttk\n",
        "\n",
        "try:\n",
        "    from PIL import Image, ImageTk\n",
        "except Exception:\n",
        "    Image = None\n",
        "    ImageTk = None\n",
        "\n",
        "\n",
        "# ---- simple, editable recommendations ----\n",
        "NORWOOD_RECS = {\n",
        "    1: [\"Maintain gentle care routine\", \"Baseline photos every 3â€“6 months\"],\n",
        "    2: [\"Consider topical minoxidil\", \"Focus on sleep & nutrition\"],\n",
        "    3: [\"Discuss finasteride/minoxidil with a clinician\", \"Dermarolling only if supervised\"],\n",
        "    4: [\"Combo therapy (finasteride + minoxidil) may help\", \"Discuss LLLT devices evidence\"],\n",
        "    5: [\"Consider procedural options (e.g., PRP)\", \"Manage expectations; camouflage options\"],\n",
        "    6: [\"Surgical candidacy evaluation\", \"Plan donor management & maintenance therapy\"],\n",
        "    7: [\"SMP or hair systems; sun protection\", \"Medical therapy only for stabilization\"],\n",
        "}\n",
        "\n",
        "HAIRFALL_RECS = {\n",
        "    False: [\"Looks stable right now\", \"Keep healthy routine & periodic photos\"],\n",
        "    True:  [\"Progression likely â€” seek medical advice\", \"Early intervention improves outcomes\"],\n",
        "}\n",
        "\n",
        "# Preventative methods (plain strings; weâ€™ll add bullets in set_results)\n",
        "PREVENTIVE_METHODS = [\n",
        "    \"Minoxidil\",\n",
        "    \"Low-Level Laser Therapy (LLLT)\",\n",
        "    \"DHT Blockers (Finasteride or Dutasteride)\",\n",
        "    \"Ketoconazole 2% Shampoo\",\n",
        "    \"Tretinoin\",\n",
        "    \"Dermarolling (with supervision)\",\n",
        "    \"Platelet-Rich Plasma (PRP) treatments\",\n",
        "    \"Hair-focused supplements (if deficient)\",\n",
        "    \"Adequate protein intake\",\n",
        "    \"Avoid smoking\",\n",
        "    \"Limit alcohol consumption\",\n",
        "    \"Improve sleep quality\",\n",
        "    \"Stress management\",\n",
        "    \"Account for genetic predisposition (family history monitoring)\",\n",
        "]\n",
        "\n",
        "# ---- optional images for each Norwood; replace with your assets if available ----\n",
        "NORWOOD_IMAGES = {i: f\"assets/norwood/{i}.png\" for i in range(1, 8)}\n",
        "\n",
        "\n",
        "class ResultsScreen(ttk.Frame):\n",
        "    \"\"\"\n",
        "    Call set_results(results_dict) to populate the screen, then raise this frame.\n",
        "    results_dict may contain:\n",
        "      - norwood_by_model: dict{name: level_int}\n",
        "      - norwood_final: int (optional; if missing we majority-vote here)\n",
        "      - hairfall_yes: bool (preferred)\n",
        "      - hairfall_label: str (optional)\n",
        "      - hairfall_prob: float (optional)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, parent, controller=None):\n",
        "        super().__init__(parent)\n",
        "        self.controller = controller\n",
        "        self._stage_img_tk = None\n",
        "\n",
        "        # keep references to dynamically created labels so we can rewrap on resize\n",
        "        self._stage_rec_labels = []\n",
        "        self._hf_rec_labels = []\n",
        "\n",
        "        self._build_ui()\n",
        "\n",
        "    # ---------- public API ----------\n",
        "    def set_results(self, results: dict):\n",
        "        \"\"\"Update all widgets using a results dict produced by the processing step.\"\"\"\n",
        "        nbm = results.get(\"norwood_by_model\", {}) or {}\n",
        "        final_level = results.get(\"norwood_final\")\n",
        "        if final_level is None and nbm:\n",
        "            final_level = self._majority_vote(list(nbm.values()))\n",
        "        if final_level is None:\n",
        "            final_level = 3  # safe default\n",
        "\n",
        "        hairfall_yes = results.get(\"hairfall_yes\")\n",
        "        if hairfall_yes is None:\n",
        "            label = (results.get(\"hairfall_label\") or \"\").lower()\n",
        "            hairfall_yes = \"yes\" in label if label else None\n",
        "\n",
        "        prob = results.get(\"hairfall_prob\")\n",
        "        prob_txt = f\" (p={prob:.2f})\" if isinstance(prob, (int, float)) else \"\"\n",
        "\n",
        "        # Big title\n",
        "        hl_text = \"Progressing hair loss\" if hairfall_yes else \"No hair loss detected\" if hairfall_yes is not None else \"â€”\"\n",
        "        self.title_lbl.config(text=\"THE RESULTS ARE READY!\")\n",
        "        self.subtitle_lbl.config(text=f\"Final Norwood: Level {final_level} â€” {hl_text}{prob_txt}\")\n",
        "\n",
        "        # Circle text (two-label layout over canvas)\n",
        "        self.circle_label_text.config(text=\"Level\")\n",
        "        self.circle_number_lbl.config(text=str(final_level))\n",
        "\n",
        "        # Stage image (center)\n",
        "        self._set_stage_image(final_level)\n",
        "\n",
        "        # -------- Recommendations (left box) --------\n",
        "        stage_recs = list(NORWOOD_RECS.get(final_level, []))  # copy\n",
        "\n",
        "        # Extra suggestion for stages 3â€“5\n",
        "        if 3 <= final_level <= 5:\n",
        "            stage_recs.insert(0, \"Consider hair transplant to achieve a full hairline\")\n",
        "\n",
        "        # Preventative measures for stages 1â€“5 (spaced & indented bullets)\n",
        "        if 1 <= final_level <= 5:\n",
        "            stage_recs.append(\"\")  # blank line for separation\n",
        "            stage_recs.append(\"Preventative measures to integrate:\")\n",
        "            stage_recs.extend([f\"   â€¢ {m}\" for m in PREVENTIVE_METHODS])\n",
        "\n",
        "        # -------- Hair-fall recommendations (right box) --------\n",
        "        hf_recs = list(HAIRFALL_RECS.get(bool(hairfall_yes), []))\n",
        "\n",
        "        # Add monitoring + integration prompts only if Hair Fall = Yes and stage â‰¤5\n",
        "        if hairfall_yes is True and 1 <= final_level <= 5:\n",
        "            hf_recs.insert(0, \"Integrate preventative routine (see preventative methods list)\")\n",
        "            hf_recs.insert(0, \"Monitor shedding (monthly photos / part-line density checks)\")\n",
        "\n",
        "        # If no hair fall AND level â‰¥6, remove any monitoring-style suggestion\n",
        "        if hairfall_yes is False and final_level >= 6:\n",
        "            hf_recs = [rec for rec in hf_recs if \"Monitor\" not in rec]\n",
        "\n",
        "        # Populate UI â€” using wrapped labels that expand vertically (no scrolling)\n",
        "        self._render_recs(self.stage_recs_container, self._stage_rec_labels, stage_recs)\n",
        "        self._render_recs(self.hf_recs_container, self._hf_rec_labels, hf_recs)\n",
        "\n",
        "        # Footer\n",
        "        model_names = \", \".join(nbm.keys()) if nbm else \"ensemble\"\n",
        "        self.footer_lbl.config(\n",
        "            text=(\n",
        "                f\"Predicted with {model_names or 'ensemble'} image models and an XGBoost tabular model.\\n\"\n",
        "                \"These recommendations are for educational purposes only and are supported by scientific research\\n\"\n",
        "                \"including publications such as the Journal of the American Academy of Dermatology (JAAD).\\n\"\n",
        "                \"They are not a substitute for professional medical advice, diagnosis, or treatment.\\n\"\n",
        "                \"Always consult a qualified dermatologist or healthcare provider before starting any new treatment or\\n\"\n",
        "                \"routine. We are not responsible for any outcomes resulting from the use of this information.\\n\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # ---------- internals ----------\n",
        "    def _build_ui(self):\n",
        "        self.columnconfigure(0, weight=1)\n",
        "        self.rowconfigure(3, weight=1)\n",
        "\n",
        "        # Header\n",
        "        self.title_lbl = ttk.Label(self, text=\"THE RESULTS ARE READY!\", font=(\"Arial\", 36, \"bold\"))\n",
        "        self.title_lbl.grid(row=0, column=0, sticky=\"w\", padx=40, pady=(30, 0))\n",
        "\n",
        "        self.subtitle_lbl = ttk.Label(self, text=\"\", font=(\"Arial\", 18))\n",
        "        self.subtitle_lbl.grid(row=1, column=0, sticky=\"w\", padx=40, pady=(6, 10))\n",
        "\n",
        "        # Main 3-column area\n",
        "        main = ttk.Frame(self)\n",
        "        main.grid(row=2, column=0, sticky=\"nsew\", padx=40, pady=10)\n",
        "        main.columnconfigure(0, weight=1)\n",
        "        main.columnconfigure(1, weight=1)\n",
        "        main.columnconfigure(2, weight=1)\n",
        "        self.rowconfigure(2, weight=1)\n",
        "\n",
        "        # Left: big circle with level (use tk.Labels so we can set bg safely)\n",
        "        circle_frame = ttk.Frame(main)\n",
        "        circle_frame.grid(row=0, column=0, sticky=\"n\", padx=(0, 20))\n",
        "\n",
        "        bg_color = self._get_bg_color_safe(circle_frame)\n",
        "        circle_canvas = tk.Canvas(circle_frame, width=260, height=260, highlightthickness=0, bg=bg_color, bd=0)\n",
        "        circle_canvas.pack()\n",
        "        circle_canvas.create_oval(5, 5, 255, 255, fill=\"#f5f5f5\", outline=\"#b5b5b5\", width=3)\n",
        "\n",
        "        self.circle_label_text = tk.Label(circle_frame, text=\"Level\", font=(\"Arial\", 20), bg=bg_color, fg=\"#555\")\n",
        "        self.circle_label_text.place(relx=0.5, rely=0.40, anchor=\"center\")\n",
        "\n",
        "        self.circle_number_lbl = tk.Label(circle_frame, text=\"\", font=(\"Arial\", 56, \"bold\"), bg=bg_color, fg=\"#333\")\n",
        "        self.circle_number_lbl.place(relx=0.5, rely=0.60, anchor=\"center\")\n",
        "\n",
        "        # Middle: stage figure\n",
        "        mid = ttk.Frame(main)\n",
        "        mid.grid(row=0, column=1, sticky=\"n\")\n",
        "        self.stage_img_lbl = ttk.Label(mid)\n",
        "        self.stage_img_lbl.pack()\n",
        "\n",
        "        # Right: recommendations (two auto-growing boxes)\n",
        "        right = ttk.Frame(main)\n",
        "        right.grid(row=0, column=2, sticky=\"nsew\")\n",
        "        right.columnconfigure(0, weight=1)\n",
        "\n",
        "        # Stage recs box\n",
        "        stage_box = ttk.LabelFrame(right, text=\"Recommendations (Norwood stage)\")\n",
        "        stage_box.grid(row=0, column=0, sticky=\"nsew\", pady=(0, 10))\n",
        "        stage_box.columnconfigure(0, weight=1)\n",
        "        self.stage_recs_container = ttk.Frame(stage_box)\n",
        "        self.stage_recs_container.grid(row=0, column=0, sticky=\"nwe\", padx=8, pady=8)\n",
        "        self.stage_recs_container.bind(\"<Configure>\", lambda e: self._rewrap_labels(self._stage_rec_labels, e.width))\n",
        "\n",
        "        # Hair-fall recs box\n",
        "        hf_box = ttk.LabelFrame(right, text=\"Recommendations (Hair loss progression)\")\n",
        "        hf_box.grid(row=1, column=0, sticky=\"nsew\")\n",
        "        hf_box.columnconfigure(0, weight=1)\n",
        "        self.hf_recs_container = ttk.Frame(hf_box)\n",
        "        self.hf_recs_container.grid(row=0, column=0, sticky=\"nwe\", padx=8, pady=8)\n",
        "        self.hf_recs_container.bind(\"<Configure>\", lambda e: self._rewrap_labels(self._hf_rec_labels, e.width))\n",
        "\n",
        "        # Footer\n",
        "        self.footer_lbl = ttk.Label(self, text=\"\", font=(\"Arial\", 11), justify=\"left\")\n",
        "        self.footer_lbl.grid(row=3, column=0, sticky=\"we\", padx=40, pady=(10, 6))\n",
        "\n",
        "        # Bottom buttons (link later)\n",
        "        btns = ttk.Frame(self)\n",
        "        btns.grid(row=4, column=0, sticky=\"we\", padx=40, pady=(8, 30))\n",
        "        for i in range(3):\n",
        "            btns.columnconfigure(i, weight=1)\n",
        "\n",
        "        self.btn_about = ttk.Button(btns, text=\"LEARN MORE ABOUT US\")\n",
        "        self.btn_models = ttk.Button(btns, text=\"BROWSE OUR MODELS ON HUGGINGFACE\")\n",
        "        self.btn_prices = ttk.Button(btns, text=\"COMPARE CLINIC PRICES >\")\n",
        "\n",
        "        self.btn_about.grid(row=0, column=0, sticky=\"we\", padx=(0, 8))\n",
        "        self.btn_models.grid(row=0, column=1, sticky=\"we\", padx=8)\n",
        "        self.btn_prices.grid(row=0, column=2, sticky=\"we\", padx=(8, 0))\n",
        "\n",
        "    def _render_recs(self, container: ttk.Frame, label_list: list, items):\n",
        "        \"\"\"Destroy old labels and render a vertical stack of wrapped labels (auto-expands).\"\"\"\n",
        "        for child in container.winfo_children():\n",
        "            child.destroy()\n",
        "        label_list.clear()\n",
        "\n",
        "        # current width (may be 1 at first; we'll rewrap on <Configure>)\n",
        "        width = max(container.winfo_width(), 300)\n",
        "        wrap = max(width - 12, 150)  # padding margin\n",
        "\n",
        "        for i, text in enumerate(items):\n",
        "            # blank lines â†’ small spacer\n",
        "            if text.strip() == \"\":\n",
        "                spacer = ttk.Frame(container, height=6)\n",
        "                spacer.grid(row=i, column=0, sticky=\"we\")\n",
        "                continue\n",
        "\n",
        "            lbl = ttk.Label(container, text=text, justify=\"left\", anchor=\"w\", wraplength=wrap)\n",
        "            lbl.grid(row=i, column=0, sticky=\"we\", pady=2)\n",
        "            label_list.append(lbl)\n",
        "\n",
        "        container.update_idletasks()\n",
        "\n",
        "    def _rewrap_labels(self, labels, new_width):\n",
        "        \"\"\"Re-apply wraplength when container width changes to keep lines tidy.\"\"\"\n",
        "        wrap = max(new_width - 12, 150)\n",
        "        for lbl in labels:\n",
        "            try:\n",
        "                lbl.configure(wraplength=wrap)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    def _set_stage_image(self, level: int):\n",
        "        \"\"\"Load and display the per-level figure if available.\"\"\"\n",
        "        if not Image or not ImageTk:\n",
        "            self.stage_img_lbl.config(text=f\"(Stage figure {level})\")\n",
        "            return\n",
        "        path = NORWOOD_IMAGES.get(level)\n",
        "        if not path or not os.path.exists(path):\n",
        "            self.stage_img_lbl.config(text=f\"(Add assets/norwood/{level}.png)\")\n",
        "            self.stage_img_lbl.image = None\n",
        "            return\n",
        "        try:\n",
        "            img = Image.open(path).convert(\"RGBA\")\n",
        "            max_h = 240\n",
        "            w, h = img.size\n",
        "            scale = min(max_h / h, 1.0)\n",
        "            if scale < 1.0:\n",
        "                img = img.resize((int(w * scale), int(h * scale)))\n",
        "            self._stage_img_tk = ImageTk.PhotoImage(img)\n",
        "            self.stage_img_lbl.config(image=self._stage_img_tk, text=\"\")\n",
        "            self.stage_img_lbl.image = self._stage_img_tk\n",
        "        except Exception:\n",
        "            self.stage_img_lbl.config(text=f\"(Couldnâ€™t load stage img {level})\")\n",
        "\n",
        "    @staticmethod\n",
        "    def _majority_vote(levels):\n",
        "        c = Counter(levels)\n",
        "        if not c:\n",
        "            return 3\n",
        "        max_count = max(c.values())\n",
        "        candidates = [lvl for lvl, cnt in c.items() if cnt == max_count]\n",
        "        return min(candidates)\n",
        "\n",
        "    def _get_bg_color_safe(self, widget):\n",
        "        \"\"\"Best-effort: get a hex background color for a ttk parent to use on tk widgets.\"\"\"\n",
        "        try:\n",
        "            return widget.cget(\"background\")\n",
        "        except Exception:\n",
        "            try:\n",
        "                return widget.master.cget(\"background\")\n",
        "            except Exception:\n",
        "                return \"#f0f0f0\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lILXbMm4MXZV"
      },
      "source": [
        "main.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FUho2eLMYl5"
      },
      "outputs": [],
      "source": [
        "# main.py\n",
        "import tkinter as tk\n",
        "from tkinter import ttk, messagebox\n",
        "\n",
        "# Screens (each must expose a Frame subclass)\n",
        "from screens.loading_screen import LoadingScreen\n",
        "from screens.intake_screen import IntakeScreen\n",
        "from screens.processing_screen import ProcessingScreen\n",
        "from screens.results_screen import ResultsScreen\n",
        "from PIL import Image\n",
        "from screens.intake_screen import (\n",
        "    CLS_RESNET18, CLS_MNV3, CLS_EFFB0, CLS_CONVNEXT,\n",
        "    majority_vote, predict_xgb\n",
        ")\n",
        "\n",
        "\n",
        "class App(tk.Tk):\n",
        "    \"\"\"\n",
        "    Central controller:\n",
        "      - creates all screens\n",
        "      - exposes navigation methods for screens to call\n",
        "      - stores shared state (image path, form answers, model results)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.title(\"Hair Loss Predictor\")\n",
        "        self.geometry(\"1100x700\")\n",
        "        self.minsize(960, 640)\n",
        "\n",
        "        # Shared state between screens\n",
        "        self.shared = {\n",
        "            \"image_path\": None,\n",
        "            \"form\": {},          # your yes/no + age answers\n",
        "            \"results\": None,     # final inference payload from processing step\n",
        "        }\n",
        "\n",
        "        # Container for screens\n",
        "        container = ttk.Frame(self)\n",
        "        container.pack(fill=\"both\", expand=True)\n",
        "        container.grid_rowconfigure(0, weight=1)\n",
        "        container.grid_columnconfigure(0, weight=1)\n",
        "\n",
        "        # Instantiate screens\n",
        "        self.screens = {}\n",
        "        self.screens[\"loading\"] = LoadingScreen(\n",
        "            container,\n",
        "            controller=self,\n",
        "            logo_path=\"https://drive.google.com/file/d/1N3E_f-qyut2RHtYm29D4YJ9UY2vGRCNr/view?usp=sharing\"\n",
        "        )\n",
        "        self.screens[\"intake\"] = IntakeScreen(container, controller=self)\n",
        "        self.screens[\"processing\"] = ProcessingScreen(container, controller=self)\n",
        "        self.screens[\"results\"] = ResultsScreen(container, controller=self)\n",
        "\n",
        "        # Grid all screens (stacked)\n",
        "        for f in self.screens.values():\n",
        "            f.grid(row=0, column=0, sticky=\"nsew\")\n",
        "\n",
        "        # Start on loading screen\n",
        "        self.show(\"loading\")\n",
        "\n",
        "    # ---------- Navigation helpers ----------\n",
        "    def show(self, name: str):\n",
        "        \"\"\"Raise the given screen by key ('loading'|'intake'|'processing'|'results').\"\"\"\n",
        "        frame = self.screens[name]\n",
        "        frame.tkraise()\n",
        "        try:\n",
        "            # optional: many of our screens expose .on_show()\n",
        "            frame.on_show()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Called by IntakeScreen after user selects image + answers form\n",
        "    def go_to_processing(self, image_path: str, form: dict):\n",
        "        if not image_path:\n",
        "            messagebox.showwarning(\"Missing image\", \"Please upload an image first.\")\n",
        "            return\n",
        "\n",
        "        self.shared[\"image_path\"] = image_path\n",
        "        self.shared[\"form\"] = form or {}\n",
        "\n",
        "        proc: ProcessingScreen = self.screens[\"processing\"]  # type: ignore\n",
        "        # show a preview on the processing screen\n",
        "        proc.set_inputs(image_path=image_path, form=form)\n",
        "        # tell the processing screen how to run the job and where to send results\n",
        "        proc.configure_job(self.run_full_inference, args=(image_path, form), on_done=self._processing_finished)\n",
        "\n",
        "        self.show(\"processing\")\n",
        "        proc.start()\n",
        "\n",
        "    # Callback that processing screen invokes when all models finish\n",
        "    def _processing_finished(self, results: dict):\n",
        "        self.shared[\"results\"] = results or {}\n",
        "        # Hand results to results screen and show it\n",
        "        res: ResultsScreen = self.screens[\"results\"]  # type: ignore\n",
        "        res.set_results(self.shared[\"results\"])\n",
        "        self.show(\"results\")\n",
        "\n",
        "    # Optional â€œStart overâ€ from results\n",
        "    def start_over(self):\n",
        "        self.shared.update({\"image_path\": None, \"form\": {}, \"results\": None})\n",
        "        # Some screens may expose reset() for their UI\n",
        "        try:\n",
        "            self.screens[\"intake\"].reset()\n",
        "        except Exception:\n",
        "            pass\n",
        "        try:\n",
        "            self.screens[\"processing\"].reset()\n",
        "        except Exception:\n",
        "            pass\n",
        "        self.show(\"loading\")\n",
        "\n",
        "    def run_full_inference(self, image_path: str, form: dict) -> dict:\n",
        "        \"\"\"Loads models (lazily), runs all 4 image models + XGBoost, returns a results dict for ResultsScreen.\"\"\"\n",
        "        # Ensure models are loaded (load() is idempotent in your wrappers)\n",
        "        CLS_RESNET18.load()\n",
        "        CLS_MNV3.load()\n",
        "        CLS_EFFB0.load()\n",
        "        CLS_CONVNEXT.load()\n",
        "\n",
        "        pil = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        preds = {}\n",
        "        for name, clf in [\n",
        "            (\"resnet18\", CLS_RESNET18),\n",
        "            (\"mobilenet_v3_large\", CLS_MNV3),\n",
        "            (\"efficientnet_b0\", CLS_EFFB0),\n",
        "            (\"convnext_tiny\", CLS_CONVNEXT),\n",
        "        ]:\n",
        "            lvl, _ = clf.predict_level(pil)\n",
        "            preds[name] = lvl\n",
        "\n",
        "        final_level = majority_vote(preds)\n",
        "        y_pred, y_label, p_yes = predict_xgb(form)\n",
        "\n",
        "        return {\n",
        "            \"norwood_by_model\": preds,\n",
        "            \"norwood_final\": final_level,\n",
        "            \"hairfall_yes\": bool(y_pred == 1),\n",
        "            \"hairfall_label\": y_label,\n",
        "            \"hairfall_prob\": p_yes,\n",
        "        }\n",
        "\n",
        "    def go_to_intake(self):\n",
        "        self.show(\"intake\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    App().mainloop()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9EnLsdamVVH"
      },
      "source": [
        "## Pyhton Tkinter UI Screen V 3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHZCGX0pmbff"
      },
      "outputs": [],
      "source": [
        "loading_screen.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJC_XFUwmfTe"
      },
      "outputs": [],
      "source": [
        "# screens/loading_screen.py\n",
        "# First screen (welcome / loading) with centered logo + fade-in\n",
        "\n",
        "import os\n",
        "from tkinter import ttk\n",
        "import io\n",
        "import re\n",
        "import requests\n",
        "import tkinter as tk   # for Canvas\n",
        "import math            # for smooth glow animation\n",
        "\n",
        "try:\n",
        "    from PIL import Image, ImageTk, ImageEnhance\n",
        "except Exception:\n",
        "    Image = None\n",
        "    ImageTk = None\n",
        "    ImageEnhance = None\n",
        "\n",
        "logo_path=\"https://drive.google.com/file/d/1ZFsPQiPY5AleOMb1wVV3EW9Q0stHIxMs/view?usp=sharing\",\n",
        "\n",
        "def _fade_with_original_alpha(img_rgba, factor: float):\n",
        "    \"\"\"\n",
        "    Returns a copy of RGBA image whose alpha channel is scaled by `factor`\n",
        "    (0.0 -> fully transparent, 1.0 -> original alpha). Preserves transparency.\n",
        "    \"\"\"\n",
        "    if img_rgba.mode != \"RGBA\":\n",
        "        img_rgba = img_rgba.convert(\"RGBA\")\n",
        "    r, g, b, a = img_rgba.split()\n",
        "    # Scale alpha without destroying its original shape\n",
        "    a = a.point(lambda px: int(px * factor))\n",
        "    return Image.merge(\"RGBA\", (r, g, b, a))\n",
        "\n",
        "\n",
        "class LoadingScreen(ttk.Frame):\n",
        "    \"\"\"\n",
        "    Usage:\n",
        "        root = tk.Tk()\n",
        "        screen = LoadingScreen(root,\n",
        "                               controller=my_controller,\n",
        "                               # logo_path and right_image_url have sensible defaults now (your Drive links)\n",
        "                               next_screen_name=\"IntakeScreen\")\n",
        "        screen.pack(fill=\"both\", expand=True)\n",
        "        root.mainloop()\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        parent,\n",
        "        controller=None,\n",
        "        # DEFAULT: your new main logo (left) Drive link\n",
        "        logo_path=\"https://drive.google.com/file/d/1ZFsPQiPY5AleOMb1wVV3EW9Q0stHIxMs/view?usp=drive_link\",\n",
        "        next_screen_name=\"IntakeScreen\",\n",
        "        # NEW: right-side image (defaults to your provided Drive link)\n",
        "        right_image_url=\"https://drive.google.com/file/d/17t-8_8udGnSfaSg1uyYsvuuURzoW4g3Y/view?usp=sharing\",\n",
        "    ):\n",
        "        super().__init__(parent)\n",
        "        self.controller = controller\n",
        "        self.logo_path = logo_path\n",
        "        self.next_screen_name = next_screen_name\n",
        "        self.right_image_url = right_image_url  # NEW\n",
        "\n",
        "        # LEFT image state\n",
        "        self._raw_logo_left = None     # PIL.Image\n",
        "        self._tk_logo_left = None      # ImageTk.PhotoImage\n",
        "        # RIGHT image state\n",
        "        self._raw_logo_right = None    # PIL.Image\n",
        "        self._tk_logo_right = None     # ImageTk.PhotoImage\n",
        "\n",
        "        self._fade_step = 0\n",
        "        self._fade_total = 18\n",
        "        self._fade_job = None\n",
        "        self._glow_job = None\n",
        "        self._glow_phase = 0.0\n",
        "\n",
        "        self._build_style()\n",
        "        self._build_ui()\n",
        "        self._load_logos()\n",
        "        self.after(300, self._start_animation)\n",
        "\n",
        "    # ---------- UI ----------\n",
        "\n",
        "    def _knockout_bg_from_corners(img, sample=8, tol=55):\n",
        "        \"\"\"\n",
        "        Make the background transparent by sampling the 4 corners to detect the bg color.\n",
        "        Works even if the bg isn't pure white.\n",
        "        tol: bigger => more aggressive removal.\n",
        "        \"\"\"\n",
        "        img = img.convert(\"RGBA\")\n",
        "        w, h = img.size\n",
        "        px = img.load()\n",
        "\n",
        "        # sample small squares from the 4 corners\n",
        "        samples = []\n",
        "        for x in range(sample):\n",
        "            for y in range(sample):\n",
        "                samples.append(px[x, y][:3])  # top-left\n",
        "                samples.append(px[w - 1 - x, y][:3])  # top-right\n",
        "                samples.append(px[x, h - 1 - y][:3])  # bottom-left\n",
        "                samples.append(px[w - 1 - x, h - 1 - y][:3])  # bottom-right\n",
        "\n",
        "        # average corner color = background\n",
        "        sr = sum(r for r, _, _ in samples) / len(samples)\n",
        "        sg = sum(g for _, g, _ in samples) / len(samples)\n",
        "        sb = sum(b for _, _, b in samples) / len(samples)\n",
        "\n",
        "        def close_to_bg(r, g, b):\n",
        "            return (abs(r - sr) <= tol and abs(g - sg) <= tol and abs(b - sb) <= tol)\n",
        "\n",
        "        # build new pixels with alpha knocked out for bg-like pixels\n",
        "        for x in range(w):\n",
        "            for y in range(h):\n",
        "                r, g, b, a = px[x, y]\n",
        "                if close_to_bg(r, g, b):\n",
        "                    px[x, y] = (r, g, b, 0)  # transparent\n",
        "                else:\n",
        "                    px[x, y] = (r, g, b, a if a != 0 else 255)  # keep/ensure opaque\n",
        "        return img\n",
        "\n",
        "    def _build_style(self):\n",
        "        style = ttk.Style(self)\n",
        "        try:\n",
        "            if style.theme_use() not in style.theme_names():\n",
        "                style.theme_use(\"clam\")\n",
        "        except Exception:\n",
        "            try:\n",
        "                style.theme_use(\"clam\")\n",
        "            except Exception:\n",
        "                pass\n",
        "        style.configure(\"Title.TLabel\", font=(\"Arial\", 36, \"bold\"))\n",
        "        style.configure(\"Subtitle.TLabel\", font=(\"Arial\", 24, \"bold\"))\n",
        "        style.configure(\"Body.TLabel\", font=(\"Arial\", 24))\n",
        "        style.configure(\"Start.TButton\", font=(\"Arial\", 16, \"bold\"))\n",
        "        style.configure(\"Small.TLabel\", font=(\"Arial\", 14, \"bold\"))\n",
        "\n",
        "    def _build_ui(self):\n",
        "        self.columnconfigure(0, weight=1)\n",
        "        self.rowconfigure(4, weight=1)\n",
        "\n",
        "        # top welcome\n",
        "        ttk.Label(self, text=\"WELCOME\", style=\"Title.TLabel\").grid(row=0, column=0, pady=(30, 0), sticky=\"n\")\n",
        "        ttk.Label(\n",
        "            self,\n",
        "            text=(\n",
        "                \"This tool uses image preprocessing (CLAHE, segmentation, cropping), \"\n",
        "                \"majority-vote Norwood stage classification from 5 CNNs, and an XGBoost tabular hair-fall predictor. \"\n",
        "                \"Built with Tkinter, it provides insights for clinical use in hair-transplant settings, \"\n",
        "                \"with the goal of supporting early intervention and offering personalized recommendations based on the results.\"\n",
        "            ),\n",
        "            style=\"Subtitle.TLabel\",\n",
        "            wraplength=700,\n",
        "            justify=\"center\"\n",
        "        ).grid(row=1, column=0, pady=(6, 0), sticky=\"n\")\n",
        "\n",
        "        ttk.Label(\n",
        "            self,\n",
        "            text=(\n",
        "                \"We provide recommendations and scientifically-backed preventive measures \"\n",
        "                \"based on your predicted male-pattern stage, and we estimate the number of \"\n",
        "                \"hair follicles needed to restore a full hairline.\"\n",
        "            ),\n",
        "            style=\"Body.TLabel\",\n",
        "            wraplength=820,\n",
        "            justify=\"center\"\n",
        "        ).grid(row=2, column=0, pady=(24, 12), sticky=\"n\")\n",
        "\n",
        "        # logo + progress\n",
        "        logo_wrap = ttk.Frame(self)\n",
        "        logo_wrap.grid(row=3, column=0, pady=(8, 4), sticky=\"n\")\n",
        "\n",
        "        # LEFT and RIGHT logo labels (side-by-side)\n",
        "        self.logo_label_left = tk.Label(logo_wrap, borderwidth=0, highlightthickness=0)\n",
        "        self.logo_label_left.pack(side=\"left\", padx=(0, 12), pady=(0, 8))\n",
        "\n",
        "        self.logo_label_right = tk.Label(logo_wrap, borderwidth=0, highlightthickness=0)\n",
        "        self.logo_label_right.pack(side=\"left\", padx=(12, 0), pady=(0, 8))\n",
        "\n",
        "        # subtle glowing bar\n",
        "        self.glow = tk.Canvas(self, width=480, height=12, highlightthickness=0, bd=0)\n",
        "        self.glow.grid(row=4, column=0, pady=(0, 20), sticky=\"n\")\n",
        "        self.glow_bar = self.glow.create_rectangle(6, 4, 474, 8, outline=\"\", fill=\"#dbeafe\")\n",
        "\n",
        "        # start button\n",
        "        self.start_btn = ttk.Button(self, text=\"START NOW >\", style=\"Start.TButton\", command=self._on_start)\n",
        "        self.start_btn.grid(row=5, column=0, pady=(6, 28))\n",
        "\n",
        "        # tagline\n",
        "        box = ttk.Frame(self, padding=16)\n",
        "        box.grid(row=6, column=0, pady=(8, 30))\n",
        "        ttk.Label(\n",
        "            box,\n",
        "            text=\"Version 3.0 - We are students from The Max Stern Valley College - This is our final project - Students Alam Bebar (207415407), Ryan Thawkho (305070567)\"\n",
        "        ).pack()\n",
        "\n",
        "        ttk.Label(\n",
        "            self,\n",
        "            text=\"Tip: Your hairline is more than just hair â€” itâ€™s confidence, presence, and the best version of you. Donâ€™t settle for less.\",\n",
        "            style=\"Small.TLabel\"\n",
        "        ).grid(row=7, column=0, pady=(0, 12))\n",
        "\n",
        "    # ---------- Image helpers ----------\n",
        "\n",
        "    def _open_image(self, src):\n",
        "        \"\"\"\n",
        "        Returns a PIL.Image in RGBA from either:\n",
        "          - local file path, or\n",
        "          - URL (http/https), incl. Google Drive share links.\n",
        "        Raises on failure.\n",
        "        \"\"\"\n",
        "        if not src:\n",
        "            raise FileNotFoundError(\"No image source provided\")\n",
        "\n",
        "        src = str(src).strip()\n",
        "\n",
        "        if src.startswith(\"http://\") or src.startswith(\"https://\"):\n",
        "            url = src\n",
        "            # Handle Google Drive share links\n",
        "            m = re.search(r\"/d/([a-zA-Z0-9_-]+)/\", url) or re.search(r\"[?&]id=([a-zA-Z0-9_-]+)\", url)\n",
        "            if \"drive.google.com\" in url and m:\n",
        "                file_id = m.group(1)\n",
        "                url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
        "\n",
        "            r = requests.get(url, timeout=15)\n",
        "            r.raise_for_status()\n",
        "            return Image.open(io.BytesIO(r.content)).convert(\"RGBA\")\n",
        "\n",
        "        if not os.path.exists(src):\n",
        "            raise FileNotFoundError(f\"Image file not found: {src}\")\n",
        "        return Image.open(src).convert(\"RGBA\")\n",
        "\n",
        "    # ---------- Logo handling + fade ----------\n",
        "\n",
        "    # --- Replace your _load_logos with this version ---\n",
        "    def _load_logos(self):\n",
        "        if Image is None or ImageTk is None:\n",
        "            self.logo_label_left.config(text=\"(logo)\")\n",
        "            self.logo_label_right.config(text=\"(logo)\")\n",
        "            return\n",
        "\n",
        "        # Load originals\n",
        "        left_img = None\n",
        "        right_img = None\n",
        "        try:\n",
        "            left_img = self._open_image(self.logo_path)\n",
        "            if left_img is not None:\n",
        "                left_img = _knockout_bg_from_corners(left_img, tol=60)  # adjust tol 45â€“70 if needed\n",
        "        except Exception as e:\n",
        "            self.logo_label_left.config(text=f\"(logo not available: {e})\")\n",
        "        try:\n",
        "            right_img = self._open_image(self.right_image_url)\n",
        "            if right_img is not None:\n",
        "                right_img = _knockout_near_white(right_img)\n",
        "        except Exception as e:\n",
        "            self.logo_label_right.config(text=f\"(image not available: {e})\")\n",
        "\n",
        "        if left_img is None and right_img is None:\n",
        "            return\n",
        "\n",
        "        # LEFT: downscale only to target width ~300 (keep aspect)\n",
        "        left_final = None\n",
        "        if left_img is not None:\n",
        "            w, h = left_img.size\n",
        "            target_w = 300\n",
        "            if w > target_w:\n",
        "                scale = target_w / float(w)\n",
        "                left_final = left_img.resize((int(w * scale), int(h * scale)), Image.LANCZOS)\n",
        "            else:\n",
        "                left_final = left_img.copy()\n",
        "            if left_final.mode != \"RGBA\":\n",
        "                left_final = left_final.convert(\"RGBA\")\n",
        "\n",
        "        # RIGHT: match LEFT height (downscale only). If no left, use ~220w.\n",
        "        right_final = None\n",
        "        if right_img is not None:\n",
        "            if right_img.mode != \"RGBA\":\n",
        "                right_img = right_img.convert(\"RGBA\")\n",
        "            if left_final is not None:\n",
        "                _, lh = left_final.size\n",
        "                rw, rh = right_img.size\n",
        "                if rh > lh and rh > 0:\n",
        "                    scale = lh / float(rh)\n",
        "                    right_final = right_img.resize((int(rw * scale), int(rh * scale)), Image.LANCZOS)\n",
        "                else:\n",
        "                    right_final = right_img.copy()\n",
        "            else:\n",
        "                # fallback if no left: downscale only to ~220w\n",
        "                rw, rh = right_img.size\n",
        "                target_w_r = 220\n",
        "                if rw > target_w_r:\n",
        "                    scale = target_w_r / float(rw)\n",
        "                    right_final = right_img.resize((int(rw * scale), int(rh * scale)), Image.LANCZOS)\n",
        "                else:\n",
        "                    right_final = right_img.copy()\n",
        "\n",
        "        # Store originals for fade (with original alpha preserved)\n",
        "        self._raw_logo_left = left_final\n",
        "        self._raw_logo_right = right_final\n",
        "\n",
        "        # Initialize as fully transparent (by scaling original alpha to 0)\n",
        "        if self._raw_logo_left is not None:\n",
        "            start_l = _fade_with_original_alpha(self._raw_logo_left, 0.0)\n",
        "            self._tk_logo_left = ImageTk.PhotoImage(start_l)\n",
        "            self.logo_label_left.configure(image=self._tk_logo_left)\n",
        "\n",
        "        if self._raw_logo_right is not None:\n",
        "            start_r = _fade_with_original_alpha(self._raw_logo_right, 0.0)\n",
        "            self._tk_logo_right = ImageTk.PhotoImage(start_r)\n",
        "            self.logo_label_right.configure(image=self._tk_logo_right)\n",
        "\n",
        "    def _start_animation(self):\n",
        "        self._fade_step = 0\n",
        "        if self._raw_logo_left is not None or self._raw_logo_right is not None:\n",
        "            self._schedule_fade()\n",
        "        self._start_glow()\n",
        "\n",
        "\n",
        "    def _schedule_fade(self):\n",
        "        if self._fade_step > self._fade_total:\n",
        "            return\n",
        "        factor = (self._fade_step / float(self._fade_total))  # 0â†’1\n",
        "\n",
        "        if self._raw_logo_left is not None:\n",
        "            img_l = _fade_with_original_alpha(self._raw_logo_left, factor)\n",
        "            self._tk_logo_left = ImageTk.PhotoImage(img_l)\n",
        "            self.logo_label_left.configure(image=self._tk_logo_left)\n",
        "\n",
        "        if self._raw_logo_right is not None:\n",
        "            img_r = _fade_with_original_alpha(self._raw_logo_right, factor)\n",
        "            self._tk_logo_right = ImageTk.PhotoImage(img_r)\n",
        "            self.logo_label_right.configure(image=self._tk_logo_right)\n",
        "\n",
        "        self._fade_step += 1\n",
        "        self._fade_job = self.after(40, self._schedule_fade)\n",
        "\n",
        "    # ---------- Navigation ----------\n",
        "\n",
        "    def _on_start(self):\n",
        "        self._stop_glow()\n",
        "        if self._fade_job:\n",
        "            try:\n",
        "                self.after_cancel(self._fade_job)\n",
        "            except Exception:\n",
        "                pass\n",
        "            self._fade_job = None\n",
        "\n",
        "        if self.controller is not None:\n",
        "            if hasattr(self.controller, \"go_to_intake\"):\n",
        "                self.controller.go_to_intake()\n",
        "            elif hasattr(self.controller, \"show\"):\n",
        "                self.controller.show(\"intake\")\n",
        "            else:\n",
        "                print(\"[LoadingScreen] No navigation method on controller.\")\n",
        "        else:\n",
        "            print(f\"[LoadingScreen] Start clicked â†’ would show: {self.next_screen_name}\")\n",
        "\n",
        "    def _start_glow(self):\n",
        "        if self._glow_job is None:\n",
        "            self._glow_phase = 0.0\n",
        "            self._tick_glow()\n",
        "\n",
        "    def _stop_glow(self):\n",
        "        if self._glow_job is not None:\n",
        "            try:\n",
        "                self.after_cancel(self._glow_job)\n",
        "            except Exception:\n",
        "                pass\n",
        "            self._glow_job = None\n",
        "\n",
        "    def _tick_glow(self):\n",
        "        self._glow_phase += 0.06\n",
        "        brightness = 200 + int(40 * (0.5 + 0.5 * math.sin(self._glow_phase)))\n",
        "        r = int(brightness * 0.55)\n",
        "        g = int(brightness * 0.75)\n",
        "        b = min(255, brightness + 15)\n",
        "        color = f\"#{r:02x}{g:02x}{b:02x}\"\n",
        "        try:\n",
        "            self.glow.itemconfig(self.glow_bar, fill=color)\n",
        "        except Exception:\n",
        "            pass\n",
        "        self._glow_job = self.after(40, self._tick_glow)  # ~25 FPS\n",
        "\n",
        "    def _fade_with_original_alpha(img_rgba, factor: float):\n",
        "        \"\"\"\n",
        "        Scale alpha channel by `factor` but preserve transparent pixels (no white bg).\n",
        "        \"\"\"\n",
        "        if img_rgba.mode != \"RGBA\":\n",
        "            img_rgba = img_rgba.convert(\"RGBA\")\n",
        "\n",
        "        # Split channels\n",
        "        r, g, b, a = img_rgba.split()\n",
        "\n",
        "        # Scale the alpha values (0â†’factor*alpha)\n",
        "        a = a.point(lambda px: int(px * factor))\n",
        "\n",
        "        # Recombine\n",
        "        return Image.merge(\"RGBA\", (r, g, b, a))\n",
        "\n",
        "    # Instead of PhotoImage(img) directly, use this helper:\n",
        "    def _to_tk(img):\n",
        "        \"\"\"Force Tkinter to respect alpha transparency.\"\"\"\n",
        "        return ImageTk.PhotoImage(img)\n",
        "\n",
        "    def _knockout_near_white(img, white=(255, 255, 255), tol=10):\n",
        "        \"\"\"\n",
        "        If img lacks an alpha channel, convert near-white background to transparent.\n",
        "        Leaves images that already have alpha untouched.\n",
        "        tol: how close to white gets removed (higher = more aggressive).\n",
        "        \"\"\"\n",
        "        if img.mode == \"RGBA\" and \"A\" in img.getbands():\n",
        "            return img  # already has alpha, do nothing\n",
        "\n",
        "        img = img.convert(\"RGBA\")\n",
        "        datas = img.getdata()\n",
        "        wr, wg, wb = white\n",
        "        out = []\n",
        "        th_r = max(0, wr - tol);\n",
        "        th_g = max(0, wg - tol);\n",
        "        th_b = max(0, wb - tol)\n",
        "        for px in datas:\n",
        "            r, g, b, a = px\n",
        "            if (r >= th_r and g >= th_g and b >= th_b):\n",
        "                out.append((r, g, b, 0))  # make near-white fully transparent\n",
        "            else:\n",
        "                out.append((r, g, b, 255))  # keep opaque\n",
        "        img.putdata(out)\n",
        "        return img\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZvZDptkmgq6"
      },
      "source": [
        "intake_screen.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kK1wvUx8mi9R"
      },
      "outputs": [],
      "source": [
        "# Screen 2: Image + Tabular Inference (Hugging Face)\n",
        "#\n",
        "# Requirements (same venv as project):\n",
        "#   pip install pillow numpy opencv-python torch torchvision efficientnet_pytorch huggingface_hub pandas joblib xgboost\n",
        "#\n",
        "# This frame expects the main app (controller) to set:\n",
        "#   - controller.shared[\"image_path\"] : str (path to the image picked in screen 1)\n",
        "#   - controller.shared[\"form\"]       : dict with keys:\n",
        "#        stay_up_late, water_reason, family_history, use_chemicals,\n",
        "#        stress, chronic_illness, age\n",
        "#\n",
        "# It renders:\n",
        "#   - image preview (left)\n",
        "#   - per-model predictions + majority vote (right, upper)\n",
        "#   - XGBoost hair fall prediction + probability (right, lower)\n",
        "\n",
        "import threading\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Tuple, Optional\n",
        "\n",
        "import tkinter as tk\n",
        "from tkinter import ttk, messagebox, filedialog\n",
        "\n",
        "# visuals\n",
        "from PIL import Image, ImageTk\n",
        "import cv2, numpy as np\n",
        "\n",
        "# â”€â”€ ML deps\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from huggingface_hub import hf_hub_download\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "import os, certifi\n",
        "os.environ[\"SSL_CERT_FILE\"] = certifi.where()\n",
        "os.environ[\"REQUESTS_CA_BUNDLE\"] = certifi.where()\n",
        "\n",
        "# ===== Hair Segmentation (exact HF setup you provided) =====\n",
        "REPO_ID   = \"alamb98/deeplabv3-hair-segmentation\"\n",
        "CKPT_NAME = \"deeplabv3_final.pth\"\n",
        "BACKBONE    = \"resnet50\"      # \"resnet50\" or \"resnet101\"\n",
        "NUM_CLASSES = 2               # background, hair\n",
        "HAIR_CLASS  = 1\n",
        "IMG_SIZE    = 256\n",
        "MEAN = [0.485, 0.456, 0.406]\n",
        "STD  = [0.229, 0.224, 0.225]\n",
        "EXPAND_RATIO = 0.01  # 1% of max(w, h) expansion around the hair bbox\n",
        "\n",
        "_SEG_MODEL = None\n",
        "_SEG_DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "_SEG_TFM = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=MEAN, std=STD),\n",
        "])\n",
        "\n",
        "def _get_seg_model():\n",
        "    global _SEG_MODEL\n",
        "    if _SEG_MODEL is not None:\n",
        "        return _SEG_MODEL\n",
        "    from torchvision.models.segmentation import deeplabv3_resnet50, deeplabv3_resnet101\n",
        "    if BACKBONE == \"resnet50\":\n",
        "        model = deeplabv3_resnet50(weights=None, num_classes=NUM_CLASSES, aux_loss=None)\n",
        "    elif BACKBONE == \"resnet101\":\n",
        "        model = deeplabv3_resnet101(weights=None, num_classes=NUM_CLASSES, aux_loss=None)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported BACKBONE.\")\n",
        "    ckpt_path = hf_hub_download(repo_id=REPO_ID, filename=CKPT_NAME)\n",
        "    state = torch.load(ckpt_path, map_location=\"cpu\")\n",
        "    if isinstance(state, dict) and \"state_dict\" in state and isinstance(state[\"state_dict\"], dict):\n",
        "        state = state[\"state_dict\"]\n",
        "    fixed = {}\n",
        "    if isinstance(state, dict):\n",
        "        for k, v in state.items():\n",
        "            if k.startswith(\"module.\"): k = k[7:]\n",
        "            if k.startswith(\"model.\"):  k = k[6:]\n",
        "            fixed[k] = v\n",
        "    else:\n",
        "        fixed = state\n",
        "    model.load_state_dict(fixed, strict=False)\n",
        "    model.to(_SEG_DEVICE).eval()\n",
        "    _SEG_MODEL = model\n",
        "    return _SEG_MODEL\n",
        "\n",
        "def _apply_clahe_bgr(img_bgr):\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    cl = clahe.apply(l)\n",
        "    merged = cv2.merge((cl, a, b))\n",
        "    return cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "def preprocess_with_segmentation(image_path: str) -> Image.Image:\n",
        "    \"\"\"\n",
        "    Loads image, applies CLAHE (exact params), runs DeeplabV3 segmentation (exact HF config),\n",
        "    crops around the hair bounding box with EXPAND_RATIO margin, draws red boundary on the\n",
        "    CROPPED image, and returns a PIL RGB image to feed the classifiers.\n",
        "    \"\"\"\n",
        "    # Load original (PIL) for size reference & later overlay\n",
        "    orig_pil = Image.open(image_path).convert(\"RGB\")\n",
        "    W, H = orig_pil.size\n",
        "\n",
        "    # OpenCV BGR for CLAHE\n",
        "    bgr = cv2.cvtColor(np.array(orig_pil), cv2.COLOR_RGB2BGR)\n",
        "    bgr = _apply_clahe_bgr(bgr)  # exact CLAHE\n",
        "\n",
        "    # Prepare model input from the (CLAHE-enhanced) RGB\n",
        "    pil_after_clahe = Image.fromarray(cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB))\n",
        "    x = _SEG_TFM(pil_after_clahe).unsqueeze(0).to(_SEG_DEVICE)\n",
        "\n",
        "    # Inference (exact DeeplabV3 config)\n",
        "    model = _get_seg_model()\n",
        "    with torch.no_grad():\n",
        "        out = model(x)\n",
        "        logits = out[\"out\"][0] if isinstance(out, dict) else out[0]\n",
        "        probs  = torch.softmax(logits, dim=0)\n",
        "        hair_p = probs[HAIR_CLASS].cpu().numpy()\n",
        "\n",
        "    # Resize prob map back to original, Otsu threshold, small morph cleanup (exact)\n",
        "    hair_p = cv2.resize(hair_p, (W, H), interpolation=cv2.INTER_LINEAR)\n",
        "    hair_u8 = np.clip(hair_p * 255.0, 0, 255).astype(np.uint8)\n",
        "    _, mask_u8 = cv2.threshold(hair_u8, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    mask_u8 = cv2.morphologyEx(mask_u8, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "    mask_u8 = cv2.morphologyEx(mask_u8, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
        "\n",
        "    # Find hair bounding box from mask (merge all contours)\n",
        "    contours, _ = cv2.findContours(mask_u8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if len(contours) == 0:\n",
        "        # No hair found â†’ fall back to full image\n",
        "        x, y, w, h = 0, 0, W, H\n",
        "    else:\n",
        "        all_pts = np.vstack(contours).squeeze()\n",
        "        xs, ys = all_pts[:, 0], all_pts[:, 1]\n",
        "        x_min, x_max = xs.min(), xs.max()\n",
        "        y_min, y_max = ys.min(), ys.max()\n",
        "        x, y, w, h = int(x_min), int(x_max - x_min), int(y_min), int(y_max - y_min)\n",
        "        # Note: carefulâ€”above was mixed; fix ordering properly:\n",
        "        x, y, w, h = int(x_min), int(y_min), int(x_max - x_min), int(y_max - y_min)\n",
        "\n",
        "    # Expand bbox by EXPAND_RATIO * max(w, h) and clamp to image bounds\n",
        "    margin = int(EXPAND_RATIO * max(w, h))\n",
        "    x1 = max(0, x - margin)\n",
        "    y1 = max(0, y - margin)\n",
        "    x2 = min(W, x + w + margin)\n",
        "    y2 = min(H, y + h + margin)\n",
        "\n",
        "    # Crop CLAHE-enhanced image and corresponding mask\n",
        "    cropped_bgr  = bgr[y1:y2, x1:x2]\n",
        "    cropped_mask = mask_u8[y1:y2, x1:x2]\n",
        "    if cropped_bgr.size == 0:  # safety fallback\n",
        "        cropped_bgr  = bgr.copy()\n",
        "        cropped_mask = mask_u8.copy()\n",
        "\n",
        "    # DO NOT draw contours on the image we feed to the models\n",
        "    cropped_rgb = cv2.cvtColor(cropped_bgr, cv2.COLOR_BGR2RGB)\n",
        "    return Image.fromarray(cropped_rgb)\n",
        "\n",
        "def preprocess_clahe_only(image_path: str) -> Image.Image:\n",
        "    \"\"\"\n",
        "    Apply the exact CLAHE you use elsewhere, but NO segmentation/cropping.\n",
        "    Returns a PIL RGB image (full frame) for model input.\n",
        "    \"\"\"\n",
        "    orig_pil = Image.open(image_path).convert(\"RGB\")\n",
        "    bgr = cv2.cvtColor(np.array(orig_pil), cv2.COLOR_RGB2BGR)\n",
        "    bgr = _apply_clahe_bgr(bgr)  # same CLAHE params (clipLimit=2.0, tileGridSize=(8,8))\n",
        "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
        "    return Image.fromarray(rgb)\n",
        "\n",
        "# ========== Shared UI helpers ==========\n",
        "def pil_to_tk(pil_img: Image.Image, max_size=(360, 360)):\n",
        "    w, h = pil_img.size\n",
        "    scale = min(max_size[0] / w, max_size[1] / h, 1.0)\n",
        "    if scale < 1.0:\n",
        "        pil_img = pil_img.resize((int(w * scale), int(h * scale)))\n",
        "    return ImageTk.PhotoImage(pil_img)\n",
        "\n",
        "# ========== Classifier wrappers (your exact HF logic) ==========\n",
        "\n",
        "@dataclass\n",
        "class ImageClassifier:\n",
        "    name: str\n",
        "    repo: str\n",
        "    weights_file: str\n",
        "    meta_file: str = \"metadata.json\"\n",
        "    model: Optional[torch.nn.Module] = None\n",
        "    tfm: Optional[object] = None\n",
        "    level_names: Optional[list] = None\n",
        "    label_base: int = 0\n",
        "    img_size: int = 224\n",
        "    mean: Tuple[float, float, float] = (0.485, 0.456, 0.406)\n",
        "    std: Tuple[float, float, float] = (0.229, 0.224, 0.225)\n",
        "\n",
        "    def _load_meta(self):\n",
        "        meta_path = hf_hub_download(self.repo, filename=self.meta_file)\n",
        "        with open(meta_path, \"r\") as f:\n",
        "            meta = json.load(f)\n",
        "        # labels field might be \"labels\" or \"class_names\"\n",
        "        self.level_names = meta.get(\"labels\") or meta.get(\"class_names\") or [f\"Level {i}\" for i in range(2, 8)]\n",
        "        self.img_size = int(meta.get(\"img_size\", 224))\n",
        "        self.mean = tuple(meta.get(\"mean\", [0.485, 0.456, 0.406]))\n",
        "        self.std = tuple(meta.get(\"std\", [0.229, 0.224, 0.225]))\n",
        "        self.label_base = int(meta.get(\"label_base\", 0))\n",
        "\n",
        "    def _build_resnet18(self):\n",
        "        model = models.resnet18(weights=None)\n",
        "        in_features = model.fc.in_features\n",
        "        model.fc = nn.Linear(in_features, len(self.level_names))\n",
        "        return model\n",
        "\n",
        "    def _build_mobilenet_v3_large(self):\n",
        "        model = models.mobilenet_v3_large(weights=None)\n",
        "        in_features = model.classifier[3].in_features\n",
        "        model.classifier[3] = nn.Linear(in_features, len(self.level_names))\n",
        "        return model\n",
        "\n",
        "    def _build_efficientnet_b0(self):\n",
        "        model = EfficientNet.from_name(\"efficientnet-b0\")\n",
        "        in_features = model._fc.in_features\n",
        "        model._fc = nn.Linear(in_features, len(self.level_names))\n",
        "        return model\n",
        "\n",
        "    def _build_convnext_tiny(self):\n",
        "        model = models.convnext_tiny(weights=None)\n",
        "        in_features = model.classifier[2].in_features\n",
        "        model.classifier[2] = nn.Linear(in_features, len(self.level_names))\n",
        "        return model\n",
        "\n",
        "    def _build_by_name(self):\n",
        "        if self.name == \"resnet18\":\n",
        "            return self._build_resnet18()\n",
        "        if self.name == \"mobilenet_v3_large\":\n",
        "            return self._build_mobilenet_v3_large()\n",
        "        if self.name == \"efficientnet_b0\":\n",
        "            return self._build_efficientnet_b0()\n",
        "        if self.name == \"convnext_tiny\":\n",
        "            return self._build_convnext_tiny()\n",
        "        if self.name == \"densenet121\":  # <-- add this\n",
        "            return self._build_densenet121()\n",
        "        raise ValueError(f\"Unknown model name: {self.name}\")\n",
        "\n",
        "    def _build_tfm(self):\n",
        "        self.tfm = transforms.Compose([\n",
        "            transforms.Resize((self.img_size, self.img_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=self.mean, std=self.std),\n",
        "        ])\n",
        "\n",
        "    def load(self):\n",
        "        if self.model is not None and self.tfm is not None:\n",
        "            return\n",
        "        # metadata\n",
        "        self._load_meta()\n",
        "        # weights\n",
        "        wpath = hf_hub_download(self.repo, filename=self.weights_file)\n",
        "        # arch\n",
        "        self.model = self._build_by_name()\n",
        "        # state\n",
        "        state = torch.load(wpath, map_location=\"cpu\")\n",
        "        if isinstance(state, dict) and \"state_dict\" in state and isinstance(state[\"state_dict\"], dict):\n",
        "            state = state[\"state_dict\"]\n",
        "        fixed = {}\n",
        "        if isinstance(state, dict):\n",
        "            for k, v in state.items():\n",
        "                if isinstance(k, str) and k.startswith(\"module.\"):\n",
        "                    k = k[len(\"module.\"):]\n",
        "                if isinstance(k, str) and k.startswith(\"model.\"):\n",
        "                    k = k[len(\"model.\"):]\n",
        "                fixed[k] = v\n",
        "        else:\n",
        "            fixed = state\n",
        "        self.model.load_state_dict(fixed, strict=True)\n",
        "        self.model.eval()\n",
        "        # tfm\n",
        "        self._build_tfm()\n",
        "\n",
        "    def predict_level(self, pil_rgb: Image.Image) -> Tuple[int, str]:\n",
        "        x = self.tfm(pil_rgb).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            logits = self.model(x)\n",
        "            pred_idx = int(logits.argmax(-1).item())  # 0-based class index\n",
        "\n",
        "        # Numeric level anchored to label_base (0 means \"use +1\")\n",
        "        base = int(self.label_base) if self.label_base is not None else 0\n",
        "        level = pred_idx + (1 if base == 0 else base)\n",
        "\n",
        "        # Human-readable label: pick directly by class index\n",
        "        if self.level_names and 0 <= pred_idx < len(self.level_names):\n",
        "            label_str = self.level_names[pred_idx]\n",
        "        else:\n",
        "            label_str = f\"Level {level}\"\n",
        "\n",
        "        # If labels look like \"Level 2\", trust that number to keep both in sync\n",
        "        try:\n",
        "            import re\n",
        "            m = re.search(r'(\\d+)', label_str)\n",
        "            if m:\n",
        "                level = int(m.group(1))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        return level, label_str\n",
        "\n",
        "    def _build_densenet121(self):\n",
        "        model = models.densenet121(weights=None)\n",
        "        in_features = model.classifier.in_features\n",
        "        model.classifier = nn.Linear(in_features, len(self.level_names))\n",
        "        return model\n",
        "\n",
        "\n",
        "# Instantiate the four models (lazy-loaded)\n",
        "CLS_RESNET18 = ImageClassifier(\n",
        "    name=\"resnet18\",\n",
        "    repo=\"alamb98/resnet18\",\n",
        "    weights_file=\"resnet18.pth\",\n",
        ")\n",
        "\n",
        "CLS_MNV3 = ImageClassifier(\n",
        "    name=\"mobilenet_v3_large\",\n",
        "    repo=\"alamb98/mobilenet_v3_large_cropped_clahe_norwood_classifier\",\n",
        "    weights_file=\"mobilenet_v3_large_cropped_clahe_best.pth\",\n",
        ")\n",
        "\n",
        "CLS_EFFB0 = ImageClassifier(\n",
        "    name=\"efficientnet_b0\",\n",
        "    repo=\"alamb98/efficientnet-b0_norwood_classifier\",\n",
        "    weights_file=\"efficientnet-b0_best.pth\",\n",
        ")\n",
        "\n",
        "CLS_CONVNEXT = ImageClassifier(\n",
        "    name=\"convnext_tiny\",\n",
        "    repo=\"alamb98/convnext_tiny_clahe_norwood_classifier\",\n",
        "    weights_file=\"convnext_tiny_clahe_best.pth\",\n",
        ")\n",
        "\n",
        "CLS_DENSENET = ImageClassifier(\n",
        "    name=\"densenet121\",\n",
        "    repo=\"alamb98/densenet121\",\n",
        "    weights_file=\"densenet121.pth\",\n",
        ")\n",
        "\n",
        "\n",
        "# ========== XGBoost HF joblib (exact feature order you provided) ==========\n",
        "\n",
        "XGB_REPO = \"alamb98/xgboost_hair_fall_classifier\"\n",
        "XGB_FILENAME = \"xgboost_hair_fall_classifier.joblib\"\n",
        "\n",
        "FEATURE_COLUMNS = [\n",
        "    \"Do you stay up late at night?_Yes\",\n",
        "    \"Do you think that in your area water is a reason behind hair fall problems?_Yes\",\n",
        "    \"Is there anyone in your family having a hair fall problem or a baldness issue?_Yes\",\n",
        "    \"Do you use chemicals, hair gel, or color in your hair?_Yes\",\n",
        "    \"Do you have too much stress_Yes\",\n",
        "    \"Did you face any type of chronic illness in the past?_Yes\",\n",
        "    \"What is your age ?\"\n",
        "]\n",
        "\n",
        "_xgb_model_cache = None\n",
        "\n",
        "def _to01(v):\n",
        "    v = str(v).strip().lower()\n",
        "    return 1 if v in (\"yes\", \"y\", \"1\", \"true\", \"t\") else 0\n",
        "\n",
        "def form_to_features(form: dict) -> pd.DataFrame:\n",
        "    row = {\n",
        "        \"Do you stay up late at night?_Yes\": _to01(form.get(\"stay_up_late\", \"No\")),\n",
        "        \"Do you think that in your area water is a reason behind hair fall problems?_Yes\": _to01(form.get(\"water_reason\", \"No\")),\n",
        "        \"Is there anyone in your family having a hair fall problem or a baldness issue?_Yes\": _to01(form.get(\"family_history\", \"No\")),\n",
        "        \"Do you use chemicals, hair gel, or color in your hair?_Yes\": _to01(form.get(\"use_chemicals\", \"No\")),\n",
        "        \"Do you have too much stress_Yes\": _to01(form.get(\"stress\", \"No\")),\n",
        "        \"Did you face any type of chronic illness in the past?_Yes\": _to01(form.get(\"chronic_illness\", \"No\")),\n",
        "        \"What is your age ?\": float(form.get(\"age\", 0)),\n",
        "    }\n",
        "    return pd.DataFrame([row], columns=FEATURE_COLUMNS)\n",
        "\n",
        "def load_xgb():\n",
        "    global _xgb_model_cache\n",
        "    if _xgb_model_cache is None:\n",
        "        model_path = hf_hub_download(repo_id=XGB_REPO, filename=XGB_FILENAME)\n",
        "        _xgb_model_cache = joblib.load(model_path)\n",
        "    return _xgb_model_cache\n",
        "\n",
        "def predict_xgb(form: dict):\n",
        "    mdl = load_xgb()\n",
        "    X = form_to_features(form).astype(float)\n",
        "    y_pred = int(mdl.predict(X)[0])\n",
        "    if hasattr(mdl, \"predict_proba\"):\n",
        "        proba_yes = float(mdl.predict_proba(X)[0][1])\n",
        "    else:\n",
        "        proba_yes = float(\"nan\")\n",
        "    label = {0: \"No hair fall\", 1: \"Yes hair fall\"}.get(y_pred, str(y_pred))\n",
        "    return y_pred, label, proba_yes\n",
        "\n",
        "# ========== Majority vote helper ==========\n",
        "\n",
        "def majority_vote(levels: Dict[str, int]) -> int:\n",
        "    from collections import Counter\n",
        "    arr = list(levels.values())\n",
        "    c = Counter(arr)\n",
        "    maxc = max(c.values()) if c else 0\n",
        "    winners = [lvl for lvl, cnt in c.items() if cnt == maxc] if c else [3]\n",
        "    return min(winners)\n",
        "\n",
        "# ========== Tkinter Screen ==========\n",
        "\n",
        "class IntakeScreen(ttk.Frame):\n",
        "    \"\"\"\n",
        "    Usage:\n",
        "      screen = ModelsScreen(parent, controller)\n",
        "      controller.shared must include:\n",
        "        - \"image_path\": str\n",
        "        - \"form\": dict (keys listed above)\n",
        "    \"\"\"\n",
        "    def __init__(self, parent, controller):\n",
        "        super().__init__(parent)\n",
        "        self.controller = controller\n",
        "\n",
        "        # --- Header ---\n",
        "        hdr = ttk.Frame(self)\n",
        "        hdr.pack(fill=\"x\", pady=10, padx=16)\n",
        "        ttk.Label(hdr, text=\"Run Models\", font=(\"Arial\", 18, \"bold\")).pack(side=\"left\")\n",
        "\n",
        "        # --- Body (left: preview, right: results) ---\n",
        "        body = ttk.Frame(self)\n",
        "        body.pack(fill=\"both\", expand=True, padx=16, pady=8)\n",
        "\n",
        "        # --- Toolbar: choose image ---\n",
        "        tools = ttk.Frame(self)\n",
        "        tools.pack(fill=\"x\", padx=16, pady=(0, 8))\n",
        "\n",
        "        ttk.Button(tools, text=\"Choose Imageâ€¦\", command=self.on_choose_image).pack(side=\"left\")\n",
        "\n",
        "        self.path_var = tk.StringVar(value=\"No image selected\")\n",
        "        ttk.Label(tools, textvariable=self.path_var).pack(side=\"left\", padx=10)\n",
        "\n",
        "        # Left: image preview (original + processed)\n",
        "        left = ttk.LabelFrame(body, text=\"Input Image\")\n",
        "        left.pack(side=\"left\", fill=\"both\", expand=True, padx=(0, 10))\n",
        "\n",
        "        # Original\n",
        "        self.preview_orig = ttk.Label(left, text=\"No image\")\n",
        "        self.preview_orig.pack(fill=\"both\", expand=True, padx=10, pady=(10, 5))\n",
        "\n",
        "        # Processed\n",
        "        self.preview_proc = ttk.Label(left, text=\"(Processed will appear here)\")\n",
        "        self.preview_proc.pack(fill=\"both\", expand=True, padx=10, pady=(5, 10))\n",
        "\n",
        "        # Right: predictions\n",
        "        right = ttk.LabelFrame(body, text=\"Predictions\")\n",
        "        right.pack(side=\"left\", fill=\"both\", expand=True, padx=(10, 0))\n",
        "\n",
        "        # Progress\n",
        "        self.pbar = ttk.Progressbar(right, mode=\"determinate\", maximum=100)\n",
        "        self.pbar.pack(fill=\"x\", padx=12, pady=(10, 4))\n",
        "        self.status = ttk.Label(right, text=\"Idle.\")\n",
        "        self.status.pack(fill=\"x\", padx=12)\n",
        "\n",
        "        # Per-model results\n",
        "        self.txt = tk.Text(right, height=18, wrap=\"word\")\n",
        "        self.txt.pack(fill=\"both\", expand=True, padx=12, pady=10)\n",
        "\n",
        "        # Footer buttons\n",
        "        ftr = ttk.Frame(self)\n",
        "        ftr.pack(fill=\"x\", pady=10, padx=16)\n",
        "        ttk.Button(ftr, text=\"Back\", command=self.on_back).pack(side=\"left\")\n",
        "        ttk.Button(ftr, text=\"Run Predictions\", command=self.on_run).pack(side=\"right\")\n",
        "\n",
        "        # NEW: view recommendations button (hidden by default; shown only if results exist)\n",
        "        self.view_btn = ttk.Button(\n",
        "            ftr, text=\"View Recommendations â†’\",\n",
        "            command=self.on_view_results\n",
        "        )\n",
        "        # Don't pack yet; we'll show/hide via _sync_view_btn_visibility()\n",
        "\n",
        "        # keep a place to store last results\n",
        "        self._last_results = None\n",
        "        # Auto show preview if available\n",
        "        self.after(50, self._refresh_preview)\n",
        "\n",
        "        # --- Form: features for XGBoost ---\n",
        "        form_wrap = ttk.LabelFrame(body, text=\"Tabular Features\")\n",
        "        form_wrap.pack(side=\"left\", fill=\"y\", padx=(0, 10), pady=0)\n",
        "\n",
        "        # Variables\n",
        "        self.var_stay_up_late   = tk.StringVar(value=\"No\")\n",
        "        self.var_water_reason   = tk.StringVar(value=\"No\")\n",
        "        self.var_family_history = tk.StringVar(value=\"No\")\n",
        "        self.var_use_chemicals  = tk.StringVar(value=\"No\")\n",
        "        self.var_stress         = tk.StringVar(value=\"No\")\n",
        "        self.var_chronic        = tk.StringVar(value=\"No\")\n",
        "        self.var_age            = tk.StringVar(value=\"25\")  # keep as string, we cast later\n",
        "\n",
        "        def yn_row(parent, label, var):\n",
        "            r = ttk.Frame(parent); r.pack(fill=\"x\", padx=8, pady=4)\n",
        "            ttk.Label(r, text=label, width=34, anchor=\"w\").pack(side=\"left\")\n",
        "            cb = ttk.Combobox(r, textvariable=var, state=\"readonly\", values=[\"No\", \"Yes\"], width=6)\n",
        "            cb.pack(side=\"left\")\n",
        "            return cb\n",
        "\n",
        "        yn_row(form_wrap, \"Do you stay up late at night?\", self.var_stay_up_late)\n",
        "        yn_row(form_wrap, \"Water in your area a reason?\", self.var_water_reason)\n",
        "        yn_row(form_wrap, \"Family hair fall/baldness history?\", self.var_family_history)\n",
        "        yn_row(form_wrap, \"Use chemicals/gel/color?\", self.var_use_chemicals)\n",
        "        yn_row(form_wrap, \"Too much stress?\", self.var_stress)\n",
        "        yn_row(form_wrap, \"Chronic illness in the past?\", self.var_chronic)\n",
        "\n",
        "        age_row = ttk.Frame(form_wrap); age_row.pack(fill=\"x\", padx=8, pady=(8,4))\n",
        "        ttk.Label(age_row, text=\"Age\", width=34, anchor=\"w\").pack(side=\"left\")\n",
        "        ttk.Entry(age_row, textvariable=self.var_age, width=8).pack(side=\"left\")\n",
        "        self._sync_view_btn_visibility()\n",
        "\n",
        "    def _compute_cropped_mask(self, image_path: str):\n",
        "        \"\"\"\n",
        "        Recompute the hair mask exactly like preprocess_with_segmentation,\n",
        "        then crop it with the same expanded bbox. Returns a binary uint8 mask.\n",
        "        \"\"\"\n",
        "        orig_pil = Image.open(image_path).convert(\"RGB\")\n",
        "        W, H = orig_pil.size\n",
        "\n",
        "        # CLAHE on BGR (same as your segmentation input)\n",
        "        bgr = cv2.cvtColor(np.array(orig_pil), cv2.COLOR_RGB2BGR)\n",
        "        bgr = _apply_clahe_bgr(bgr)\n",
        "\n",
        "        # Segment (same exact config)\n",
        "        pil_after_clahe = Image.fromarray(cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB))\n",
        "        x = _SEG_TFM(pil_after_clahe).unsqueeze(0).to(_SEG_DEVICE)\n",
        "        model = _get_seg_model()\n",
        "        with torch.no_grad():\n",
        "            out = model(x)\n",
        "            logits = out[\"out\"][0] if isinstance(out, dict) else out[0]\n",
        "            probs = torch.softmax(logits, dim=0)\n",
        "            hair_p = probs[HAIR_CLASS].cpu().numpy()\n",
        "\n",
        "        # Mask (resize back + Otsu + morph) â€“ identical to preprocess\n",
        "        hair_p = cv2.resize(hair_p, (W, H), interpolation=cv2.INTER_LINEAR)\n",
        "        hair_u8 = np.clip(hair_p * 255.0, 0, 255).astype(np.uint8)\n",
        "        _, mask_u8 = cv2.threshold(hair_u8, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        kernel = np.ones((3, 3), np.uint8)\n",
        "        mask_u8 = cv2.morphologyEx(mask_u8, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "        mask_u8 = cv2.morphologyEx(mask_u8, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
        "\n",
        "        # Same bbox + expand logic\n",
        "        contours, _ = cv2.findContours(mask_u8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        if len(contours) == 0:\n",
        "            x, y, w, h = 0, 0, W, H\n",
        "        else:\n",
        "            all_pts = np.vstack(contours).squeeze()\n",
        "            xs, ys = all_pts[:, 0], all_pts[:, 1]\n",
        "            x_min, x_max = xs.min(), xs.max()\n",
        "            y_min, y_max = ys.min(), ys.max()\n",
        "            x, y, w, h = int(x_min), int(y_min), int(x_max - x_min), int(y_max - y_min)\n",
        "\n",
        "        margin = int(EXPAND_RATIO * max(w, h))\n",
        "        x1 = max(0, x - margin);\n",
        "        y1 = max(0, y - margin)\n",
        "        x2 = min(W, x + w + margin);\n",
        "        y2 = min(H, y + h + margin)\n",
        "\n",
        "        cropped_mask = mask_u8[y1:y2, x1:x2]\n",
        "        if cropped_mask.size == 0:\n",
        "            cropped_mask = mask_u8.copy()\n",
        "        return cropped_mask\n",
        "\n",
        "    def _refresh_preview(self):\n",
        "        img_path = self.controller.shared.get(\"image_path\")\n",
        "        self.path_var.set(img_path or \"No image selected\")\n",
        "        if not img_path:\n",
        "            try:\n",
        "                self.preview_orig.configure(text=\"No image selected\", image=\"\")\n",
        "            except Exception:\n",
        "                pass\n",
        "            try:\n",
        "                self.preview_proc.configure(text=\"(Processed will appear here)\", image=\"\")\n",
        "                self.preview_proc.image = None\n",
        "            except Exception:\n",
        "                pass\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            # Original (top)\n",
        "            pil_orig = Image.open(img_path).convert(\"RGB\")\n",
        "            tk_img_orig = pil_to_tk(pil_orig)\n",
        "            self.preview_orig.configure(image=tk_img_orig, text=\"\")\n",
        "            self.preview_orig.image = tk_img_orig\n",
        "\n",
        "            # Clean processed for models (no red outline)\n",
        "            pil_proc_clean = preprocess_with_segmentation(img_path)\n",
        "\n",
        "            # Preview-only red outline from REAL cropped mask\n",
        "            cropped_mask = self._compute_cropped_mask(img_path)\n",
        "            arr = np.array(pil_proc_clean)\n",
        "            bgr = cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)\n",
        "            contours, _ = cv2.findContours(cropped_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            bgr_preview = bgr.copy()\n",
        "            cv2.drawContours(bgr_preview, contours, -1, (0, 0, 255), 2)\n",
        "            pil_proc_preview = Image.fromarray(cv2.cvtColor(bgr_preview, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "            tk_img_proc = pil_to_tk(pil_proc_preview)\n",
        "            self.preview_proc.configure(image=tk_img_proc, text=\"\")\n",
        "            self.preview_proc.image = tk_img_proc\n",
        "\n",
        "        except Exception as e:\n",
        "            try:\n",
        "                self.preview_orig.configure(text=f\"Failed to load image:\\n{e}\", image=\"\")\n",
        "                self.preview_orig.image = None\n",
        "            except Exception:\n",
        "                pass\n",
        "            try:\n",
        "                self.preview_proc.configure(text=\"(Processing failed)\", image=\"\")\n",
        "                self.preview_proc.image = None\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    def on_back(self):\n",
        "        if hasattr(self.controller, \"show\"):\n",
        "            self.controller.show(\"loading\")\n",
        "        else:\n",
        "            messagebox.showinfo(\"Back\", \"Implement controller.show(...) to navigate.\")\n",
        "\n",
        "    def on_show(self):\n",
        "        self._refresh_preview()\n",
        "        form = self.controller.shared.get(\"form\", {})\n",
        "        if form:\n",
        "            self.var_stay_up_late.set(\"Yes\" if form.get(\"stay_up_late\", \"No\") in (\"Yes\", \"yes\", 1, True) else \"No\")\n",
        "            self.var_water_reason.set(\"Yes\" if form.get(\"water_reason\", \"No\") in (\"Yes\", \"yes\", 1, True) else \"No\")\n",
        "            self.var_family_history.set(\"Yes\" if form.get(\"family_history\", \"No\") in (\"Yes\", \"yes\", 1, True) else \"No\")\n",
        "            self.var_use_chemicals.set(\"Yes\" if form.get(\"use_chemicals\", \"No\") in (\"Yes\", \"yes\", 1, True) else \"No\")\n",
        "            self.var_stress.set(\"Yes\" if form.get(\"stress\", \"No\") in (\"Yes\", \"yes\", 1, True) else \"No\")\n",
        "            self.var_chronic.set(\"Yes\" if form.get(\"chronic_illness\", \"No\") in (\"Yes\", \"yes\", 1, True) else \"No\")\n",
        "            try:\n",
        "                self.var_age.set(str(form.get(\"age\", \"\")))\n",
        "            except Exception:\n",
        "                pass\n",
        "            self._sync_view_btn_visibility()\n",
        "\n",
        "    def on_run(self):\n",
        "        img_path = self.controller.shared.get(\"image_path\")\n",
        "        if not img_path:\n",
        "            messagebox.showwarning(\"Missing image\", \"Please select an image on the first screen.\")\n",
        "            return\n",
        "\n",
        "        # collect and save the form so other screens can access it too\n",
        "        form = self._collect_form()\n",
        "        if hasattr(self.controller, \"shared\"):\n",
        "            self.controller.shared[\"form\"] = form\n",
        "\n",
        "        # clear UI + start\n",
        "        self.txt.delete(\"1.0\", \"end\")\n",
        "        self.status.config(text=\"Downloading / loading modelsâ€¦\")\n",
        "        self.pbar[\"value\"] = 0\n",
        "\n",
        "        t = threading.Thread(target=self._worker, args=(img_path, form), daemon=True)\n",
        "        t.start()\n",
        "\n",
        "    # Full replacement in _worker:\n",
        "    def _worker(self, img_path: str, form: dict):\n",
        "        try:\n",
        "            steps = [\n",
        "                (\"Load resnet18\", lambda: CLS_RESNET18.load()),\n",
        "                (\"Load mobilenet_v3_large\", lambda: CLS_MNV3.load()),\n",
        "                (\"Load efficientnet_b0\", lambda: CLS_EFFB0.load()),\n",
        "                (\"Load convnext_tiny\", lambda: CLS_CONVNEXT.load()),\n",
        "                (\"Load densenet121\", lambda: CLS_DENSENET.load()),  # <-- add this\n",
        "                (\"Load hair segmentation model\", lambda: _get_seg_model()),\n",
        "            ]\n",
        "\n",
        "            per_step = 50 / max(1, len(steps))  # first ~50% for loading (now includes seg)\n",
        "            for name, fn in steps:\n",
        "                self._ui_progress(name)\n",
        "                fn()\n",
        "                self._ui_bump(per_step)\n",
        "\n",
        "            # --- Build both inputs ---\n",
        "            self._ui_progress(\"Preprocessing imagesâ€¦\")\n",
        "            pil_proc = preprocess_with_segmentation(img_path)  # CLAHE + seg + crop (clean)\n",
        "            pil_clahe = preprocess_clahe_only(img_path)  # CLAHE only (full frame)\n",
        "            self._ui_bump(5)\n",
        "\n",
        "            # --- Inference on processed image ---\n",
        "            preds_proc = {}\n",
        "            for nick, clf in [\n",
        "                (\"resnet18\", CLS_RESNET18),\n",
        "                (\"mobilenet_v3_large\", CLS_MNV3),\n",
        "                (\"efficientnet_b0\", CLS_EFFB0),\n",
        "                (\"convnext_tiny\", CLS_CONVNEXT),\n",
        "                (\"densenet121\", CLS_DENSENET),\n",
        "            ]:\n",
        "                self._ui_progress(f\"Processed image â†’ {nick}â€¦\")\n",
        "                lvl, _ = clf.predict_level(pil_proc)\n",
        "                preds_proc[nick] = lvl\n",
        "                self._ui_bump(5)\n",
        "\n",
        "            final_proc = majority_vote(preds_proc)\n",
        "\n",
        "            # --- Inference on CLAHE-only image ---\n",
        "            preds_clahe = {}\n",
        "            for nick, clf in [\n",
        "                (\"resnet18\", CLS_RESNET18),\n",
        "                (\"mobilenet_v3_large\", CLS_MNV3),\n",
        "                (\"efficientnet_b0\", CLS_EFFB0),\n",
        "                (\"convnext_tiny\", CLS_CONVNEXT),\n",
        "                (\"densenet121\", CLS_DENSENET),\n",
        "            ]:\n",
        "                self._ui_progress(f\"CLAHE-only image â†’ {nick}â€¦\")\n",
        "                lvl, _ = clf.predict_level(pil_clahe)\n",
        "                preds_clahe[nick] = lvl\n",
        "                self._ui_bump(5)\n",
        "\n",
        "            final_clahe = majority_vote(preds_clahe)\n",
        "\n",
        "            # --- XGBoost once (tabular doesnâ€™t depend on image) ---\n",
        "            self._ui_progress(\"Running XGBoostâ€¦\")\n",
        "            y_pred, y_label, p_yes = predict_xgb(form)\n",
        "            self._ui_bump(10)\n",
        "\n",
        "            # --- Compose output text (both runs) ---\n",
        "            lines = []\n",
        "            lines.append(\"â€” Image Models on PROCESSED (CLAHE + segmentation + 1% crop) â€”\")\n",
        "            for k, v in preds_proc.items():\n",
        "                lines.append(f\"  â€¢ {k}: Level {v}\")\n",
        "            lines.append(f\"  â†’ Final Norwood (majority): Level {final_proc}\")\n",
        "\n",
        "            lines.append(\"\\nâ€” Image Models on CLAHE-ONLY (full frame) â€”\")\n",
        "            for k, v in preds_clahe.items():\n",
        "                lines.append(f\"  â€¢ {k}: Level {v}\")\n",
        "            lines.append(f\"  â†’ Final Norwood (majority): Level {final_clahe}\")\n",
        "\n",
        "            if p_yes == p_yes:\n",
        "                lines.append(f\"\\nHair-Fall (XGBoost): {y_label}  (p_yes={p_yes:.2f})\")\n",
        "            else:\n",
        "                lines.append(f\"\\nHair-Fall (XGBoost): {y_label}\")\n",
        "\n",
        "            # Keep existing shape for downstream (choose PROCESSED as the canonical result)\n",
        "            self._last_results = {\n",
        "                \"norwood_by_model\": preds_proc,\n",
        "                \"norwood_final\": final_proc,\n",
        "                \"hairfall_yes\": bool(y_pred == 1),\n",
        "                \"hairfall_label\": y_label,\n",
        "                \"hairfall_prob\": p_yes,\n",
        "\n",
        "                # extra fields (optional; for your own inspection)\n",
        "                \"norwood_by_model_clahe\": preds_clahe,\n",
        "                \"norwood_final_clahe\": final_clahe,\n",
        "            }\n",
        "\n",
        "            self._ui_done(\"\\n\".join(lines))\n",
        "\n",
        "        except Exception as e:\n",
        "            self._ui_done(f\"[ERROR]\\n{e}\")\n",
        "\n",
        "    # UI-thread helpers\n",
        "    def _ui_progress(self, msg):\n",
        "        self.after(0, lambda: self.status.config(text=msg))\n",
        "\n",
        "    def _ui_bump(self, delta):\n",
        "        def _b():\n",
        "            v = min(100, self.pbar[\"value\"] + delta)\n",
        "            self.pbar[\"value\"] = v\n",
        "        self.after(0, _b)\n",
        "\n",
        "    def _ui_done(self, text):\n",
        "        def _d():\n",
        "            self.pbar[\"value\"] = 100\n",
        "            self.status.config(text=\"Done.\")\n",
        "            self.txt.delete(\"1.0\", \"end\")\n",
        "            self.txt.insert(\"end\", text)\n",
        "            # Update visibility now that results may exist\n",
        "            self._sync_view_btn_visibility()\n",
        "\n",
        "        self.after(0, _d)\n",
        "\n",
        "    def _sync_view_btn_visibility(self):\n",
        "        \"\"\"Show the View Recommendations button only if results exist.\"\"\"\n",
        "        has_local = bool(self._last_results)\n",
        "        has_shared = False\n",
        "        try:\n",
        "            has_shared = bool(getattr(self.controller, \"shared\", {}).get(\"results\"))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        should_show = has_local or has_shared\n",
        "\n",
        "        # If should show and it's not currently packed â†’ pack it\n",
        "        if should_show and not getattr(self.view_btn, \"_is_packed\", False):\n",
        "            self.view_btn.pack(side=\"right\", padx=(0, 8))\n",
        "            self.view_btn._is_packed = True\n",
        "\n",
        "        # If should hide and it's currently packed â†’ forget it\n",
        "        if not should_show and getattr(self.view_btn, \"_is_packed\", False):\n",
        "            self.view_btn.pack_forget()\n",
        "            self.view_btn._is_packed = False\n",
        "\n",
        "    def on_choose_image(self):\n",
        "        \"\"\"Open a file dialog, store the path, and refresh the preview.\"\"\"\n",
        "        fp = filedialog.askopenfilename(\n",
        "            parent=self,  # tie dialog to this window\n",
        "            title=\"Select image\",\n",
        "            filetypes=[\n",
        "                (\"Image files\", (\"*.png\", \"*.jpg\", \"*.jpeg\", \"*.bmp\", \"*.webp\",\n",
        "                                 \"*.PNG\", \"*.JPG\", \"*.JPEG\", \"*.BMP\", \"*.WEBP\")),\n",
        "                (\"All files\", \"*\"),\n",
        "            ],\n",
        "        )\n",
        "        if not fp:\n",
        "            return\n",
        "        # Save to shared state so other screens can use it\n",
        "        if hasattr(self.controller, \"shared\"):\n",
        "            self.controller.shared[\"image_path\"] = fp\n",
        "        # Update path label + preview\n",
        "        self.path_var.set(fp)\n",
        "        self._refresh_preview()\n",
        "\n",
        "    def on_view_results(self):\n",
        "        \"\"\"Navigate to the Results screen with the latest predictions (local or shared).\"\"\"\n",
        "        results = self._last_results\n",
        "        if not results:\n",
        "            try:\n",
        "                results = getattr(self.controller, \"shared\", {}).get(\"results\")\n",
        "            except Exception:\n",
        "                results = None\n",
        "\n",
        "        if not results:\n",
        "            from tkinter import messagebox\n",
        "            messagebox.showinfo(\"No results\", \"Run predictions first.\")\n",
        "            return\n",
        "\n",
        "        if hasattr(self.controller, \"shared\"):\n",
        "            self.controller.shared[\"results\"] = results\n",
        "\n",
        "        try:\n",
        "            res = self.controller.screens[\"results\"]\n",
        "            res.set_results(results)\n",
        "            self.controller.show(\"results\")\n",
        "        except Exception:\n",
        "            from tkinter import messagebox\n",
        "            messagebox.showinfo(\"Results\", \"Results screen not available in controller.\")\n",
        "\n",
        "    def _collect_form(self) -> dict:\n",
        "        # Normalize age (blank/invalid -> 0)\n",
        "        try:\n",
        "            age_val = float(self.var_age.get().strip())\n",
        "        except Exception:\n",
        "            age_val = 0.0\n",
        "\n",
        "        return {\n",
        "            \"stay_up_late\":   self.var_stay_up_late.get(),\n",
        "            \"water_reason\":   self.var_water_reason.get(),\n",
        "            \"family_history\": self.var_family_history.get(),\n",
        "            \"use_chemicals\":  self.var_use_chemicals.get(),\n",
        "            \"stress\":         self.var_stress.get(),\n",
        "            \"chronic_illness\": self.var_chronic.get(),\n",
        "            \"age\":            age_val,\n",
        "        }\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9XlqLJ7mpz4"
      },
      "source": [
        "processing_screen.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZE8oDXVQmrdA"
      },
      "outputs": [],
      "source": [
        "# screens/processing_screen.py\n",
        "import os\n",
        "import threading\n",
        "import traceback\n",
        "import tkinter as tk\n",
        "from tkinter import ttk\n",
        "\n",
        "try:\n",
        "    from PIL import Image, ImageTk\n",
        "except Exception:  # keep UI alive even if PIL missing\n",
        "    Image = None\n",
        "    ImageTk = None\n",
        "\n",
        "\n",
        "class ProcessingScreen(ttk.Frame):\n",
        "    \"\"\"\n",
        "    A waiting/processing view.\n",
        "    - Call `configure_job(predict_fn, args, kwargs, on_done)` before showing.\n",
        "      * predict_fn: a callable that will run on a background thread.\n",
        "      * args/kwargs: passed to predict_fn\n",
        "      * on_done(results_dict): called on the Tk thread when predict_fn returns.\n",
        "    - Call `show_uploaded_image(path)` to preview the userâ€™s photo.\n",
        "    - When this frame is raised, call `start()` to begin the job (starts spinner).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, parent, controller=None):\n",
        "        super().__init__(parent)\n",
        "        self.controller = controller\n",
        "\n",
        "        # --- Layout ---\n",
        "        self.columnconfigure(0, weight=1)\n",
        "\n",
        "        self.title_lbl = ttk.Label(\n",
        "            self, text=\"TESTING...\", anchor=\"w\",\n",
        "            font=(\"Arial\", 38, \"bold\")\n",
        "        )\n",
        "        self.title_lbl.grid(row=0, column=0, sticky=\"w\", padx=40, pady=(30, 0))\n",
        "\n",
        "        self.subtitle_lbl = ttk.Label(\n",
        "            self,\n",
        "            text=(\"PLEASE WAIT A MOMENT WHILE OUR DEEP LEARNING\\n\"\n",
        "                  \"AND MACHINE LEARNING MODELS PREDICT YOUR\\n\"\n",
        "                  \"NORWOOD SCALE STAGE, AND WHETHER THERE IS A\\n\"\n",
        "                  \"PROGRESSING HAIR LOSS\"),\n",
        "            anchor=\"w\",\n",
        "            font=(\"Arial\", 20, \"bold\")\n",
        "        )\n",
        "        self.subtitle_lbl.grid(row=1, column=0, sticky=\"w\", padx=40, pady=(6, 16))\n",
        "\n",
        "        # Preview area\n",
        "        self.preview_wrap = ttk.Frame(self)\n",
        "        self.preview_wrap.grid(row=2, column=0, sticky=\"w\", padx=40, pady=(8, 0))\n",
        "\n",
        "        self.preview_caption = ttk.Label(\n",
        "            self.preview_wrap, text=\"Your uploaded image:\",\n",
        "            font=(\"Arial\", 18)\n",
        "        )\n",
        "        self.preview_caption.grid(row=0, column=0, sticky=\"w\", pady=(0, 10))\n",
        "\n",
        "        self.preview_lbl = ttk.Label(self.preview_wrap)\n",
        "        self.preview_lbl.grid(row=1, column=0, sticky=\"w\")\n",
        "\n",
        "        # Progress area\n",
        "        self.progress_wrap = ttk.Frame(self)\n",
        "        self.progress_wrap.grid(row=3, column=0, sticky=\"we\", padx=40, pady=(30, 20))\n",
        "        self.progress_wrap.columnconfigure(0, weight=1)\n",
        "\n",
        "        self.progress = ttk.Progressbar(self.progress_wrap, mode=\"indeterminate\")\n",
        "        self.progress.grid(row=0, column=0, sticky=\"we\")\n",
        "\n",
        "        self.status_lbl = ttk.Label(self.progress_wrap, text=\"Loading modelsâ€¦\", font=(\"Arial\", 12))\n",
        "        self.status_lbl.grid(row=1, column=0, sticky=\"w\", pady=(8, 0))\n",
        "\n",
        "        # Error box (hidden unless needed)\n",
        "        self.err_box = tk.Text(self, height=8, wrap=\"word\", foreground=\"red\")\n",
        "        self.err_box.grid(row=4, column=0, sticky=\"nsew\", padx=40, pady=(10, 20))\n",
        "        self.rowconfigure(4, weight=1)\n",
        "        self.err_box.grid_remove()\n",
        "\n",
        "        # Internals\n",
        "        self._tk_img = None\n",
        "        self._predict_fn = None\n",
        "        self._job_args = ()\n",
        "        self._job_kwargs = {}\n",
        "        self._on_done = None\n",
        "        self._thread = None\n",
        "        self._anim_job = None\n",
        "        self._anim_dots = 0\n",
        "\n",
        "    # ---------------- Public API ----------------\n",
        "\n",
        "    def configure_job(self, predict_fn, args=(), kwargs=None, on_done=None):\n",
        "        \"\"\"Register the heavy job to run in a background thread.\"\"\"\n",
        "        self._predict_fn = predict_fn\n",
        "        self._job_args = args or ()\n",
        "        self._job_kwargs = kwargs or {}\n",
        "        self._on_done = on_done\n",
        "\n",
        "    def show_uploaded_image(self, image_path: str, max_size=(420, 420)):\n",
        "        \"\"\"Preview the user image (PIL) on the left.\"\"\"\n",
        "        if not Image or not ImageTk:\n",
        "            self.preview_lbl.configure(text=os.path.basename(image_path))\n",
        "            return\n",
        "        try:\n",
        "            img = Image.open(image_path).convert(\"RGB\")\n",
        "            w, h = img.size\n",
        "            scale = min(max_size[0] / w, max_size[1] / h, 1.0)\n",
        "            if scale < 1.0:\n",
        "                img = img.resize((int(w * scale), int(h * scale)))\n",
        "            self._tk_img = ImageTk.PhotoImage(img)\n",
        "            self.preview_lbl.configure(image=self._tk_img)\n",
        "        except Exception:\n",
        "            self.preview_lbl.configure(text=\"(couldnâ€™t preview image)\")\n",
        "\n",
        "    def start(self):\n",
        "        \"\"\"Begin spinner + launch background work.\"\"\"\n",
        "        self._start_spinner()\n",
        "        self._start_job_thread()\n",
        "\n",
        "    # ---------------- Internals ----------------\n",
        "\n",
        "    def _start_spinner(self):\n",
        "        self.progress.start(12)  # speed\n",
        "        self._anim_tick()\n",
        "\n",
        "    def _stop_spinner(self):\n",
        "        try:\n",
        "            self.progress.stop()\n",
        "        except Exception:\n",
        "            pass\n",
        "        if self._anim_job is not None:\n",
        "            self.after_cancel(self._anim_job)\n",
        "            self._anim_job = None\n",
        "\n",
        "    def _anim_tick(self):\n",
        "        # simple 'Loadingâ€¦', 'Loadingâ€¦..' loop\n",
        "        base = \"Processing inputâ€¦\"\n",
        "        self._anim_dots = (self._anim_dots + 1) % 6\n",
        "        self.status_lbl.configure(text=base + \".\" * self._anim_dots)\n",
        "        self._anim_job = self.after(400, self._anim_tick)\n",
        "\n",
        "    def _start_job_thread(self):\n",
        "        if self._predict_fn is None:\n",
        "            self._show_error(\"No job configured for ProcessingScreen.\")\n",
        "            return\n",
        "\n",
        "        def runner():\n",
        "            try:\n",
        "                results = self._predict_fn(*self._job_args, **self._job_kwargs)\n",
        "            except Exception as e:\n",
        "                tb = traceback.format_exc()\n",
        "                self.after(0, lambda: self._show_error(f\"{e}\\n\\n{tb}\"))\n",
        "                return\n",
        "            self.after(0, lambda: self._finish(results))\n",
        "\n",
        "        self._thread = threading.Thread(target=runner, daemon=True)\n",
        "        self._thread.start()\n",
        "\n",
        "    def _finish(self, results):\n",
        "        self._stop_spinner()\n",
        "        if callable(self._on_done):\n",
        "            try:\n",
        "                self._on_done(results)\n",
        "            except Exception as e:\n",
        "                self._show_error(f\"on_done callback failed: {e}\")\n",
        "\n",
        "    def _show_error(self, text):\n",
        "        self._stop_spinner()\n",
        "        self.err_box.grid()  # show\n",
        "        self.err_box.delete(\"1.0\", \"end\")\n",
        "        self.err_box.insert(\"end\", str(text))\n",
        "        self.status_lbl.configure(text=\"An error occurred.\")\n",
        "\n",
        "    def set_inputs(self, image_path: str, form: dict):\n",
        "        \"\"\"Compatibility wrapper used by main.py.\"\"\"\n",
        "        if image_path:\n",
        "            self.show_uploaded_image(image_path)\n",
        "        # stash for convenience if someone wants to fetch later\n",
        "        self._job_kwargs.setdefault(\"inputs\", {\"image_path\": image_path, \"form\": form})\n",
        "\n",
        "    def start_processing(self, on_done=None):\n",
        "        \"\"\"Compatibility wrapper used by main.py.\n",
        "\n",
        "        Expects the controller to expose run_full_inference(image_path, form) -> dict.\n",
        "        Falls back to any predict_fn already configured via configure_job().\n",
        "        \"\"\"\n",
        "        if callable(on_done):\n",
        "            self._on_done = on_done\n",
        "\n",
        "        # If no predict_fn configured yet, but controller has a runner, wire it up.\n",
        "        if self._predict_fn is None and hasattr(self.controller, \"run_full_inference\"):\n",
        "            inputs = self._job_kwargs.get(\"inputs\", {})\n",
        "            img = inputs.get(\"image_path\")\n",
        "            form = inputs.get(\"form\", {})\n",
        "            self.configure_job(self.controller.run_full_inference, args=(img, form))\n",
        "\n",
        "        self.start()\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Clear transient UI.\"\"\"\n",
        "        try:\n",
        "            self.progress.stop()\n",
        "        except Exception:\n",
        "            pass\n",
        "        self.status_lbl.config(text=\"Loading modelsâ€¦\")\n",
        "        self.err_box.grid_remove()\n",
        "        self.preview_lbl.configure(image=\"\", text=\"\")\n",
        "        self._tk_img = None\n",
        "        self._predict_fn = None\n",
        "        self._job_args = ()\n",
        "        self._job_kwargs = {}\n",
        "        self._on_done = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzdqOcVomvhu"
      },
      "source": [
        "results_screen.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "totqQIiUmyO0"
      },
      "outputs": [],
      "source": [
        "# screens/results_screen.py\n",
        "import os\n",
        "from collections import Counter\n",
        "import tkinter as tk\n",
        "from tkinter import ttk\n",
        "import webbrowser\n",
        "import io, re, requests\n",
        "import threading\n",
        "\n",
        "try:\n",
        "    from PIL import Image, ImageTk\n",
        "except Exception:\n",
        "    Image = None\n",
        "    ImageTk = None\n",
        "\n",
        "# ---- simple, editable recommendations ----\n",
        "NORWOOD_RECS = {\n",
        "    1: [\"Maintain gentle care routine\", \"Baseline photos every 3â€“6 months\"],\n",
        "    2: [\"Consider topical minoxidil\", \"Focus on sleep & nutrition\"],\n",
        "    3: [\"Discuss finasteride/minoxidil with a clinician\", \"Dermarolling only if supervised\"],\n",
        "    4: [\"Combo therapy (finasteride + minoxidil) may help\", \"Discuss LLLT devices evidence\"],\n",
        "    5: [\"Consider procedural options (e.g., PRP)\", \"Manage expectations; camouflage options\"],\n",
        "    6: [\"Surgical candidacy evaluation\", \"Plan donor management & maintenance therapy\"],\n",
        "    7: [\"SMP or hair systems; sun protection\", \"Medical therapy only for stabilization\"],\n",
        "}\n",
        "\n",
        "HAIRFALL_RECS = {\n",
        "    False: [\"Looks stable right now\", \"Keep healthy routine & periodic photos\"],\n",
        "    True:  [\"Progression likely â€” seek medical advice\", \"Early intervention improves outcomes\"],\n",
        "}\n",
        "\n",
        "# Preventative methods (plain strings; weâ€™ll add bullets in set_results)\n",
        "PREVENTIVE_METHODS = [\n",
        "    \"Minoxidil\",\n",
        "    \"Low-Level Laser Therapy (LLLT)\",\n",
        "    \"DHT Blockers (Finasteride or Dutasteride)\",\n",
        "    \"Ketoconazole 2% Shampoo\",\n",
        "    \"Tretinoin\",\n",
        "    \"Dermarolling (with supervision)\",\n",
        "    \"Platelet-Rich Plasma (PRP) treatments\",\n",
        "    \"Hair-focused supplements (if deficient)\",\n",
        "    \"Adequate protein intake\",\n",
        "    \"Avoid smoking\",\n",
        "    \"Limit alcohol consumption\",\n",
        "    \"Improve sleep quality\",\n",
        "    \"Stress management\",\n",
        "    \"Account for genetic predisposition (family history monitoring)\",\n",
        "]\n",
        "\n",
        "# Norwood figures hosted on Google Drive (share links)\n",
        "NORWOOD_IMAGES = {\n",
        "    1: \"https://drive.google.com/file/d/1whqwEo11ZEiNkAebh8NfrM-Kx30touex/view?usp=sharing\",\n",
        "    2: \"https://drive.google.com/file/d/1whqwEo11ZEiNkAebh8NfrM-Kx30touex/view?usp=sharing\",\n",
        "    3: \"https://drive.google.com/file/d/16OV3-81-VHD42DTWGl9co0TRq4YGXeM0/view?usp=sharing\",\n",
        "    4: \"https://drive.google.com/file/d/1GIF1zqoUy6ybR6Vs7rakYFQM7RNlLWxA/view?usp=drive_link\",\n",
        "    5: \"https://drive.google.com/file/d/1GIF1zqoUy6ybR6Vs7rakYFQM7RNlLWxA/view?usp=drive_link\",\n",
        "    6: \"https://drive.google.com/file/d/1CDsOJrkvpSx0me4nHSl6jb6eycJGQg_f/view?usp=drive_link\",\n",
        "    7: \"https://drive.google.com/file/d/18Bg2V7Ops_rx20tPSIfG8447o7yRZUgk/view?usp=drive_link\",\n",
        "}\n",
        "\n",
        "# Short, plain-English descriptions for grouped display levels\n",
        "STAGE_DESCRIPTIONS = {\n",
        "    \"1â€“2\": \"Little to no recession at the temples; hairline mostly intact.\",\n",
        "    \"3\":   \"Noticeable recession at the temples forming an M-shape; crown usually preserved.\",\n",
        "    \"4â€“5\": \"Front and crown thinning; the bridge between them narrows or breaks.\",\n",
        "    \"6\":   \"Front and crown areas have merged; only sparse hair remains across the top.\",\n",
        "    \"7\":   \"Only a narrow horseshoe fringe remains at the sides and back.\",\n",
        "}\n",
        "\n",
        "\n",
        "class ResultsScreen(ttk.Frame):\n",
        "    \"\"\"\n",
        "    Call set_results(results_dict) to populate the screen, then raise this frame.\n",
        "    results_dict may contain:\n",
        "      - norwood_by_model: dict{name: level_int}\n",
        "      - norwood_final: int (optional; if missing we majority-vote here)\n",
        "      - hairfall_yes: bool (preferred)\n",
        "      - hairfall_label: str (optional)\n",
        "      - hairfall_prob: float (optional)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, parent, controller=None):\n",
        "        super().__init__(parent)\n",
        "        self.controller = controller\n",
        "        self._stage_img_tk = None\n",
        "\n",
        "        # keep references to dynamically created labels so we can rewrap on resize\n",
        "        self._stage_rec_labels = []\n",
        "        self._hf_rec_labels = []\n",
        "\n",
        "        self._build_style()\n",
        "        self._build_ui()\n",
        "\n",
        "        # Async image loading\n",
        "        self._img_cache = {}      # level -> PIL.Image\n",
        "        self._img_req_id = 0      # monotonic to ignore stale worker responses\n",
        "\n",
        "    # ---------- public API ----------\n",
        "    def set_results(self, results: dict):\n",
        "        \"\"\"Update all widgets using a results dict produced by the processing step.\"\"\"\n",
        "        nbm = results.get(\"norwood_by_model\", {}) or {}\n",
        "        final_level = results.get(\"norwood_final\")\n",
        "        if final_level is None and nbm:\n",
        "            final_level = self._majority_vote(list(nbm.values()))\n",
        "        if final_level is None:\n",
        "            final_level = 3  # safe default\n",
        "\n",
        "        hairfall_yes = results.get(\"hairfall_yes\")\n",
        "        if hairfall_yes is None:\n",
        "            label = (results.get(\"hairfall_label\") or \"\").lower()\n",
        "            hairfall_yes = \"yes\" in label if label else None\n",
        "\n",
        "        prob = results.get(\"hairfall_prob\")\n",
        "        prob_txt = f\" (p={prob:.2f})\" if isinstance(prob, (int, float)) else \"\"\n",
        "\n",
        "        # Title + grouped subtitle\n",
        "        hl_text = \"Progressing hair loss\" if hairfall_yes else \"No hair loss detected\" if hairfall_yes is not None else \"â€”\"\n",
        "        self.title_lbl.config(text=\"THE RESULTS ARE READY!\")\n",
        "        range_label, circle_text = self._group_label(final_level)\n",
        "        self.subtitle_lbl.config(text=f\"Final Norwood: {range_label} â€” {hl_text}{prob_txt}\")\n",
        "\n",
        "        # Circle text\n",
        "        self.circle_label_text.config(text=\"Levels\" if \"â€“\" in circle_text else \"Level\")\n",
        "        self.circle_number_lbl.config(text=circle_text)\n",
        "\n",
        "        # Description under image\n",
        "        self.stage_img_desc_lbl.config(text=self._stage_description(final_level))\n",
        "\n",
        "        # Stage image (center)\n",
        "        self._set_stage_image(final_level)\n",
        "\n",
        "        # -------- Recommendations (right box) --------\n",
        "        stage_recs = self._get_stage_recs(final_level)\n",
        "\n",
        "        # Extra suggestion for stages 3â€“5\n",
        "        if 3 <= final_level <= 5:\n",
        "            stage_recs.insert(0, \"Consider hair transplant to achieve a full hairline\")\n",
        "\n",
        "        # Preventative measures for stages 1â€“5 (spaced & indented bullets)\n",
        "        if 1 <= final_level <= 5:\n",
        "            stage_recs.append(\"\")  # blank line for separation\n",
        "            stage_recs.append(\"Preventative measures to integrate:\")\n",
        "            stage_recs.extend([f\"   â€¢ {m}\" for m in PREVENTIVE_METHODS])\n",
        "\n",
        "        # -------- Hair-fall recommendations (right box) --------\n",
        "        # IMPORTANT: don't coerce None â†’ False\n",
        "        hf_recs = list(HAIRFALL_RECS.get(hairfall_yes, []))\n",
        "\n",
        "        # Add monitoring + integration only if Hair Fall = Yes and stage â‰¤5\n",
        "        if hairfall_yes is True and 1 <= final_level <= 5:\n",
        "            hf_recs.insert(0, \"Integrate preventative routine (see preventative methods list)\")\n",
        "            hf_recs.insert(0, \"Monitor shedding (monthly photos / part-line density checks)\")\n",
        "\n",
        "        # If no hair fall AND level â‰¥6, remove any monitoring-style suggestion\n",
        "        if hairfall_yes is False and final_level >= 6:\n",
        "            hf_recs = [rec for rec in hf_recs if \"Monitor\" not in rec]\n",
        "\n",
        "        # Populate UI lists\n",
        "        self._render_recs(self.stage_recs_container, self._stage_rec_labels, stage_recs)\n",
        "        self._render_recs(self.hf_recs_container, self._hf_rec_labels, hf_recs)\n",
        "\n",
        "        # Graft + price estimate (left box)\n",
        "        est = self._estimate_grafts_and_costs(final_level)\n",
        "        self._render_costs(est)\n",
        "\n",
        "        # Footer\n",
        "        model_keys = sorted(nbm.keys()) if nbm else []\n",
        "        model_count = len(model_keys)\n",
        "        models_str = \", \".join(model_keys) if model_keys else \"ensemble\"\n",
        "        ensemble_note = f\" ({model_count}-model ensemble)\" if model_count else \"\"\n",
        "        self.footer_lbl.config(\n",
        "            text=(\n",
        "                f\"Predicted with {models_str} image models{ensemble_note} and an XGBoost tabular model.\\n\"\n",
        "                \"These recommendations are for educational purposes only and are supported by scientific research including publications such as the Journal of the American\\n\"\n",
        "                \"Academy of Dermatology (JAAD). They are not a substitute for professional medical advice, diagnosis, or treatment. Always consult a qualified dermatologist\\n\"\n",
        "                \"or healthcare provider before starting any new treatment or routine. We are not responsible for any outcomes resulting from the use of this information.\\n\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # ---------- styles ----------\n",
        "    def _build_style(self):\n",
        "        style = ttk.Style(self)\n",
        "        try:\n",
        "            style.theme_use(style.theme_use())\n",
        "        except Exception:\n",
        "            try:\n",
        "                style.theme_use(\"clam\")\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        # Bold titles on LabelFrames\n",
        "        style.configure(\"Section.TLabelframe\", padding=8)\n",
        "        style.configure(\"Section.TLabelframe.Label\", font=(\"Arial\", 14, \"bold\"))\n",
        "\n",
        "        # General text styles\n",
        "        style.configure(\"SectionHeader.TLabel\", font=(\"Arial\", 15, \"bold\"))\n",
        "        style.configure(\"Body.TLabel\", font=(\"Arial\", 13))\n",
        "        style.configure(\"Emph.TLabel\", font=(\"Arial\", 12, \"bold\"))\n",
        "\n",
        "    # ---------- internals ----------\n",
        "    def _build_ui(self):\n",
        "        self.columnconfigure(0, weight=1)\n",
        "        # main grows; footer stays compact\n",
        "        self.rowconfigure(2, weight=1)\n",
        "        self.rowconfigure(3, weight=0)\n",
        "\n",
        "        # Header\n",
        "        self.title_lbl = ttk.Label(self, text=\"THE RESULTS ARE READY!\", font=(\"Arial\", 36, \"bold\"))\n",
        "        self.title_lbl.grid(row=0, column=0, sticky=\"w\", padx=40, pady=(30, 0))\n",
        "\n",
        "        self.subtitle_lbl = ttk.Label(self, text=\"\", font=(\"Arial\", 18))\n",
        "        self.subtitle_lbl.grid(row=1, column=0, sticky=\"w\", padx=40, pady=(6, 6))\n",
        "\n",
        "        # Separator under header\n",
        "        #ttk.Separator(self, orient=\"horizontal\").grid(row=1, column=0, sticky=\"we\", padx=40, pady=(0, 8))\n",
        "\n",
        "        # Main area with vertical separators: 5 columns (content | sep | content | sep | content)\n",
        "        main = ttk.Frame(self)\n",
        "        main.grid(row=2, column=0, sticky=\"nsew\", padx=40, pady=10)\n",
        "        for c in (0, 2, 4):\n",
        "            main.columnconfigure(c, weight=1)\n",
        "        for c in (1, 3):\n",
        "            main.columnconfigure(c, weight=0)\n",
        "\n",
        "        # ---------- LEFT COLUMN: circle + costs ----------\n",
        "        left = ttk.Frame(main)\n",
        "        left.grid(row=0, column=0, sticky=\"nsew\", padx=(0, 20))\n",
        "        left.columnconfigure(0, weight=1)\n",
        "\n",
        "        # Circle (top)\n",
        "        circle_frame = ttk.Frame(left)\n",
        "        circle_frame.grid(row=0, column=0, sticky=\"n\", pady=(0, 10))\n",
        "\n",
        "        bg_color = self._get_bg_color_safe(circle_frame)\n",
        "        circle_canvas = tk.Canvas(circle_frame, width=260, height=260, highlightthickness=0, bg=bg_color, bd=0)\n",
        "        circle_canvas.pack()\n",
        "        circle_canvas.create_oval(5, 5, 255, 255, fill=\"#f5f5f5\", outline=\"#b5b5b5\", width=3)\n",
        "\n",
        "        self.circle_label_text = tk.Label(circle_frame, text=\"Level\", font=(\"Arial\", 20), bg=bg_color, fg=\"#555\")\n",
        "        self.circle_label_text.place(relx=0.5, rely=0.40, anchor=\"center\")\n",
        "\n",
        "        self.circle_number_lbl = tk.Label(circle_frame, text=\"\", font=(\"Arial\", 56, \"bold\"), bg=bg_color, fg=\"#333\")\n",
        "        self.circle_number_lbl.place(relx=0.5, rely=0.60, anchor=\"center\")\n",
        "\n",
        "        # Costs box (bold section title via style)\n",
        "        costs_box = ttk.LabelFrame(left, text=\"Estimated grafts & price (Israel)\", style=\"Section.TLabelframe\")\n",
        "        costs_box.grid(row=1, column=0, sticky=\"nwe\")\n",
        "        costs_box.columnconfigure(0, weight=1)\n",
        "        self.costs_container = ttk.Frame(costs_box)\n",
        "        self.costs_container.grid(row=0, column=0, sticky=\"nwe\", padx=8, pady=4)\n",
        "\n",
        "        # Vertical separator between left and mid\n",
        "        ttk.Separator(main, orient=\"vertical\").grid(row=0, column=1, sticky=\"ns\", padx=10, pady=4)\n",
        "\n",
        "        # ---------- MIDDLE COLUMN: stage figure in stable box ----------\n",
        "        mid = ttk.Frame(main)\n",
        "        mid.grid(row=0, column=2, sticky=\"n\", padx=20)\n",
        "        self.stage_wrap = ttk.Frame(mid, width=320, height=240)\n",
        "        self.stage_wrap.pack()\n",
        "        self.stage_wrap.pack_propagate(False)\n",
        "        self.stage_img_lbl = ttk.Label(self.stage_wrap, anchor=\"center\")\n",
        "        self.stage_img_lbl.pack(expand=True, fill=\"both\")\n",
        "\n",
        "        # Short description under the stage image\n",
        "        self.stage_img_desc_lbl = ttk.Label(\n",
        "            mid, text=\"\", style=\"Body.TLabel\", justify=\"center\", wraplength=320\n",
        "        )\n",
        "        self.stage_img_desc_lbl.pack(pady=(8, 0))\n",
        "        self.stage_wrap.bind(\"<Configure>\", lambda e: self.stage_img_desc_lbl.configure(wraplength=e.width))\n",
        "\n",
        "        # Vertical separator between mid and right\n",
        "        ttk.Separator(main, orient=\"vertical\").grid(row=0, column=3, sticky=\"ns\", padx=10, pady=4)\n",
        "\n",
        "        # ---------- RIGHT COLUMN: recommendations ----------\n",
        "        right = ttk.Frame(main)\n",
        "        right.grid(row=0, column=4, sticky=\"nsew\", padx=(20, 0))\n",
        "        right.columnconfigure(0, weight=1)\n",
        "\n",
        "        stage_box = ttk.LabelFrame(right, text=\"Recommendations (Norwood stage)\", style=\"Section.TLabelframe\")\n",
        "        stage_box.grid(row=0, column=0, sticky=\"nsew\", pady=(0, 10))\n",
        "        stage_box.columnconfigure(0, weight=1)\n",
        "        self.stage_recs_container = ttk.Frame(stage_box)\n",
        "        self.stage_recs_container.grid(row=0, column=0, sticky=\"nwe\", padx=8, pady=4)\n",
        "        self.stage_recs_container.bind(\"<Configure>\", lambda e: self._rewrap_labels(self._stage_rec_labels, e.width))\n",
        "\n",
        "        hf_box = ttk.LabelFrame(right, text=\"Recommendations (Hair loss progression)\", style=\"Section.TLabelframe\")\n",
        "        hf_box.grid(row=1, column=0, sticky=\"nsew\")\n",
        "        hf_box.columnconfigure(0, weight=1)\n",
        "        self.hf_recs_container = ttk.Frame(hf_box)\n",
        "        self.hf_recs_container.grid(row=0, column=0, sticky=\"nwe\", padx=8, pady=4)\n",
        "        self.hf_recs_container.bind(\"<Configure>\", lambda e: self._rewrap_labels(self._hf_rec_labels, e.width))\n",
        "\n",
        "        # Footer\n",
        "        self.footer_lbl = ttk.Label(self, text=\"\", style=\"Body.TLabel\", justify=\"left\")\n",
        "        self.footer_lbl.grid(row=3, column=0, sticky=\"we\", padx=40, pady=(8, 6))\n",
        "        self.bind(\"<Configure>\", self._on_resize)\n",
        "\n",
        "        # Bottom buttons (navigation on the left, links on the right)\n",
        "        btns = ttk.Frame(self)\n",
        "        btns.grid(row=4, column=0, sticky=\"we\", padx=40, pady=(8, 30))\n",
        "        for i in range(5):\n",
        "            btns.columnconfigure(i, weight=1)\n",
        "\n",
        "        self.btn_back = ttk.Button(btns, text=\"â€¹ BACK\", command=self.on_back)\n",
        "        self.btn_start_over = ttk.Button(btns, text=\"START OVER\", command=self.on_start_over)\n",
        "        self.btn_back.grid(row=0, column=0, sticky=\"we\", padx=(0, 8))\n",
        "        self.btn_start_over.grid(row=0, column=1, sticky=\"we\", padx=(8, 16))\n",
        "\n",
        "        self.btn_about = ttk.Button(btns, text=\"LEARN MORE ABOUT US\", command=self.on_learn_more)\n",
        "        self.btn_models = ttk.Button(btns, text=\"BROWSE OUR MODELS ON HUGGINGFACE\", command=self.on_browse_models)\n",
        "        self.btn_prices = ttk.Button(btns, text=\"COMPARE CLINIC PRICES >\", command=self.on_compare_prices)\n",
        "        self.btn_about.grid(row=0, column=2, sticky=\"we\", padx=(0, 8))\n",
        "        self.btn_models.grid(row=0, column=3, sticky=\"we\", padx=8)\n",
        "        self.btn_prices.grid(row=0, column=4, sticky=\"we\", padx=(8, 0))\n",
        "\n",
        "    def _on_resize(self, event=None):\n",
        "        # account for the 40px left/right padding around the grid cell\n",
        "        try:\n",
        "            wrap = max(self.winfo_width() - 80, 320)\n",
        "            self.footer_lbl.configure(wraplength=wrap)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    def _render_recs(self, container: ttk.Frame, label_list: list, items):\n",
        "        \"\"\"Destroy old labels and render a vertical stack of wrapped labels (auto-expands).\"\"\"\n",
        "        for child in container.winfo_children():\n",
        "            child.destroy()\n",
        "        label_list.clear()\n",
        "\n",
        "        width = max(container.winfo_width(), 300)\n",
        "        wrap = max(width - 12, 150)  # padding margin\n",
        "\n",
        "        for i, text in enumerate(items):\n",
        "            # blank lines â†’ small spacer\n",
        "            if text.strip() == \"\":\n",
        "                spacer = ttk.Frame(container, height=4)  # tighter rhythm\n",
        "                spacer.grid(row=i, column=0, sticky=\"we\")\n",
        "                continue\n",
        "\n",
        "            lbl = ttk.Label(container, text=text, style=\"Body.TLabel\", justify=\"left\", anchor=\"w\", wraplength=wrap)\n",
        "            lbl.grid(row=i, column=0, sticky=\"we\", pady=1)\n",
        "            label_list.append(lbl)\n",
        "\n",
        "        container.update_idletasks()\n",
        "\n",
        "    def _rewrap_labels(self, labels, new_width):\n",
        "        \"\"\"Re-apply wraplength when container width changes to keep lines tidy.\"\"\"\n",
        "        wrap = max(new_width - 12, 150)\n",
        "        for lbl in labels:\n",
        "            try:\n",
        "                lbl.configure(wraplength=wrap)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    def _group_label(self, level: int):\n",
        "        \"\"\"\n",
        "        Map a single predicted level to a grouped display label and the circle text.\n",
        "        Returns (range_label_for_subtitle, circle_text).\n",
        "        \"\"\"\n",
        "        if level in (1, 2):\n",
        "            return (\"Levels 1â€“2\", \"1â€“2\")\n",
        "        elif level == 3:\n",
        "            return (\"Level 3\", \"3\")\n",
        "        elif level in (4, 5):\n",
        "            return (\"Levels 4â€“5\", \"4â€“5\")\n",
        "        elif level == 6:\n",
        "            return (\"Level 6\", \"6\")\n",
        "        else:\n",
        "            return (\"Level 7\", \"7\")\n",
        "\n",
        "    def _set_stage_image(self, level: int):\n",
        "        \"\"\"Asynchronously load and display the per-level figure.\"\"\"\n",
        "        if not Image or not ImageTk:\n",
        "            # Not cached â†’ show placeholder\n",
        "            self.stage_img_lbl.config(text=\"Loading imageâ€¦\", image=\"\")\n",
        "            self.stage_img_lbl.image = None\n",
        "            return\n",
        "\n",
        "        src = NORWOOD_IMAGES.get(level)\n",
        "        if not src:\n",
        "            self.stage_img_lbl.config(text=f\"(No image mapped for level {level})\", image=\"\")\n",
        "            self.stage_img_lbl.image = None\n",
        "            return\n",
        "\n",
        "        # If cached, render immediately\n",
        "        if level in self._img_cache:\n",
        "            self._render_stage_image(self._img_cache[level])\n",
        "            return\n",
        "\n",
        "        # Not cached â†’ show placeholder and start background download\n",
        "        self.stage_img_lbl.config(text=\"Loading imageâ€¦\", image=\"\")\n",
        "        self.stage_img_lbl.image = None\n",
        "\n",
        "        # Bump request id and capture it for this worker\n",
        "        self._img_req_id += 1\n",
        "        req_id = self._img_req_id\n",
        "\n",
        "        def worker():\n",
        "            pil_img = self._download_stage_image(src)\n",
        "\n",
        "            # Post back to UI thread; ignore if another request superseded us\n",
        "            def on_ui():\n",
        "                if req_id != self._img_req_id:\n",
        "                    return  # stale\n",
        "                if pil_img is None:\n",
        "                    self.stage_img_lbl.config(text=f\"(Couldnâ€™t load stage img {level})\", image=\"\")\n",
        "                    self.stage_img_lbl.image = None\n",
        "                else:\n",
        "                    # cache and render\n",
        "                    self._img_cache[level] = pil_img\n",
        "                    self._render_stage_image(pil_img)\n",
        "\n",
        "            self.after(0, on_ui)\n",
        "\n",
        "        threading.Thread(target=worker, daemon=True).start()\n",
        "\n",
        "    def _render_stage_image(self, pil_img):\n",
        "        \"\"\"Resize and display a PIL image inside a stable 320x240 box.\"\"\"\n",
        "        try:\n",
        "            max_w, max_h = 320, 240\n",
        "            img = pil_img.copy()\n",
        "            # Fit to BOTH width and height while preserving aspect ratio\n",
        "            img.thumbnail((max_w, max_h), Image.LANCZOS)\n",
        "            tk_img = ImageTk.PhotoImage(img)\n",
        "            self._stage_img_tk = tk_img  # keep a reference\n",
        "            self.stage_img_lbl.config(image=tk_img, text=\"\")\n",
        "            self.stage_img_lbl.image = tk_img\n",
        "        except Exception:\n",
        "            self.stage_img_lbl.config(text=\"(Couldnâ€™t render image)\", image=\"\")\n",
        "            self.stage_img_lbl.image = None\n",
        "\n",
        "    def _download_stage_image(self, src: str):\n",
        "        \"\"\"Return a PIL.Image or None. Supports Google Drive links and local file paths.\"\"\"\n",
        "        try:\n",
        "            # Local file path?\n",
        "            if os.path.exists(src):\n",
        "                return Image.open(src).convert(\"RGBA\")\n",
        "\n",
        "            # URL (including Google Drive)\n",
        "            if isinstance(src, str) and (src.startswith(\"http://\") or src.startswith(\"https://\")):\n",
        "                url = src\n",
        "                if \"drive.google.com\" in url:\n",
        "                    m = re.search(r\"/d/([a-zA-Z0-9_-]+)/\", url) or re.search(r\"[?&]id=([a-zA-Z0-9_-]+)\", url)\n",
        "                    if m:\n",
        "                        file_id = m.group(1)\n",
        "                        url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
        "                # modest headers + timeout to avoid long hangs\n",
        "                r = requests.get(url, timeout=10, headers={\"User-Agent\": \"HairLossPredictor/1.0\"})\n",
        "                r.raise_for_status()\n",
        "                return Image.open(io.BytesIO(r.content)).convert(\"RGBA\")\n",
        "\n",
        "            return None\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def _majority_vote(levels):\n",
        "        c = Counter(levels)\n",
        "        if not c:\n",
        "            return 3\n",
        "        max_count = max(c.values())\n",
        "        candidates = [lvl for lvl, cnt in c.items() if cnt == max_count]\n",
        "        return min(candidates)\n",
        "\n",
        "    def _get_bg_color_safe(self, widget):\n",
        "        \"\"\"Best-effort: get a hex background color for a ttk parent to use on tk widgets.\"\"\"\n",
        "        try:\n",
        "            return widget.cget(\"background\")\n",
        "        except Exception:\n",
        "            try:\n",
        "                return widget.master.cget(\"background\")\n",
        "            except Exception:\n",
        "                return \"#f0f0f0\"\n",
        "\n",
        "    def on_back(self):\n",
        "        \"\"\"Go back to the Intake screen (keeps current image/form/results in memory).\"\"\"\n",
        "        try:\n",
        "            if hasattr(self.controller, \"show\"):\n",
        "                self.controller.show(\"intake\")\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    def on_start_over(self):\n",
        "        \"\"\"Reset app state and return to the Loading screen.\"\"\"\n",
        "        try:\n",
        "            if hasattr(self.controller, \"start_over\"):\n",
        "                self.controller.start_over()\n",
        "            elif hasattr(self.controller, \"show\"):\n",
        "                # fallback: just go to loading if start_over isn't available\n",
        "                self.controller.show(\"loading\")\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    def on_learn_more(self):\n",
        "        \"\"\"Open the About Us webpage in the default browser.\"\"\"\n",
        "        url = \"https://github.com/RyanThawkho/Predicting-Male-Pattern-Baldness-Using-Image-and-Blood-Test-Data/tree/main\"  # <-- change to your actual link\n",
        "        try:\n",
        "            webbrowser.open_new_tab(url)\n",
        "        except Exception as e:\n",
        "            from tkinter import messagebox\n",
        "            messagebox.showerror(\"Error\", f\"Could not open webpage:\\n{e}\")\n",
        "\n",
        "    def on_compare_prices(self):\n",
        "        \"\"\"Open clinic price comparison page.\"\"\"\n",
        "        url = \"https://www.kamaze.co.il/aesthetics/compare/33/hair-transplant\"\n",
        "        try:\n",
        "            webbrowser.open_new_tab(url)\n",
        "        except Exception as e:\n",
        "            from tkinter import messagebox\n",
        "            messagebox.showerror(\"Error\", f\"Could not open webpage:\\n{e}\")\n",
        "\n",
        "    def on_browse_models(self):\n",
        "        \"\"\"Open the developer's Hugging Face models page.\"\"\"\n",
        "        url = \"https://huggingface.co/alamb98\"\n",
        "        try:\n",
        "            webbrowser.open_new_tab(url)\n",
        "        except Exception as e:\n",
        "            from tkinter import messagebox\n",
        "            messagebox.showerror(\"Error\", f\"Could not open webpage:\\n{e}\")\n",
        "\n",
        "    def _estimate_grafts_and_costs(self, level: int):\n",
        "        \"\"\"\n",
        "        Return a dict with estimated graft needs and Israel-market price ranges\n",
        "        for DHI/FUE and FUT. Level 3 DHI/FUE fixed at â‚ª21,000 (per user).\n",
        "        NOTE: These are broad, educational estimates; individual plans vary.\n",
        "        \"\"\"\n",
        "        if level in (1, 2):\n",
        "            group = \"Levels 1â€“2\"\n",
        "            grafts = \"â‰ˆ 800â€“1,200 grafts\"\n",
        "            price_fue = \"â‚ª14,000â€“18,000\"\n",
        "            price_fut = \"â‚ª11,000â€“15,000\"\n",
        "        elif level == 3:\n",
        "            group = \"Level 3\"\n",
        "            grafts = \"â‰ˆ 1,500â€“2,200 grafts\"\n",
        "            price_fue = \"â‚ª21,000 (DHI/FUE)\"\n",
        "            price_fut = \"â‚ª18,000â€“20,000\"\n",
        "        elif level in (4, 5):\n",
        "            group = \"Levels 4â€“5\"\n",
        "            grafts = \"â‰ˆ 2,500â€“3,500 grafts\"\n",
        "            price_fue = \"â‚ª26,000â€“34,000\"\n",
        "            price_fut = \"â‚ª22,000â€“30,000\"\n",
        "        elif level == 6:\n",
        "            group = \"Level 6\"\n",
        "            grafts = \"â‰ˆ 3,500â€“4,500 grafts\"\n",
        "            price_fue = \"â‚ª32,000â€“42,000\"\n",
        "            price_fut = \"â‚ª28,000â€“38,000\"\n",
        "        else:  # level 7\n",
        "            group = \"Level 7\"\n",
        "            grafts = \"â‰ˆ 4,500â€“6,000 grafts (often 2 sessions)\"\n",
        "            price_fue = \"â‚ª38,000â€“55,000\"\n",
        "            price_fut = \"â‚ª34,000â€“48,000\"\n",
        "\n",
        "        note = (\n",
        "            \"Estimates only â€” always consult a clinic. Costs depend on graft count,\"\n",
        "            \" donor supply, hair caliber/curl, previous procedures, and goals.\"\n",
        "        )\n",
        "        return {\n",
        "            \"group\": group,\n",
        "            \"grafts\": grafts,\n",
        "            \"price_fue\": price_fue,\n",
        "            \"price_fut\": price_fut,\n",
        "            \"note\": note,\n",
        "        }\n",
        "\n",
        "    def _render_costs(self, data: dict):\n",
        "        \"\"\"Render the costs/grafts panel with wrapped lines.\"\"\"\n",
        "        # clear\n",
        "        for child in self.costs_container.winfo_children():\n",
        "            child.destroy()\n",
        "\n",
        "        # Make nice stacked labels\n",
        "        width = max(self.costs_container.winfo_width(), 300)\n",
        "        wrap = max(width - 12, 150)\n",
        "\n",
        "        def line(text, bold=False, pad=(2, 2)):\n",
        "            lbl = ttk.Label(self.costs_container, text=text, justify=\"left\", anchor=\"w\", wraplength=wrap)\n",
        "            if bold:\n",
        "                try:\n",
        "                    lbl.configure(font=(\"Arial\", 11, \"bold\"))\n",
        "                except Exception:\n",
        "                    pass\n",
        "            lbl.pack(fill=\"x\", pady=pad)\n",
        "            return lbl\n",
        "\n",
        "        line(f\"{data['group']}\", bold=True, pad=(0, 4))\n",
        "        line(f\"Estimated grafts: {data['grafts']}\")\n",
        "        line(f\"DHI/FUE: {data['price_fue']}\")\n",
        "        line(f\"FUT: {data['price_fut']}\")\n",
        "        ttk.Separator(self.costs_container, orient=\"horizontal\").pack(fill=\"x\", pady=6)\n",
        "        line(data[\"note\"])\n",
        "\n",
        "    def _get_stage_recs(self, level: int):\n",
        "        \"\"\"\n",
        "        Return stage recommendations with grouping:\n",
        "          - Levels 1â€“2 share the same combined list\n",
        "          - Levels 4â€“5 share the same combined list\n",
        "          - 3, 6, 7 keep their own\n",
        "        \"\"\"\n",
        "        if level in (1, 2):\n",
        "            combined = (NORWOOD_RECS.get(1, []) + NORWOOD_RECS.get(2, []))\n",
        "        elif level in (4, 5):\n",
        "            combined = (NORWOOD_RECS.get(4, []) + NORWOOD_RECS.get(5, []))\n",
        "        else:\n",
        "            combined = list(NORWOOD_RECS.get(level, []))\n",
        "\n",
        "        # de-duplicate while preserving order\n",
        "        deduped = []\n",
        "        seen = set()\n",
        "        for item in combined:\n",
        "            if item not in seen:\n",
        "                seen.add(item)\n",
        "                deduped.append(item)\n",
        "        return deduped\n",
        "\n",
        "    def _stage_description(self, level: int) -> str:\n",
        "        \"\"\"Return a short description matching the grouped label.\"\"\"\n",
        "        _, circle_text = self._group_label(level)\n",
        "        return STAGE_DESCRIPTIONS.get(circle_text, \"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQJW8q1mmy8a"
      },
      "source": [
        "main.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYTJTx7Dm1DS"
      },
      "outputs": [],
      "source": [
        "# main.py\n",
        "import tkinter as tk\n",
        "from tkinter import ttk, messagebox\n",
        "\n",
        "# Screens (each must expose a Frame subclass)\n",
        "from screens.loading_screen import LoadingScreen\n",
        "from screens.intake_screen import IntakeScreen\n",
        "from screens.processing_screen import ProcessingScreen\n",
        "from screens.results_screen import ResultsScreen\n",
        "from PIL import Image\n",
        "from screens.intake_screen import (\n",
        "    CLS_RESNET18, CLS_MNV3, CLS_EFFB0, CLS_CONVNEXT,\n",
        "    majority_vote, predict_xgb\n",
        ")\n",
        "\n",
        "\n",
        "class App(tk.Tk):\n",
        "    \"\"\"\n",
        "    Central controller:\n",
        "      - creates all screens\n",
        "      - exposes navigation methods for screens to call\n",
        "      - stores shared state (image path, form answers, model results)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.title(\"Hair Loss Predictor\")\n",
        "        self.geometry(\"1100x700\")\n",
        "        self.minsize(960, 640)\n",
        "\n",
        "        # Shared state between screens\n",
        "        self.shared = {\n",
        "            \"image_path\": None,\n",
        "            \"form\": {},          # your yes/no + age answers\n",
        "            \"results\": None,     # final inference payload from processing step\n",
        "        }\n",
        "\n",
        "        # Container for screens\n",
        "        container = ttk.Frame(self)\n",
        "        container.pack(fill=\"both\", expand=True)\n",
        "        container.grid_rowconfigure(0, weight=1)\n",
        "        container.grid_columnconfigure(0, weight=1)\n",
        "\n",
        "        # Instantiate screens\n",
        "        self.screens = {}\n",
        "        self.screens[\"loading\"] = LoadingScreen(\n",
        "            container,\n",
        "            controller=self,\n",
        "            logo_path=\"https://drive.google.com/file/d/1N3E_f-qyut2RHtYm29D4YJ9UY2vGRCNr/view?usp=sharing\"\n",
        "        )\n",
        "        self.screens[\"intake\"] = IntakeScreen(container, controller=self)\n",
        "        self.screens[\"processing\"] = ProcessingScreen(container, controller=self)\n",
        "        self.screens[\"results\"] = ResultsScreen(container, controller=self)\n",
        "\n",
        "        # Grid all screens (stacked)\n",
        "        for f in self.screens.values():\n",
        "            f.grid(row=0, column=0, sticky=\"nsew\")\n",
        "\n",
        "        # Start on loading screen\n",
        "        self.show(\"loading\")\n",
        "\n",
        "    # ---------- Navigation helpers ----------\n",
        "    def show(self, name: str):\n",
        "        \"\"\"Raise the given screen by key ('loading'|'intake'|'processing'|'results').\"\"\"\n",
        "        frame = self.screens[name]\n",
        "        frame.tkraise()\n",
        "        try:\n",
        "            # optional: many of our screens expose .on_show()\n",
        "            frame.on_show()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Called by IntakeScreen after user selects image + answers form\n",
        "    def go_to_processing(self, image_path: str, form: dict):\n",
        "        if not image_path:\n",
        "            messagebox.showwarning(\"Missing image\", \"Please upload an image first.\")\n",
        "            return\n",
        "\n",
        "        self.shared[\"image_path\"] = image_path\n",
        "        self.shared[\"form\"] = form or {}\n",
        "\n",
        "        proc: ProcessingScreen = self.screens[\"processing\"]  # type: ignore\n",
        "        # show a preview on the processing screen\n",
        "        proc.set_inputs(image_path=image_path, form=form)\n",
        "        # tell the processing screen how to run the job and where to send results\n",
        "        proc.configure_job(self.run_full_inference, args=(image_path, form), on_done=self._processing_finished)\n",
        "\n",
        "        self.show(\"processing\")\n",
        "        proc.start()\n",
        "\n",
        "    # Callback that processing screen invokes when all models finish\n",
        "    def _processing_finished(self, results: dict):\n",
        "        self.shared[\"results\"] = results or {}\n",
        "        # Hand results to results screen and show it\n",
        "        res: ResultsScreen = self.screens[\"results\"]  # type: ignore\n",
        "        res.set_results(self.shared[\"results\"])\n",
        "        self.show(\"results\")\n",
        "\n",
        "    # Optional â€œStart overâ€ from results\n",
        "    def start_over(self):\n",
        "        self.shared.update({\"image_path\": None, \"form\": {}, \"results\": None})\n",
        "        # Some screens may expose reset() for their UI\n",
        "        try:\n",
        "            self.screens[\"intake\"].reset()\n",
        "        except Exception:\n",
        "            pass\n",
        "        try:\n",
        "            self.screens[\"processing\"].reset()\n",
        "        except Exception:\n",
        "            pass\n",
        "        self.show(\"loading\")\n",
        "\n",
        "    def run_full_inference(self, image_path: str, form: dict) -> dict:\n",
        "        \"\"\"Loads models (lazily), runs all 4 image models + XGBoost, returns a results dict for ResultsScreen.\"\"\"\n",
        "        # Ensure models are loaded (load() is idempotent in your wrappers)\n",
        "        CLS_RESNET18.load()\n",
        "        CLS_MNV3.load()\n",
        "        CLS_EFFB0.load()\n",
        "        CLS_CONVNEXT.load()\n",
        "\n",
        "        pil = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        preds = {}\n",
        "        for name, clf in [\n",
        "            (\"resnet18\", CLS_RESNET18),\n",
        "            (\"mobilenet_v3_large\", CLS_MNV3),\n",
        "            (\"efficientnet_b0\", CLS_EFFB0),\n",
        "            (\"convnext_tiny\", CLS_CONVNEXT),\n",
        "        ]:\n",
        "            lvl, _ = clf.predict_level(pil)\n",
        "            preds[name] = lvl\n",
        "\n",
        "        final_level = majority_vote(preds)\n",
        "        y_pred, y_label, p_yes = predict_xgb(form)\n",
        "\n",
        "        return {\n",
        "            \"norwood_by_model\": preds,\n",
        "            \"norwood_final\": final_level,\n",
        "            \"hairfall_yes\": bool(y_pred == 1),\n",
        "            \"hairfall_label\": y_label,\n",
        "            \"hairfall_prob\": p_yes,\n",
        "        }\n",
        "\n",
        "    def go_to_intake(self):\n",
        "        self.show(\"intake\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    App().mainloop()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0062a4b023cd4fc89551df4277e408e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b4f231b24b84db2b13490a6d1d4f9b7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b9179123006f440489e33dd2f882fe38",
            "value": "â€‡â€‡...xgboost_hair_fall_classifier.joblib:â€‡100%"
          }
        },
        "11cd1c591d63426a819c4a3d00e0520c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14d46328fe9f498b983e0367b7242603": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1af501bb411e4e67a4c64c8d9e92a0a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "214fae346aa84eccbe5882afb1ab0656": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2182b4a8a36848c4a07c76dd4a64375c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f2e2fc7ef54461a85fb619098a08c05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38acfd388a01439e95563ce2c20c8817": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a708d93f1524597a1a8758ca415451f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aeaa9070cb944328e40a401e202fd82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7cb5cdb156041c6af54d42741fb9fc0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_47346fb4ba0549188b2e055e259c0028",
            "value": "Processingâ€‡Filesâ€‡(1â€‡/â€‡1)â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡:â€‡100%"
          }
        },
        "3b83dd45ad50474db2a55781ab3ed6dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_2182b4a8a36848c4a07c76dd4a64375c",
            "style": "IPY_MODEL_8b18ce183ba14899b577237d2f4deb3d",
            "value": true
          }
        },
        "3e78b7b26f1647c082d96b113cccde69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "419a5d37336741c681c2a0d5349fc5f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41a299d1894c46fa88fa30c19a222a8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "452ee95e0dc64736b762f5cfef2966c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9acda40993d04dc8ac4735e0107786ac",
              "IPY_MODEL_6bda8817a0b94105a5499e64158b78d3",
              "IPY_MODEL_ee83aa1c7e5c446b9027cc1d0ab2ac8c"
            ],
            "layout": "IPY_MODEL_6ecd0d90495f4a26a08cc9651ef35976"
          }
        },
        "4577b88358c6428d9b885ff4d4473fbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_38acfd388a01439e95563ce2c20c8817",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ee0b778744f44c5c945a9cd12093d417",
            "value": ""
          }
        },
        "46da16e43ae74180b6df3d6829952188": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0062a4b023cd4fc89551df4277e408e3",
              "IPY_MODEL_83ee1354ed6e4615bd08c5bebe4e51d4",
              "IPY_MODEL_4f2b0b09ccc3441988a4b9cee2a4dd81"
            ],
            "layout": "IPY_MODEL_bd7c556a21ae42c0b24b6134fd98ea7c"
          }
        },
        "47346fb4ba0549188b2e055e259c0028": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4aef77b59273487d825a4fb902fa48ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4bf5e3471d6c40caab3efa70e2431df2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3790aa0fa274b23a77f1dcf9b1fe7fb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4aef77b59273487d825a4fb902fa48ec",
            "value": 1
          }
        },
        "4f2b0b09ccc3441988a4b9cee2a4dd81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_669d36403fd54984bcd9bd4039f216a8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_41a299d1894c46fa88fa30c19a222a8d",
            "value": "â€‡â€‡189kBâ€‡/â€‡â€‡189kBâ€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡"
          }
        },
        "52d34ac9915745999cd22f7c949cac41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "548a58207d7e4d74bd74a055e4f057af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57c5e0fbed7049e19d6dda3fb7f969bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "589abc95558142358648d600f6076fa1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "668e1bf5c63b48dea17668e8527b7a1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95f5c85401f04244a68de18631faf3f3",
              "IPY_MODEL_4bf5e3471d6c40caab3efa70e2431df2",
              "IPY_MODEL_88b49ffcd25b491b90d99a6798fb982c"
            ],
            "layout": "IPY_MODEL_589abc95558142358648d600f6076fa1"
          }
        },
        "669d36403fd54984bcd9bd4039f216a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6897d611d0cc4fa7aa77a8b4edeacfb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_57c5e0fbed7049e19d6dda3fb7f969bd",
            "style": "IPY_MODEL_7e899251cecf4434b982ad0cc9f3e9d8",
            "tooltip": ""
          }
        },
        "69293defbd3f4ebe9eaaad8cf5036e83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "695ca5ac9e92423183b4eca35a3b073f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11cd1c591d63426a819c4a3d00e0520c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_dfae06417a5b4e6197cb25dbeb19e9fc",
            "value": "Connecting..."
          }
        },
        "6bda8817a0b94105a5499e64158b78d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14d46328fe9f498b983e0367b7242603",
            "max": 188641,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8ad759bf4d2490b85a55e28ccbbc38e",
            "value": 188641
          }
        },
        "6ecd0d90495f4a26a08cc9651ef35976": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e899251cecf4434b982ad0cc9f3e9d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "80bbe663222945e4b4c111a827768706": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81f43482b6da437bad87273c5f02a605": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a0ccff7a68f42d2a8b0895b6345f27a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b2d9ac97db4f42eba4f3edd3b3ff86a0",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "83ee1354ed6e4615bd08c5bebe4e51d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_548a58207d7e4d74bd74a055e4f057af",
            "max": 188641,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4726b45a1a84b36a23b392bb8cfad35",
            "value": 188641
          }
        },
        "8621c495aebd4ae0990a5bd3e923848b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86342a28207043d080259f190aac52c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "889049e5296d401db5e560f655db7d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80bbe663222945e4b4c111a827768706",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ff04c5a4b313492fb8a73edcafc8bbd0",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "88b49ffcd25b491b90d99a6798fb982c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_419a5d37336741c681c2a0d5349fc5f5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3e78b7b26f1647c082d96b113cccde69",
            "value": "â€‡â€‡189kBâ€‡/â€‡â€‡189kB,â€‡â€‡471kB/sâ€‡â€‡"
          }
        },
        "8a0ccff7a68f42d2a8b0895b6345f27a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b18ce183ba14899b577237d2f4deb3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f51dfd864f047fd853aaf71c8b8b9c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_c269acba95f14cc68f0f6f9f34f9fd65"
          }
        },
        "95f5c85401f04244a68de18631faf3f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52d34ac9915745999cd22f7c949cac41",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ec2dde35edcd493da530f38666ffec6b",
            "value": "Newâ€‡Dataâ€‡Uploadâ€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡:â€‡100%"
          }
        },
        "9acda40993d04dc8ac4735e0107786ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a708d93f1524597a1a8758ca415451f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2f2e2fc7ef54461a85fb619098a08c05",
            "value": "â€‡â€‡...xgboost_hair_fall_classifier.joblib:â€‡100%"
          }
        },
        "9b4f231b24b84db2b13490a6d1d4f9b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeb6df19b6ca4f34b2bbf6caa7781389": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69293defbd3f4ebe9eaaad8cf5036e83",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_214fae346aa84eccbe5882afb1ab0656",
            "value": 1
          }
        },
        "b2d9ac97db4f42eba4f3edd3b3ff86a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9179123006f440489e33dd2f882fe38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd7c556a21ae42c0b24b6134fd98ea7c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c269acba95f14cc68f0f6f9f34f9fd65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "c4726b45a1a84b36a23b392bb8cfad35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7cb5cdb156041c6af54d42741fb9fc0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8ad759bf4d2490b85a55e28ccbbc38e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db4f5dc54fb143259f864063aa395f71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dde7a5d4cbb5453bad8e378b884e5ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfae06417a5b4e6197cb25dbeb19e9fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3790aa0fa274b23a77f1dcf9b1fe7fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ec2dde35edcd493da530f38666ffec6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed4133ab62e240e182b219d673a3cea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3aeaa9070cb944328e40a401e202fd82",
              "IPY_MODEL_aeb6df19b6ca4f34b2bbf6caa7781389",
              "IPY_MODEL_ef3238bd31c14610b8c8ef41a2cd19af"
            ],
            "layout": "IPY_MODEL_8621c495aebd4ae0990a5bd3e923848b"
          }
        },
        "ee0b778744f44c5c945a9cd12093d417": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee83aa1c7e5c446b9027cc1d0ab2ac8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1af501bb411e4e67a4c64c8d9e92a0a9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_86342a28207043d080259f190aac52c2",
            "value": "â€‡â€‡189kBâ€‡/â€‡â€‡189kBâ€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡â€‡"
          }
        },
        "ef3238bd31c14610b8c8ef41a2cd19af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db4f5dc54fb143259f864063aa395f71",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_dde7a5d4cbb5453bad8e378b884e5ff2",
            "value": "â€‡â€‡189kBâ€‡/â€‡â€‡189kB,â€‡â€‡471kB/sâ€‡â€‡"
          }
        },
        "ff04c5a4b313492fb8a73edcafc8bbd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
